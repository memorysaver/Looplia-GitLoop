{
  "id": "b2d7084b-daab-4fc8-9ce3-21380dd6c638",
  "source_type": "podcast",
  "title": "E179｜DeepSeek技术解析：为何引发英伟达股价下跌？",
  "link": "https://sv101.fireside.fm/186",
  "published": "2025-02-06T01:30:00+00:00",
  "author": "硅谷101",
  "summary": "<p>随着DeepSeek登上苹果App Store榜首，这款低成本、高性能的开源模型引发全球关注的同时，也造成了英伟达股价在1月27日下跌近17%，市值蒸发5890亿美元。按理说，像DeepSeek这样的开源模型会带动AI创业繁荣，进而推高GPU需求。为什么英伟达却不涨反跌？本期节目我们将和模型算法、GPU虚拟化领域的学者与创业者，一起探讨DeepSeek的核心优势，它对芯片产业和开源生态的影响，还原这场市场震动背后的逻辑。</p>\n\n<p><strong>【主播】</strong><br />\n泓君Jane，硅谷101创始人，播客主理人<br />\n<strong>【嘉宾】</strong><br />\n陈羽北，加州大学戴维斯分校电子与计算机工程系助理教授，AIzip.ai联合创始人<br />\nJohn Yue，Inference.ai创始人兼CEO</p>\n\n<p><strong>【你将听到】</strong><br />\n02:29 DeepSeek的三板斧：低成本、高性能、全开源<br />\n03:57 大模型创新瓶颈：技术路线趋同，突破性想法变少<br />\n05:09 核心创新：V3基础模型能力强<br />\n07:01 创新一：MOE与绕过稀疏奖励<br />\n09:04 创新二： 通过蒸馏学习传递能力，大模型教小模型<br />\n12:46 为何V3出来一个月之后才引爆股市<br />\n13:54  对英伟达利好与利空：冲击溢价但并未冲垮壁垒<br />\n16:01 DeepSeek冲击英伟达两大护城河：“绕过”NVLink和CUDA<br />\n23:00 类似于Groq的推理芯片能崛起吗？软件依然是难点<br />\n29:11 《The Bitter Lesson》的启发：AI的两种基本能力是学习与搜索<br />\n30:06 效率困境：AI需要跨越三个数量级才能达到人类智能<br />\n35:20 开源的意义：降低AI应用开发准入门槛<br />\n38:06 重构API价格体系：DeepSeek R1通过技术优化将成本降至OpenAI O1的1/27<br />\n39:47 降级芯片难持续：老款芯片停产限制了成本优化空间<br />\n43:08 小模型特定场景突破：某些任务已可媲美大模型表现<br />\n45:34 未来AI基建分层化：端、边、云分工协同是趋势<br />\n48:32 Anthropic的预测过分乐观：AI学习效率太低不足以追赶人类智能<br />\n53:10 大模型本身不足以通向AGI，但基础研究方向正在取得进展<br />\n56:00 模型自我能力提升是达到AGI的核心门槛<br />\n57:33 通往AGI的多条路径：世界模型等不同技术方向并存<br />\n01:03:22 提问DeepSeek ：数据与持续创新能力</p>\n\n<p><strong>【其他相关信息】</strong></p>\n\n<ul>\n<li>MOE (Mixture of Experts，专家混合模型)：一种神经网络架构，结合多个专家子模型进行工作，通过负载均衡提高效率，适用于大规模模型。</li>\n<li>Bootstrap (自举法)：模型通过生成多个答案并选择最佳结果，来提升自身性能的自我改进方法。</li>\n<li>蒸馏 (Distillation)：将大模型的知识转移给小模型，通过模仿大模型的输出，提高小模型的能力。</li>\n<li>GRPO (Group Relative Policy Optimization ，分组相对策略优化）：一种用于强化学习的优化算法，通过在同一问题下生成多个输出（即“分组”），并对这些输出进行相对比较来计算奖励。这种方法避免了传统 PPO 中对价值函数的依赖，从而显著减少了内存和计算资源的消耗。</li>\n<li>PPO (Proximal Policy Optimization，近端策略优化)：一种强化学习算法，通过限制策略更新的幅度来保持优化的稳定性。</li>\n<li>负载均衡 (Load Balance)：在分布式系统中平衡计算任务，避免过度集中或资源闲置。</li>\n<li>强化学习 (Reinforcement Learning)：通过奖励机制引导AI模型学习最优策略的机器学习方法。</li>\n<li>模型预测控制 (Model Predictive Control)：基于对未来状态的预测来优化当前决策的方法，广泛用于自动化控制。</li>\n<li>NV Link (NVIDIA Link)：英伟达开发的高速芯片互联技术，支持多GPU协同工作，提升计算效率。</li>\n<li>CUDA (Compute Unified Device Architecture，统一计算设备架构)：英伟达推出的并行计算平台和编程模型，用于加速GPU上的计算任务。</li>\n<li>PTX (Parallel Thread Execution，并行线程执行)：CUDA平台底层的指令集架构，直接与GPU硬件交互。</li>\n<li>CUDA Core/Tensor Core：CUDA Core 是GPU中的基础计算单元，负责执行并行计算任务；而 Tensor Core 是专门为加速深度学习中的矩阵运算和AI任务设计的计算单元，提供更高的计算效率。</li>\n<li>ASIC (Application Specific Integrated Circuit，专用集成电路)：为特定应用定制的集成电路，通常用于高效处理特定任务。</li>\n<li>Groq：一家专注于开发AI专用芯片的美国公司，提供高效的AI计算解决方案。</li>\n<li>《The Bitter Lesson》(痛苦的教训)：Rich Sutton的经典文章，提出在AI发展中，计算能力和规模比算法精巧性更为重要。</li>\n<li>世界模型 (World Model)：一种能够预测动作后果的AI模型，常用于环境模拟、决策规划和强化学习中。</li>\n<li>《Genie 2》：DeepMind的研究论文，介绍了一个可以在任意2D图像中进行自由移动探索的AI模型 - 给它一张图片，AI就能变成图中的&quot;主角&quot;，可以在画面中前后左右走动，仿佛真的进入了这个2D世界。这是一个重要的&quot;世界模型&quot;(World Model)的实例。</li>\n<li>HPC (High Performance Computing，高性能计算)：使用超级计算机集群处理复杂的计算任务，通常应用于科学计算、气候模拟等高需求场景。</li>\n</ul>\n\n<p><strong>【监制】</strong><br />\n杜秀<br />\n<strong>【后期】</strong><br />\nAMEI<br />\n<strong>【BGM】</strong><br />\nDusk Movers - Alexandra Woodward<br />\nCity Phases STEMS INSTRUMENTS - John Abbot</p>\n\n<p><strong>【在这里找到我们】</strong><br />\n公众号：硅谷101<br />\n收听渠道：苹果｜小宇宙｜喜马拉雅｜蜻蜓FM｜网易云音乐｜QQ音乐｜荔枝播客<br />\n海外用户：Apple Podcast｜Spotify｜TuneIn｜YouTube｜Amazon Music<br />\n联系我们：<a href=\"mailto:podcast@sv101.net\" rel=\"nofollow\">podcast@sv101.net</a></p><p>Special Guests: John Yue and 陈羽北.</p>",
  "content": "<p>随着DeepSeek登上苹果App Store榜首，这款低成本、高性能的开源模型引发全球关注的同时，也造成了英伟达股价在1月27日下跌近17%，市值蒸发5890亿美元。按理说，像DeepSeek这样的开源模型会带动AI创业繁荣，进而推高GPU需求。为什么英伟达却不涨反跌？本期节目我们将和模型算法、GPU虚拟化领域的学者与创业者，一起探讨DeepSeek的核心优势，它对芯片产业和开源生态的影响，还原这场市场震动背后的逻辑。</p>\n\n<p><strong>【主播】</strong><br />\n泓君Jane，硅谷101创始人，播客主理人<br />\n<strong>【嘉宾】</strong><br />\n陈羽北，加州大学戴维斯分校电子与计算机工程系助理教授，AIzip.ai联合创始人<br />\nJohn Yue，Inference.ai创始人兼CEO</p>\n\n<p><strong>【你将听到】</strong><br />\n02:29 DeepSeek的三板斧：低成本、高性能、全开源<br />\n03:57 大模型创新瓶颈：技术路线趋同，突破性想法变少<br />\n05:09 核心创新：V3基础模型能力强<br />\n07:01 创新一：MOE与绕过稀疏奖励<br />\n09:04 创新二： 通过蒸馏学习传递能力，大模型教小模型<br />\n12:46 为何V3出来一个月之后才引爆股市<br />\n13:54  对英伟达利好与利空：冲击溢价但并未冲垮壁垒<br />\n16:01 DeepSeek冲击英伟达两大护城河：“绕过”NVLink和CUDA<br />\n23:00 类似于Groq的推理芯片能崛起吗？软件依然是难点<br />\n29:11 《The Bitter Lesson》的启发：AI的两种基本能力是学习与搜索<br />\n30:06 效率困境：AI需要跨越三个数量级才能达到人类智能<br />\n35:20 开源的意义：降低AI应用开发准入门槛<br />\n38:06 重构API价格体系：DeepSeek R1通过技术优化将成本降至OpenAI O1的1/27<br />\n39:47 降级芯片难持续：老款芯片停产限制了成本优化空间<br />\n43:08 小模型特定场景突破：某些任务已可媲美大模型表现<br />\n45:34 未来AI基建分层化：端、边、云分工协同是趋势<br />\n48:32 Anthropic的预测过分乐观：AI学习效率太低不足以追赶人类智能<br />\n53:10 大模型本身不足以通向AGI，但基础研究方向正在取得进展<br />\n56:00 模型自我能力提升是达到AGI的核心门槛<br />\n57:33 通往AGI的多条路径：世界模型等不同技术方向并存<br />\n01:03:22 提问DeepSeek ：数据与持续创新能力</p>\n\n<p><strong>【其他相关信息】</strong></p>\n\n<ul>\n<li>MOE (Mixture of Experts，专家混合模型)：一种神经网络架构，结合多个专家子模型进行工作，通过负载均衡提高效率，适用于大规模模型。</li>\n<li>Bootstrap (自举法)：模型通过生成多个答案并选择最佳结果，来提升自身性能的自我改进方法。</li>\n<li>蒸馏 (Distillation)：将大模型的知识转移给小模型，通过模仿大模型的输出，提高小模型的能力。</li>\n<li>GRPO (Group Relative Policy Optimization ，分组相对策略优化）：一种用于强化学习的优化算法，通过在同一问题下生成多个输出（即“分组”），并对这些输出进行相对比较来计算奖励。这种方法避免了传统 PPO 中对价值函数的依赖，从而显著减少了内存和计算资源的消耗。</li>\n<li>PPO (Proximal Policy Optimization，近端策略优化)：一种强化学习算法，通过限制策略更新的幅度来保持优化的稳定性。</li>\n<li>负载均衡 (Load Balance)：在分布式系统中平衡计算任务，避免过度集中或资源闲置。</li>\n<li>强化学习 (Reinforcement Learning)：通过奖励机制引导AI模型学习最优策略的机器学习方法。</li>\n<li>模型预测控制 (Model Predictive Control)：基于对未来状态的预测来优化当前决策的方法，广泛用于自动化控制。</li>\n<li>NV Link (NVIDIA Link)：英伟达开发的高速芯片互联技术，支持多GPU协同工作，提升计算效率。</li>\n<li>CUDA (Compute Unified Device Architecture，统一计算设备架构)：英伟达推出的并行计算平台和编程模型，用于加速GPU上的计算任务。</li>\n<li>PTX (Parallel Thread Execution，并行线程执行)：CUDA平台底层的指令集架构，直接与GPU硬件交互。</li>\n<li>CUDA Core/Tensor Core：CUDA Core 是GPU中的基础计算单元，负责执行并行计算任务；而 Tensor Core 是专门为加速深度学习中的矩阵运算和AI任务设计的计算单元，提供更高的计算效率。</li>\n<li>ASIC (Application Specific Integrated Circuit，专用集成电路)：为特定应用定制的集成电路，通常用于高效处理特定任务。</li>\n<li>Groq：一家专注于开发AI专用芯片的美国公司，提供高效的AI计算解决方案。</li>\n<li>《The Bitter Lesson》(痛苦的教训)：Rich Sutton的经典文章，提出在AI发展中，计算能力和规模比算法精巧性更为重要。</li>\n<li>世界模型 (World Model)：一种能够预测动作后果的AI模型，常用于环境模拟、决策规划和强化学习中。</li>\n<li>《Genie 2》：DeepMind的研究论文，介绍了一个可以在任意2D图像中进行自由移动探索的AI模型 - 给它一张图片，AI就能变成图中的&quot;主角&quot;，可以在画面中前后左右走动，仿佛真的进入了这个2D世界。这是一个重要的&quot;世界模型&quot;(World Model)的实例。</li>\n<li>HPC (High Performance Computing，高性能计算)：使用超级计算机集群处理复杂的计算任务，通常应用于科学计算、气候模拟等高需求场景。</li>\n</ul>\n\n<p><strong>【监制】</strong><br />\n杜秀<br />\n<strong>【后期】</strong><br />\nAMEI<br />\n<strong>【BGM】</strong><br />\nDusk Movers - Alexandra Woodward<br />\nCity Phases STEMS INSTRUMENTS - John Abbot</p>\n\n<p><strong>【在这里找到我们】</strong><br />\n公众号：硅谷101<br />\n收听渠道：苹果｜小宇宙｜喜马拉雅｜蜻蜓FM｜网易云音乐｜QQ音乐｜荔枝播客<br />\n海外用户：Apple Podcast｜Spotify｜TuneIn｜YouTube｜Amazon Music<br />\n联系我们：<a href=\"mailto:podcast@sv101.net\" rel=\"nofollow\">podcast@sv101.net</a></p><p>Special Guests: John Yue and 陈羽北.</p>",
  "enriched_via": "rss",
  "audio": {
    "url": "https://aphid.fireside.fm/d/1437767933/f0f20376-8faf-4940-b920-84af6c734e2d/b2d7084b-daab-4fc8-9ce3-21380dd6c638.mp3",
    "type": "audio/mpeg",
    "length": "93598507"
  },
  "duration": "1:04:59",
  "season_number": "4",
  "image": "https://media24.fireside.fm/file/fireside-images-2024/podcasts/images/f/f0f20376-8faf-4940-b920-84af6c734e2d/cover.jpg?v=6",
  "season": "4",
  "tags": [
    "AI，DeepSeek",
    "AGI",
    "大模型，英伟达，NV，NVIDIA，陈羽北，"
  ],
  "archived_at": "2025-11-28T07:01:47.266014+00:00"
}