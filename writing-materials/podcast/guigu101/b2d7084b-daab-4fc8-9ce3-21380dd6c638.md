---
id: b2d7084b-daab-4fc8-9ce3-21380dd6c638
source_type: podcast
source_key: guigu101
title: "E179｜DeepSeek技术解析：为何引发英伟达股价下跌？"
url: https://sv101.fireside.fm/186
published: 2025-02-06T01:30:00+00:00
downloaded_at: 2025-11-28T07:12:35.898925+00:00
---

# E179｜DeepSeek技术解析：为何引发英伟达股价下跌？

欢迎收听硅谷101我是红军大家过年好大家春节过得怎么样我是整个春节期间都有被Deepseek给刷屏而且它其实不仅仅是在中国火它也是现在硅谷还有华尔街讨论的热点那Deepseek是在1月26号那一天登上苹果App Store榜的榜首的从那之后的18天,它的下载量是1600万次。如果我们对比OpenAI发布ChatGPT的同期下载量了,它是ChatGPT同期下载量的1.8倍,现在已经成为了全球140个市场里面下载量最多的应用。那DeepSeek引发关注的另外一点,它的出现也带来了美国科技股的全线下跌。在1月27号的那一天英伟达它的跌幅就接近17%市值蒸发了5890亿美元按理说像DeepSeek这种低成本高性能同时还是开源的模型它的出现应该是带来整个AI创业的繁荣那市场就应该需要更多的GPU那所以按照这个逻辑推理英伟达的股价应该是涨而不是跌但是为何英伟达不涨反跌呢这期节目我们就会详细的来解释这个问题那除此之外呢我们也会深度解析DeepSeek的核心技术以及对整个芯片产业还有开源生态的影响在过去的这一周我们在硅谷做了十个跟DeepSeek相关的深度采访我们就不一一在播客里面呈现了大家感兴趣的话呢可以去观看硅谷101的视频我们现在也正在加班加点的制作中那下面就先请收听我们今天的播客那今天我们来聊一聊最近可以说是大家都在热议的Deep Seek那跟我在一起的呢也是大家的老朋友加州大学戴维斯分校电子与计算机工程系助理教授陈宇北哈喽宇北你好你好对还有一位是Inference.ai的创始人与CEO John Yue哈喽John你好哈喽那今天其实正好预备我觉得你可以从模型跟算法的方向来讲然后John可以跟我们从算力的方向来分析一下正好是在两位这个专业的方向上那我觉得首先可不可以先总体上给大家介绍一下就是为什么这次DeepSeek一出来他立刻不管是在股市上还是说在中美之间的这个讨论他都引发了大家的关注那预备你先从技术上给我们简单分析一下他有哪些表经验的表现吧我觉得这次就是引发这么大的一个讨论的话首先就是DeepSeek在所有的这些Language Model的团队里面呢它本身不是一个非常的知名的一个团队在之前就很多人其实不知道DeepSeek他们很低调第二个是说呢这次媒体报道出来的一个talking point我觉得是说他们低成本然后用基本上用不是最好的算力啊然后用很便宜的价格就超越了OpenAI那我认为这个呢可能对于很多不了解以前的他们的背景的读者吧它会造成一定的冲击对整个的股市也会造成一定的冲击然后第三个呢是它确实这次DeepSeek做出来的这个模型在Benchmark上跟O1达到了一样的差不多的水平甚至更好伯仲之间所以这个可能对大家也有一个冲击就是说是不是美国的Leadership不存在了我觉得主要的引发这么大的一个讨论是从这么几点来的我觉得就是说这个报道还是有一定的片面性的对对 我觉得在展开以前我非常想follow一下你刚刚说的就是是不是美国的Leadership不存在了你怎么看这个问题这可能也是大家最关心的一个问题我其实觉得当然Deep Seek的技术很好了但是我实际上感觉就是说在泛化能力上面我一个初步的一个感觉还是说O1的这个模型在一般的任务上的泛化能力还要更强一点第二个是说我觉得有一点确实是就是说大家在大模型上的这种技术大家对它的理解和技术或者说做的方法在一定程度上我觉得这个速度下降了就是大家想的有点相似做的很多东西在收敛那当这个时候的话它其实不是美国的技术领先的一个问题而是说是整个学界大家的想法这种创新性我其实觉得在这一点上是有convergence这个确实让大家会觉得有这么一点就是slow down就是会下降嘛整个的速度你说创新的速度在下降或者说我感觉大家的想法很多的时候是有点像没有那种你说出来我压根就没有想到的这种想法好多的时候在这种越来越少了你指的是比如说大家都开始认同强化学习的方式是这一点呢我自己一点粗浅的理解这次我反而觉得这个强化学习是被大家过度提到了一个东西当然一会儿我们可以再说这个细节但是从Deep Stick这次的进展我认为虽然这个强化学习在这里面占了很大的一个比重但是在我看来其实是基础模型本身的能力这个实际上是很强的你说V3其实已经是一个很强的模型了对我觉得V3是一个本身它的基础能力是不错的为什么呢因为在如果你仔细看它的这个文章里边有一个数字你可以看到在R1 Zero没有进行强化学习之前呢生成100条它的成功率如果没记错的话也已经是在10%左右了这是一个非常非常显著的一个性能4O是多少4O跟O14O的话我印象中是最后到了780吧但是呢基本的一个概念是说它在前期10%是一个非常高的Number在我看来他用了一个GRPO的方法本身的这个Policy Gradient这个方法呢在我看来我的理解是这也算是一个比较粗糙的一个模型就可以认为那后来在网上有我看到有小伙伴说PPO也可以就是其他的RL的方法也可以那么我觉得如果要是这样的话那其实最主要的这个进展我认为是在这个基础模型的前期它已经达到了一个10%我觉得这个是非常好的一个性能当模型的基础能力达到一定水平之后呢你可以通过一个这样类似于search的方法能够自我进行提升如果你可以找到一个比较方便的一个reward的话就是这种学习的奖励函数的话那你就可以实现自我的提升所以我觉得这个是一个蛮好的一个message但是我觉得反而强化学习在这里面的地位是次要的所以我总结你的观点就是你觉得Deepseek之所以好本质上还是因为V3的表现非常惊艳V3的表现惊艳其实是他们比如说用MOE的各种方式去让这个基础模型它的整体的性能更好然后R1只是说它在这个基础模型之上的一次升级但是你觉得V3比R1跟R10更重要我觉得它们都有一些重要的点V3里边的重要的点的话我认为基本上都在和model架构的efficiency上的提升我觉得在V3里边的话有两个比较重要的工作就是一个是MOEMOE以前的话你会发现不同的expert它的load balance做的不太好所以当你把它分散到不同的节点上的话它的load balance会有问题所以他们在这一点上做了一个load balance的优化同时呢它在attention的这个layer的话它要节省这个kv cache其实也是在提高这个架构的efficiency就是它的性能吧这两点作为它的核心的创新然后使得它在一个600多币的一个microtron级别的这种大模型上然后它的基础模型的表现其实已经挺不错的了那么这次Deepseek R1.0的时候他们其实做的第一件事情就是说我先设计一个非常简单直观的奖励函数管它叫做Rule-based的这种奖励函数然后基本上就我刚才说的你要保证你回答的这个数学题它要绝对正确你的回答格式也要绝对正确然后它一个基本想法就是说我就用Deepseek V3的方法每次你问我一个问题的时候我回答它100条然后再从这100条里边去寻找那些增强这些回答对的回答的比重就是实际上它绕过了reinforced learning我认为就是强化学习里边最难的一个问题就是稀疏的奖励就比如说我回答100条我回答1万条它都不对那么我其实就没有办法去提升了因为我根本就没有一个学习的方向因为所有的时候都是错的对吧反正是说如果我做的这个任务已经有一定的成功率我加强这些成功率的这些部分我觉得这件事情就使它从一个稀疏的奖励变成了一个比较稠密的奖励同时我也就不再用去搭桥去建模去学中间的一些奖励的函数了所以我感觉就是说这里边是一个它的借助V3的基础的能力有一个挺大的提升同时呢在R10里面告诉我们如果一个模型的基础能力已经不错了那么我是有可能通过这个模型自我进行提升的其实这种思路和model predictive control和世界模型的一些想法其实是有很多的相似之处的只不过是我现在在这里解决了一个最简单的一个问题那么第二个我觉得看似是一个显而易见但是这次也产生了很大影响力的一个结果呢就是说我可以先训一个这样600多币的一个大模型然后我让它用自己发的方式对吧因为它可以回答100次然后用自我bootstrap的方法逐渐提高这个能力从原来的10%可能后面提到70% 80%用这样的一个方式呢我先学一个大模型然后也可以用大模型去教小模型然后他们后面做了一个非常有意思的实验就是说在Q1上面做了到1.5B一直到30几B然后这样的模型他们都做了这样的一个distillation争流学习你用大模型学出来的这些 reasoning和 planning的能力你可以来教这些小模型提升他们在相关问题上的表现我感觉是一个相对来讲比较容易想到的一个点因为其实在所有的自我增强的这种或者说model predictive controlmodel based RL等等里边面临一个核心问题就是说如果你的模型不够好那么我在上面提升的话我就刚才又说的这些方法这种通过search搜索的这种方法其实表现都不会太好但是你如果用一个大模型它的搜索能力可以了对吧它本身的自己的模型表现好了以后呢然后你已经学到的这些能力你直接交给小模型这个是可以的所以我听下来觉得Deepseek整体上它是一个组合权就是它每一步跟它接下来比如说它从V3到R10到R1每一步它的方向上都是有一些策略上的可取之处的那你觉得在硅谷的这些公司里面比如说像OpenAIGemini或者像Cloud.AI包括Lama他们有去沿用这样一套就是吹模型的整个的方法吗我觉得是有的就是说很多的这种想法其实都是在之前的工作里面都有比如我印象中在DeepSeek V3的这个模型他们用到的Multihead的这种Latent Attention之前应该Meta有一篇工作专门讲的就是一个Multi-Token的一个Layer其实也有相似的效果也应该有很大的借鉴然后Resoning和Planning的话之前也有过很多这个方面的工作了当然这个Process的这个Reward像这种Model-Based方法我其实恰恰觉得这次DeepSeek R1-Zero他们取这个名字在一定程度上和这个Alpha-Zero有点像你们是什么时候关注到DeepSeek这家公司的以前他们应该就一直在发一些文章但是真正特别仔细的关注还是最近的事情了就是之前一直在听V3出来开始但之前应该也有一些文章他们应该一直在发嗯 这样呢我应该是12月的时候听说的吧也是V3对 V3但是当时也没有很注意这件事情因为大家都觉得可能美国还是AI领先很多国内模型虽然说跑分跑了好但是大家也不知道到底是怎么跑的分觉得没有很多心情去关注而且尤其对我们就是客户如果不提的话我们也不会去甚至研究这个东西但他这个应该是就是微软的那个CEO最近发了一个推特那个发完以后才火起来了他其实火了好几波我是在2024年的年中就不停有人发给我Deepseek的文章其实当时就是还有一个硅谷的媒体叫Semi Analysis他们就写了一篇文章就说V2是他们见过的现在最好的质量最高的开源模型的文章那个时候大概2024年的七八月份有一轮然后V3我印象中最开始是像Android Capacity他们几个意见领袖在推特上说这个模型很棒然后开始把V3带火的之后股市的英伟达的价格跌其实是在R1出来之后的几天我其实是在想这个市场它是怎么发生的为什么在这个模型出来差不多之后的一个多月才引发了股市上的连锁反应我还是感觉这个媒体的报道给大家的一个印象是说Deep Seek它用了很少的钱做出这样的大模型就好像是说OpenAI你烧了这么多钱然后它做得跟你一样对对对对第二个印象是说其实我觉得整个market是emotional的就是很多人他可能过来会问我这样的问题就说Deep Seek是不是不用英美达的最好的芯片但是我说它背后的资方是换方对吧那我们又知道换方实际上它是算力的一个大佬这个也可能报道也会对于不了解患方的人来讲的话对心理上会造成一定的冲击所以我认为首先训练所花的总共的研发的成本是不低的第二个事情是我认为如果没有搞错的话就是也确实用到了英伟达最好的一类芯片那么从这样的两点出发来讲的话我其实觉得市场是没有必要因此而恐慌对吧就是说英伟达的芯片不再被需要了随便出来一个小的团队就可以花几百万美金来挑战OpenAI了如果公众是这样的印象造成这样的恐慌的话我觉得是没有必要的我其实是想问一下John就是因为你是做GPU的就是你觉得R1出来对英伟达它到底是利好还是利空就为什么它的股价会跌这应该是把双刃剑就是有利好也有利空利好这边就很明显了就是deep seek出来其实它是给了人们很多的想象空间以前很多人都已经放弃做这种AI model什么现在它其实是属于给了大家很多信心让更多的这个初创出来可以去试探更多的这种Application的应用层面的一些possibility那如果有更多人做APP的话那其实这是英伟达最希望看到的一个局面就是AI整个行业被盘活那大家都需要买更多的卡所以这样子的话其实看起来是对英伟达更好的那更差的这一面呢就是英伟达的溢价确实是受到了一些冲击但是这里头可能很多人刚开始是以为它的壁垒被冲倒了所以一下就跌了特别多但其实我感觉也不是说壁垒被冲倒了没有那么严重壁垒是什么就是英伟达它其实是有两个最大的壁垒一个是它的Infiniband芯片互联然后另一个是Cuda就是它那整个一套调用GPU的这个系统就是它跟AMD这些其他芯片公司其实已经不是在一个层面在竞争的因为其他的人都是在争就是我单张卡我的性能怎么样但是英伟达其实争的是我互联的这个技术怎么样然后我的软件调用软件ecosystem的这个维持是怎么样的所以英伟达真正是这两个壁垒这两个壁垒Deep Seek其实都有稍微冲击到它的溢价但并没有把它的溢价给冲垮就是怎么冲到它的溢价呢刚才一位说它那个MOE做的优化其实是有一点削弱英伟达互联的这一块的一个重要性它现在其实可以说就是我不同的expert放在不同卡上我之间的互联可以做的不是有那么重要而且有一些doorman的一些expert不用的时候他就休息了这其实对英伟达的互联这一块的需求是有一点冲击另一块就是对Cuda这一块它其实是告诉大家现在有这么一种可能以前大家都没有觉得它可以绕过Cuda现在就说我们这个团队其实是可以绕过Cuda直接去用PTX然后做一些optimization当然这不是说以后所有团队都有这个能力去做这件事情但它至少提供了一种可能性就是现在你有可能做这个事情了有可能做这个事情以后就导致我有可能不需要买尹伟达的卡或者我不需要买尹伟达最先进的这个卡或者我可以用更小一点的英伟达的卡去跑这个事情以后就导致我有可能不需要买尹伟达的卡,或者我不需要买尹伟达最先进的这个卡,或者我可以用更小一点的尹伟达的卡去跑这个模型。什么叫做绕过Kuda,它是真的绕过Kuda了吗?就是我听到一种说法是说,其实它用的不是那个Kuda比较高层的API,但是它还是用了Kuda比较底层的这些API。对,用词不太准确,就是没有完全绕过Kuda的这个ecosystem,就是它可以直接去调用Kuda底下,就不是刚刚你说的那个很高层那个API它可以直接去调用PTX就是在这个instruction set的上头一层的这个instruction set然后它在这一层直接做一些优化但是这个也是挺大的一个工程它并不是说任何一个小公司都有能力去做这件事情对 那如果DeepSeek它有这种能力了业界其他公司会有这种能力吗就比如说如果大家现在假设我买不到英伟达的GPU我用AMD的GPU去做那因为AMD跟英伟达就是你刚刚讲的两个核心壁垒一个是NV-Link还有一个是CUDA如果这两个都有某种程度上受到冲击的话你觉得现在对AMD这样的公司它会是一个利好吗我觉得短期来说对AMD是一个利好因为AMD我记着它最近已经宣布它把Deep Seek给弄过去了但是长期来看也不好说吧长期来看我觉得可能还是因为的因为这毕竟只是Deep Seek这一个模型CUDA厉害的地方在于它是一个通用的这种GPU调用的一个软件系统就是你什么软件过来都可以用Cuda但是Deep Seek这种做法是它只支持Deep Seek所以你后头有别的模型你还要再重新适配一次那我们就是在读就是以后是不是Deep Seek就真的是Gold Standard了Deep Seek就真的是这个OpenAI了所有的这个初创都在Deep Seek上建那如果是这样的话那对MD挺好的因为它已经移植过去了Deep Seek但如果后面不是Deep Seek就比如说Deep Seek其实它的伟大也是在于它对Reinforcement LearningGRPO啊这些方法的一些改进那后面的更多模型如果都是用这种方法你有可能来日方长不一定是Deep Seek它如果再是别的模型的话那别的模型它又要重新适配那就还是挺麻烦的还不如用Cuda所以你的核心观点是它动摇了就是英伟达的这两大非常厉害的NVLink跟Cuda那从GPU的需求上来看呢首先我没觉得它动摇了这两个壁垒我觉得这两个壁垒还是非常坚挺的壁垒只是它对这个溢价有一些冲击就是你有可能收不了那么高的价格了但是也并不代表其他的竞品能突然就进来就是它是一个非常漫长的过程就是其他竞品做的跟这两个壁垒不太一样就是你可以就像我刚刚说的你针对这一个模型你可以绕过这个东西但是没有人做出就是英伟达Cuda那种就是通用的我全都可以绕过所以在这个上面其实是没有冲到英伟达的壁垒只是Deep Seek提供了一个就比如有个墙现在有一个人大家以前都觉得翻不过这个墙现在这个人跳过去了然后说你看我可以跳过去你们也有可能跳过来但如果这个人开圆了大家开始用它的模型了但是不行了就是只能它跳过去不是说就是它跳过去了别人现在也都能跳过去这就是这件事情它为什么冲击了溢价但是没有打倒闭的就这个墙没有变低但是这个人现在告诉大家它可以过去了它说It's possible to go over那你们其他人能不能过来呢我只是提供了一个精神上的一个鼓励就是说这件事情是有可能的对GPU的需求会减少吗因为他们这次训练成本低所以某种程度上把这个股市的跌也理解成是不是大家需要更少的GPU就可以训练出更好的模型了对如果就是训练这一个模型的话那是这样但是Deep Seek出来真正的伟大的意义是在于它重新激发了做AI这些人的热情那这么来看的话应该是会有更多的公司出来他们会买更多的芯片所以这件事情有可能是溢价降低销售量变大这么一个事情所以那它最后市值是变大还是变小你就看你中间的这个比例是怎么样你自己的观点呢这个不好说吧这个还是得看Application就是25年大家能玩出来什么花样如果之前觉得Application出不来的一大阻力是GPU价格的话那应该英伟达它的市值会涨就等于现在这个价格变成十分之一甚至更低了那这个阻力就不在了但如果它的阻力是别的的话那就不好说了所以其实就是越多的AI应用出来Deepseek把这个门槛降得越多从GPU的需求上来说整体上是对英伟达更利好的对因为Application出来的这些人他不会自己雇一个团队去把Deep C干这些事干一遍他绕过Cuda去搞什么PTX他出来的会是一些很小的这种公司他只是想要开箱就可以用的这种Solution所以这样子的话还是英伟达所以英伟达应该最想看到的局面是更多的AI公司出来更多的AI公司出来他们需要的是吹模型的GPU还是更多的推理芯片我其实个人感觉推理芯片后面也会是英伟达我不觉得这些小公司长期有一些优势它短期肯定是大家都有优势如果一直是用DeepSeek的话那确实是有一些但是长期我觉得推理可能也是英伟达训练也是英伟达为什么推理是英伟达就是因为它还是Cuda然后它还是这个行业的龙头刚才说那两个壁垒其实也没有动摇这些ASIC公司主要的是两个问题一个是软件支持不够另一个是硬件其实是没有壁垒的就像我们看一些GrocCerebras这种公司他们其实是一个大的Wafer上头然后做这种芯片当然其实就是在硬件上看来它只是一个CudaCore和TensorCore之间的一个比例它并不是说我在某项上做到了英伟达做不到的一个东西你比如说TPUTPU它其实100%都是TensorCore但是你说英伟达要想做100%TensorCore它做不了吗也不是它只是觉得100%都是TensorCore没有这个市场所以他如果觉得就是我哪天想做Grog这个比例我觉得英伟达要做那个没有什么难度就是他其实硬件上我只要没有看到很强硬的壁垒大家其实基本有点趋同的趋势然后软件上是他另一个大的问题就这些ASIC的这种公司软件的维护其实做的都不是特别好就是连做到PTX那一层的维护都不是特别好就连TPUTPU用的也是英伟达的PTX对吧它的instruction set所以这两个就导致了可能英伟达还是一直占有龙头地位推理芯片对软件的要求也同样高吗我其实是在想这样一个问题就是比如说在整个GPU跟训练的这个芯片上英伟达有绝对的垄断地位是因为它的整个的软件你是离不开或者很难绕过这一套系统的但是推理上它方便绕过去吗推理所对软件要求也很高你还是要去调用底下的GPU的一些底层的instruction所以像Grokt他们不是说自己性能很好吗但是他的软件侧其实还是没有建起来对Grokt的软件侧比英伟达软件侧还是差得非常远所以你看他们现在做的模式其实越来越重他刚开始就做个芯片现在他又做了自己数据中心然后又做了自己的云他就等于把这一套Vertical全部在站着但他资金跟英伟达比可是差得很远他凭什么能做得更好那你觉得现在市场上有非常值得关注的芯片公司吗我觉得AMD有一定可能吧但是其他的ASIC我觉得可能还差一些但是就看AMD来说应该跟英伟达还是有很长一段距离如果从投资创业这一块来看你觉得有公司在芯片未来的推理策它是能成的吗我个人感觉就是如果要在芯片这块创新可能更多聚焦在芯片的软件这一块的维护可能会好一些而不是去在硬件上做一些比如DDR啊TensorCoreCUDA Core这支援比例的一些调配我觉得这块其实没有什么意义的你等于只是在帮英伟达当一个打头兵去看一下就这个比例有没有人要但是其实你建立不了什么壁垒但是软件这块其实是有挺大的优化空间就是你要做出一套比CUDA更优的一个软件可能这块会有很大机会但也不是一件很简单的事情中国的公司有机会吗华为所有人都有机会对我是在想这样的一个问题就是因为美国对中国有芯片禁运那他们其实也更有动力去在底层上去做一些研发包括在软件侧去做一些研发因为你刚刚提到了其实芯片侧它的研发硬件上大家都有一种趋同的趋势那如果在这样的一种高压的环境下比如说有一些公司像华为他们也财大其粗对不对他也可以在软件侧去做一些重的投入然后把这个生态给逼成了那华为是有可能的如果中国的话它硬件上还是需要做出一些进步的硬件还是有门槛的对因为中国连生产芯片的这一块都被制裁了它不是说英伟达一家在制裁它它是从高速内存到芯片的组装到Kalvest Packaging到底下台积电这块生产芯片到ASML卖给它光刻机它是整条产业链全部在制裁中国所以中国如果要出芯片像华为那它不仅是一个软件的问题它是整个制造的这一条链全部要搞出来然后再把软件搞出来懂了解释的非常清晰这次其实Deep Seek出来以后我其实反而觉得对英伟达这样的公司是一个利好之前的话大家有一个想法Transformer出来了以后这七年之内Transformer的这个架构它没有变化那么如果以后一直是这样的话那么对于英伟达来讲是一个非常不利的消息因为你像Kuda它最擅长的一点就是说它是通用性它支持很多不同的架构然后所以在模型架构快速改进的时候这个是对英伟达是最好的假设一旦说我们从某一天开始所有的模型的架构不再变了那你就可以想象那是不是我就可以做ASIC了对吧那我就可以专门优化这个Transformer Tension的这个Mechanism等等的但是恰恰是比如说像DeepSIC他用到了MOE他用到了Layton的这种Multihead的Tension这些对Layer进行改进对这种计算进行改进了以后又回到了一个诶 模型又要改进了对吧这个对于英伟达来讲是一个利好可能会对OpenAI来讲不是非常利好因为像Sam他自己也出来说了如果你能找到比Transformer更好的这个架构那我们很多的investment都会in trouble我觉得eventually这个架构还是会变你像DeepSeek这次出来以后它在推这些架构的改变包括之前从M&OE出来以后推这种架构的改变这可能对于OpenAI这样的公司来讲的话是一个冲击对因为我注意到其实大家这次说DeepSeek和R1做得特别好的是推理能力能不能给我们普通不懂技术的听众普及一下什么叫做推理能力就是为什么推理是很重要的那如果不是推理它的另一端是什么推理的话其实就可以认为是我要做一个复杂的任务我直接无法输出这个的结果所以我可能要中间有一些草稿纸可能要做一些计算依赖这些中间的过程我可能输出结果也可能要做更多的计算所以基本上就可以认为不管是推理也好不管是plan也好还有 reasoning也好都需要刚才我说的这样的一种能力就是说我现在要解决一个问题或者说我看到一件事情它发生了我想知道它为什么会发生然后你要往前倒在我的定义里我管这个叫做 reasoning就是反向的去思考可不可以用现实的生活举一些例子比如说数学是推理代码是推理吗代码的话其实取决这个任务的复杂性它是否需要中间步凡是需要中间步过程我认为都属于一种推理的过程不需要中间部的任务有哪些能不能举几个例子方便大家理解咱们就以这种Language Model Agent的一个方式来举个例子对吧就是比如说今天的天气怎么样那么这个任务的话就相当于是一个非常直观的一个问题对吧就是说我现在想知道天气是什么呀然后这个语言模型它可以直接调用天气的这个API把天气给我拿过来这个任务就结束了它就不算推理对不算推理但是以下这个任务就算是推理比如说我现在在加州在Palo Alto我现在要去纽约能否给我找一个最快的一条路线那么你这个时候你会发现有几种路线可能是坐这几班飞机这么着可以过来然后也可以是说我可以先开车到附近的一个机场然后再去达成这样一班飞机对吧有不同的这种选择那它就需要一些中间部调用API也好自己的一些思考也好在里面对所以发展大模型最核心的是发展他们的推理能力吗或者说一个大模型我们去判断它的一些核心的能力有哪几部分是特别重要的我觉得发展大模型在我看来有几个非常重要的任务不光是这种推理和planning为什么大家对推理和对规划的能力非常的重视因为很多听众可能都听过一个就是有一篇非常著名的文章是Rich Sutton写的叫做The Bitter Lesson然后我觉得这个写得非常非常好就是他在2019年写这篇文章每年都会让所有的同学全部重新读一遍这个文章就是Do not try to be too smart这里边他提到两种最general的能力来自于一种是学习一种是搜索实际上是学习的过程你大模型之前比如说在这种无监督学习也好他的funtuning就是后面的监督的funtuning也好他其实你可以认为规划到学习这个方面那么现在说的这种推理和规划的能力实际上它是一种搜索的能力所以这两种它都反复出现DeepMind的比如它冲在前面其实是它很侧重的是后面的搜索的这个能力对吧它如果做这种Alpha Zero啊什么的做这些AlphaGo啊它做了很多这样的工作那么这两种结合起来显然是应该结合的然后这次DeepSeek R1它也做的是说是先通过自我的启发式的搜索然后再通过学习用这样一个Rawbase的方法其实把这两种能力结合起来那么我觉得这是很重要的但是在发展大模型的过程之中我其实觉得还有一个至关重要的点我认为如果你想通往AGI的话是不可能绕过去的一个点不管是说我们做大模型的各种各样training实际上最终我们希望能让它实现类人的智能那么不管说我希望它能够做问答也好我能够预测未来也好然后可以去做coding也好或者说去做这种推理和规划的能力其实都是希望能赋予它人这样的智能但是人有一个非常非常的强的能力就是人的学习的效率极其至高有两种估算我觉得都是有一定道理的第一种估算是babylm的里边的一个估算是到人的13岁之前你所接收的token还是word小于100million第二种估算是说假设从人出生开始每秒钟你可以take in30个token大概是10个词你每天12个小时20年这个最多是10个billion的token那么这两个数放在这然后我们说LAMA3它的pre-training其实已经到了15个training了所以你看我们的大模型实际上现在一直在follow的一个思路是说我们要scale就是更大的模型更多的数据更多的计算然后让我们的模型更强这个没有任何问题但是呢你会发现它比人所拥有的数据的数量级已经开始大的三个四个数量级那么这个时候可能我们会要反问一个问题为什么人可以以如此高效的方式来学习我认为推理和逻辑还有规划的能力可能是构成这样一个高效性的原因之一可能还有因果呀等等的一些其他的原因然后我认为发展大模型的过程中如何实现这样的高效也是非常重要的所以现在大模型跟人脑相比它的学习效率还是低很多就是至少从数据上来看低很多几个数量级的方式低这个非常像当年的蒸汽机刚一开始出来我记得我看过一个数就是早年有一个估算说它的这个能量的效率是0.02%那到今天可能是有20%对吧刚好也差了三个数量级所以我觉得什么时候我们对数据的燃烧的效率可以提高三个数量级这是当年我跟Yang讨论他启发我的一个问题我们有一次在吃午饭的时候聊到这个问题什么时候我们觉得数据的我们的燃烧效率可以提高三个数量级的时候可能这种general intelligence或者human level intelligence就可能更加可能一些了但是在此之前呢我认为只有scaling可能是不够的对 我跟大家解释一下于北刚刚提到的Yang是指Yang Lequin他的中文名字是杨立坤他是于北的博士后导师也是图灵奖得主跟Jofre Hinton和Yoshua Banjo一起被称作是深度学习三巨头他同时也是Meta的首席科学家待会儿呢我们会有一部分专门去讨论AGI呀那个时候我们可以详细展开聊一下他的思想那在此之前我们先把Deepseek的这一部分聊完我们先说一下开源你们觉得Deepseek他选择开源的这条路他对行业的生态具体会有哪些的影响就比如说我知道最近可能在美国的一个论坛Reddit上大家很多已经开始去部署Deepseek的模型了然后其实我很想知道他选了开源以后这个开源到底是怎么去反补他让他能把模型做得更好的对 最近我们其实也部署了一些Deepseek的模型在我们平台上面我觉得他开源其实是一件对整个AI行业非常好的一个事情因为去年下半年以后大家会感觉有一点失落因为AI application看起来都起不来起不来的有一大原因就是很多人觉得OpenAI其实把所有application的壁垒基本都能打掉了个百分之八九十大家其实都是比较惶恐的就是我做一个什么东西然后明年是不是OpenAI出个什么O4什么就把我的东西全部带了那我如果做这个东西建立在OpenAI上的话那就更麻烦对吧我建立在OpenAI上它出了一个新的模型把我的application完全包含进去了那我在价格上也没法跟他争我在功能上没法跟他争那这就导致很多人其实就压手对吧他就不太敢去做然后VC也不太敢进来那我觉得这次Deepseek它开源其实对整个行业的一个好处就等于就是大家都有了自己的OpenAI我其实就是作为一个小的这个application developer我不再害怕OpenAI出下一版本把我淹没或者把我淹到我没法跟他竞争或者我的产品就干脆再用他的API然后我就直接就死了我现在用的是一个开源的做非常好的一个模型这样的话我其实有一定的这种continuity我就有更大的更多的信心去做更多的applicationDeepseek如果它再能有能力去超过OpenAI的话这个事情我觉得对整个行业就更好了就等于说是有一条恶龙现在它不存在了大家其实发展的就能更好一些更多人用它其实它就跟Lama的逻辑是一样的更多人用然后有更多反馈所以它的模型能做得更好那Deep Seek它其实也是这样如果有更多的Application Developer大家都觉得用这个等于自己拥有的自己的OpenAI那它收集数据的速度肯定是比其他的model都快很多对现在我们能看到一个开源的模型它在整个的性能上已经跟OpenAI的O1我们说可以说超过或者说接近但是基本上是同一量级的对不对那可以预期OpenAI它很快发了O3 mini之后呢开源模型可能也会升级也会有下一个版本再来超过这些避原模型就是我是在想当一个开源模型它的性能足够好的时候OpenAI就是这些避原模型它存在的意义是什么因为大家就直接可以拿到这个开源模型的底座去用了Deepseek的意义在于它的价格降了很多它是开源的它跟OpenAI最前沿的这些模型差不多好它不是说比OpenAI已经好了那确实就是说它后来这个避原模型还有什么意义呢意义就在于它可能还会是领先的一个其实就像苹果和安卓对吧苹果其实还是比安卓好的就是Leadership跟Concentrate它更有可能做出更好的产品但是开源的意义可能就在于它就像安卓一样就谁都可以用然后非常便宜那这样它降低了进入行业的门槛所以TAS可能才是真正让这个行业蓬勃的一个因素然后这些B元的模型它有可能是一直领先的B元如果还不如开源那可能就没有意义但它应该是有management上面的这个优势它应该是超过开源那现在看起来确实是有一批币员不如开源的那就自求多福如果币员还不如开源的我也不知道这公司在干什么你还不如免费好我觉得开源的生态是非常重要的因为我除了在实验室以外我之前参与一家公司叫AZIP也做很多的全站的这种AI应用然后你会发现一件事情是说很多这种开源的模型你直接是无法使用的就是产品节的东西你无法直接使用这些开源的模型但是如果有这样的开源的模型可能会大大提高你生产出一个这种产品级的模型的大大提高你的效率所以你像Deepseek也好Lama也好我觉得这种开源的这种生态对于整个的community来讲是至关重要的一件事情因为它降低了所有的AI应用准入门槛那其实见到更多的AI的应用它有更多的触及这件事情是对于每一个做AI的人是一个非常利好的一个消息你其实不希望就是我们做大量的training但实际上real life里面真正能用的AI的application非常非常少对吧第二是它定价定得非常非常的高这样的话对于整个的生态是非常不健康的一种状态所以我认为meta在做的这件事情很重要对吧就是它这个LAMA一直在兼职open source构建这样让所有的AI的开发者都可以做自己的应用对吧虽然LAMA并没有把这个应用直接给你做完它给你提供了一个foundationfoundation顾名思义它其实就是一个地板对吧你可以在这个地板之上你可以构建你所想要构建的这种应用但是呢它其实把90%的任务给你做好了我认为更好的这样的Foundation其实对于整个生态是非常非常重要的OpenAI它下大功夫来优化的一些能力的话它依然会有这样的优势但是我们也不希望这个市场上只有OpenAI那对于所有的人来讲可能都是一个不利的一个消息还有一个问题是DeepSeek他们是怎么把API接口的价格给降下来的因为我看了一下它的R1官网写的是每百万输入的token缓存命中的是一块钱然后缓存未命中的是四块钱然后每百万输出的token是16块钱然后O1的价格我整体算了一下差不多每个档位都是他们的26到27倍之高它是怎么把这个API的成本给降下来的它等于是从上到下做了整个的一套优化从PTX这块怎么调用底下的GPU到MOE的架构的Low Balance整个的它都做了一套优化然后我觉得这里面可能最重要的一点就是它可以降低了对芯片的要求就是你本来可能非得在H100上A100上跑然后你现在可能可以用稍微低端一些或者你甚至可以用Groc你可以用国内的那些严格版的H800或者H20这些卡去跑那这样它其实就已经大幅度的降低了每个Token的成本然后它里头如果再做优化比如切割GPUVirtualized GPU这方面的东西它其实可以降起来很多而且OpenAI内部其实也说不定人家早都降下来它只是不想降Retail的价格这也不确定我觉得主要就是这两个吧一个是架构上一个是芯片可以降级了那芯片降级未来会成为全行业一个比较普遍的事情吗我觉得也不会因为英伟达的老芯片全都停产所以市面上其实有限的就比如你虽然可以说我这个能在V100上跑但是V100早就停产了而且每年它要折旧所以你可能过两年市面上就没有V100因为它只会产最新的芯片那它的成本还是低的吗如果你在新的芯片上做一些优化比如像我们做这种切割GPU那就有可能会变低因为它这模型变小了嘛就我们最近跑它那个7B的模型其实就是20个G左右那我们就拿一张H100把它切了三分之一然后就跑这个Deep Seek那你成本直接就降了三分之一呗可能我觉得后来会是更多的虚拟化GPU来降低成本因为如果只是基于老卡和游戏卡的话首先游戏卡英伟达是blackless你不能用游戏卡去正规的host这些模型然后你用老卡就是刚刚说的老卡停产而且老卡有很多维护这些问题所以我并不觉得它会成为一个主流的现象所以其实现在你们是提供给大家去做芯片优化然后来去节省成本的这样的一个工作的那你最近客户应该是暴增你觉得这个是受益于Deep Seek还是说你们一直在做这件事情我们从去年开始就在搞这件事情我们也是一直在赌后面会有更多的小模型然后刚好Deep Seek出来以后Deep Seek刚才说就是有带来的一个趋势也是它会蒸馏出更多的小模型那大家如果跑更多小模型的话其实就需要不同型号的芯片如果每次都去用物理芯片的话可能是比较难弄的刚刚其实我们有提到Deep Seek它让它的整个的API成本降低了你刚刚也分析过它的这个研究方法就它的这套研究方法未来你觉得它们有可能会用到更多的比如说你们在做GPU的分片跟客户的一些模型中就是它的这个研究方法会不会带来整个行业的一次大家对GPU成本更低的一次节省你就说它reinforcement learning的那些方法吗对应该是吧就它这个出来了应该是给行业证明了现在有更优的RL的一个方法我觉得后面肯定会有很多人用相同的方法去做这个事情而且尤其是他自己去调用Cuda这一块以前可能没有人有勇气去试这件事情当然他们证明了就我们这么几个博士生毕业也可以很快弄一个绕过你们Cuda那后面可能很多的这种模型公司都会去效仿那这样的话应该是大家都这么搞的话成本肯定会下降所以我理解训练成本降低了推理成本也大幅地下降了对所以你们现在帮客户去部署这种GPU的时候客户的主要需求是什么简单便捷很快地部署上来价格弹性价格低这个价格低指的是前面部署的还是说整个后面的一套的解决方案就是所有地方价格低它都是开心的但是我们只能解决它部署这一块的这个成本其实是有很多浪费的所以我们在做这个技术就是比如拿一张A100H100它都是80个G但你要蒸留出来一些小模型或者就是你就用现有的什么SnowflakeDatabreaks那种模型那也就是个10个G有的还更小那其实你在80G上部署一个10G的东西你就等于大部分的GPU全部浪费了但是你还是要付整个GPU的钱就假如你用H100你其实是想用它的那个速度你想要它那个4纳米那个速度所以你还是要整张卡租然后你在Inference的时候你的Workload其实是一个弹性的就是有时候你客户就增了很多有时候就减少了那如果你一张卡上浪费了很多的Space的话你括的时候你其实每张卡上都浪费了那么多那现在我们在做的这个事情就等于说是我把它虚拟化了以后你就完全没有浪费就能够比较简单粗暴地解决了很多GPU部署成本的问题这个领域其实还有一个有意思的方向就是说在过去的六到八个月吧我觉得这种小模型的能力进展非常之快这带来将来一个变革就是说我之前一开始说到了全世界有99%的算力是对大家不可见的大家不会觉得一个ARM的芯片一个高通的芯片里面它有这个AI的能力那么未来的话如果有大量的这种小语言模型然后有各种各样的这种VLM有Audio Intelligence等等的这些能力可能会越来越多的出现在曾经不会被用到的这种平台上那现在特斯拉车上已经用到了很多但是越来越多的时候你会发现手机里耳机里眼镜里眼镜里这个也是一个火爆的一个单品现在出来很多眼镜的公司但越来越多的这些设备里边你会出来这种on device的AI他们对于降低成本提高AI的可用性我其实觉得未来是有巨大的机会的小模型好用吗小模型其实在很多的领域有很多的基本的应用你可以发现当你把小模型给到足够的吹进以后呢它其实最终和大模型的性能其实差不多说一个具体的应用场景就比如说咱们现在正在录制这个节目咱们用到这个话筒话筒里面会有降噪的这些功能然后你这个降噪的功能你可以做出来极限小的neural network这实际网络它其实可以就放在话筒里面你把模型放大10倍放大100倍然后你会发现他们的性能差不太多就是最后的这SNR其实没有太大的变化那这个时候你就可以把它放到这里边了以后所有的话筒里面都会跑一个AI的模型然后它已经把降噪的这个东西做完了所以越来越多这样的功能会集成进来比如说小语言模型我们可以放到一个手表上那它可以做一些基本的问答调用API完成一些基本的工作那更复杂的一些工作它其实可以offload到语言上面做这样的一个层次化的一个智能对吧但是它其实很多的这种平台上一个手表上它已经能做非常复杂的这种推理了而且你在手机上像高通的芯片其实它的这种推理的能力可以达到50T Ops它其实是一个非常大的一个算力没有比A100差多少所以很多小模型它其实是可以胜任很多大模型已经在做的事情然后这个对于降成本提高AI的触及程度是有很大的帮助的小模型是本地的还是联网的本地的所以我理解未来我们整个世界里面可能会有各种各样的小模型当这个小模型不够用的时候它再去调动这种大模型这样就可以极大的节省这一部分的推理成本对 我觉得就是未来的AI的infra应该是一个层次化的它最小的可以到端上面就是在传感器里边就做一些非常普通的问题在边上也会有更多的AI的功能然后到云上 对吧端边云 我认为它未来是一个整体之前我说过一个数字如果你做一个简单的计算的话你把全世界刚才我说的端上和边上的这个算力你乘一下你会发现是全世界HPC里边的GPU的算力的100倍那这个是非常可怕的一件事因为它的量太大了高性能GPU可能是以百万片的级别在出但是你像手机像边上的这种端上的它都可能是以10个Billion就是这种100亿的这种量级或者手机比如说是10亿这种级别然后到Sensor的话它又会大那么一两个收像机当它的Volume上去以后它的加起来的算力实际上是超大的芯片够用吗比如说高通的芯片它可以做很多很复杂的功能就是说从小语言模型一直到visual language model到audio的ASR什么的很多的功能都胜任了所以其实对于这些我管它叫做初级的AI的功能不管是agentic的还是perception的对吧就感知的很多我认为在这种edge platform和endpoint身上都是可以完成的最后呢最复杂的一部分任务会交到云上面来然后第二个事情是你会发现全世界其实99%到90%的数据其实也在端和边上但是现在大部分的情况是use it or lose it就比如你不可能把camera的所有的这些video全都传上来所以如果你有AI的function在端和边上你可能会能够把最有用的数据传上来这个其实是价值是巨大的所以其实现在的这些数据都是没有被unlock的然后在未来的话当你的AI的触及程度变得多了以后你可以认为初级的AI模型反而是可以充当大模型的一种数据压缩这样的一个角色对 然后现在大家部署的是Deep Seek的小模型吗还是Lama的其实可能都不是它一个整个生态然后有Q1的然后有Lama的有Deep Seek现在出来的一些模型也有很多字眼的所以我觉得整个生态里面其实只能说是越来越多的这样的小模型在涌现而且它们的能力在快速提高选模型看中的关键点是什么首先它必须得快对吧 得小这是它的效率的问题但是除此之外它必须得足够好因为没人会为一个小快但不好用的模型买单的所以就是说你一定要保证它所处理的任务它能够胜任这个我认为是叫做鲁棒性就是AI的鲁棒性这个很重要我们就说一个话筒降噪你放到这里了那它必须得能够保证我的一个音质它不能最后出来的很粗糙那我是不会用它的那我可能还是要用后期的处理软件我理解了所以其实我觉得在应用端的话大家看的并不是说最前眼的模型是什么而是说最适合我的模型是什么就是哪一个模型它能保证比如说我在话筒里面加一个降噪功能它最后出来的兼顾音质跟降噪它能调整到一个最优水平然后在这个情况下选成本最低的就可以了是的对那最后我们再来讨论一下AGI的问题我看最近Answerpick的CEO跟创始人Dario Amaday他自己在他的文章里面他也是说了这个人工智能发展的三大动力曲线第一个就是Scanning Law然后这个我们就不解释了然后第二个大概就是说在人工智能发展的过程中通过比如说算法的改进然后芯片上的改进各种各样的方法它可以让你的训练的效率跟数量级再去提升一个比如说每年四倍或者十倍的速度第三个呢它就是说整个的训练范式其实也在改变比如说从2020年到2023年整个业界它用的方法就是预训练大模型的方式但是其实在2024年几乎所有的公司都意识到了大家要在预训练的这个模型上加入强化学习这个思维练的方式去训练但是大家在这个步骤上其实花的钱不够多就比如说以前从这个十万到一百万美元那如果我把这些步骤比如说拉到1亿美元会怎么样通过这三个方式他是觉得整个人工智能的发展按照现在的速度算它会是指数级的增长然后他的智能也会指数级的提升所以他有一个结论非常震惊我他就说大概在2026年到2027年他觉得AI会在任何行业任何场景下比绝大部分的人会聪明他用的是almost这个词almost我觉得应该99%他做这样一个预测就是2026年2027年这样一个预测我认为还是非常有勇气的你觉得没有那么快就是如果你说五年以后的话我认为可能是更稳妥一点因为五年以后的事情谁都不知道怎么回事但是如果你说是明年的事因为现在是2025年了如果说你明年在各行各业都要超越大部分的人或者是我再多给一年2027年我认为这是有挑战的单个任务呢比如说写代码写代码其实是提高效率但是你说超越人我觉得不是这样的就是很多你会发现这些低级别的任务确实很繁琐它确实可以加速但是人工智能它真正用在应用里的开发还远远不够因为你如果这么去想一下这个全世界的算力它主要是应用在训练上还是应用在推理上以前可能主要的都是应用在训练上随着这种大模型的能力变强随着AI的开发成本下降所以他这个AI的应用上的所用到的算力其实已经提高了很多了对我觉得替代人可能是他是一个应用层面的事情但我觉得从他的角度来说因为他其实自己是一个大模型公司的创始人我想他说的应该是指模型能达到的这个智力水平对如果不解决学习的Efficiency的这个问题的话我其实觉得大模型的智力水平的话是无法跟人真的放在一个级别上的OK对所以你觉得达到样说的这个efficiency它大概需要多久比如说三个数量级对就是我们当时讨论的时候这个三个数量级后来我们就简单我做了一个这样的一个计算我其实觉得这个还有非常大的不可预测性因为这里面需要基础研究现在我们当前的人工智能跟人所能达到的能力或者自然natural intelligence和artificial intelligence它们之间的一个efficiency效率差距我认为不管从功耗从模型尺寸从学习所需要的数据都差至少三个数量级跟人相比对功耗的话你可以想人的这个大脑其实非常efficient它在运转的时候你在醒的时候它的功耗大概相当于一个20瓦那么同样的话你可以想象我如果要是有一个600个billion parameter这样的一个模型的话你就可以想象大概我需要多少张卡呢大概是需要16张卡这个样子大概对应的是一个2万瓦的一个量级那么你看20瓦和2万瓦差了三个数量级人呢假设咱们在20岁之前只能access不超过10个billion token那么LAMA的这个训练的数据量也是15个trillion那么15个trillion和10个billion的话那优时刚好是大概三个数量起这个样子第三个例子你说如果你看自然界的这些小动物你看像Jumping Spider它可以做非常复杂的三维的navigation这样的模型在我们现在自动驾驶里面所做的这些navigation的模型的话基本上是billion级别的parameter而你看Jumping Spider它只有几百万个神经元刚好又是三个数量级所以我觉得自然的Natural Intelligence和Artificial Intelligence它存在这样至少一个三个数量级的Efficiency的差距如何Unlock这个差距或者Bridge这个Gap我觉得需要基础研究现在整个大模型的进步让你看到了这个希望吗我觉得大模型的进步其实并没有看到这个希望但是大模型之外像这种Resening Planning或者是Neurosymbolic的Representation这种逻辑推理也好然后像这种Search也好像因果Causality也好我觉得这个似乎都在正确的路上而且这种Data的Curation这个Data的迭代就是人其实是非常擅长的做一件事情是说我学一个东西然后我找到哪里学习最有效然后我Focus上学习这些东西对吧我要搭桥等等原则上来讲的话如果机器能有这样的能力自我去提升我认为这个就像人相似了但是目前呢很多的时候你的机器的提升是来自于人来给你准备数据所以就是Human in the loop对吧然后他还给你做更好的Curation什么时候这个过程能够基本自动化模型他自己给他一个Internet他上去自己提升自己能够Make every token count的话那我认为这样的话可能距离人的智能就更加接近了所以你是觉得整个基础研究已经走在了正确的路上类似于类人智能的这些基础研究基本上在全面开环我觉得是有很多这样的比较有意思的研究但是呢基础研究它虽然我们的发展速度一直在加快但是基础研究本身有一种不可预测性有可能明天有个小神童什么的就找出来一种就unlock的这个密码然后大家都happy的这个问题solve掉了它是计算机领域的研究还是人脑领域的研究我觉得它其实是在数学计算机和人脑工程几个的一个交叉的一个进展当然目前的话工程占主导地位就是在工程上面你可能尝试很多这样的想法就是更快主要是工程上的我认为在这件事情工程上面走的在最近的实验都走的比其他领域都要快一点因为主要是你可以做实验嘛不管你怎么想你最后可以有更高效的实验效率因为数据上话你要证明证明的话其实有的时候这个数据太复杂了你无法证明对吧所以计算机或者说工程in general它close这个loop更方便一些嗯对这样你对Dariel的观点有什么想法吗我觉得这说的差不多吧我只要觉得他说完全能超过人这里头最大的一个瓶颈可能在于domain knowledge比如像我创业这么多年你要说一个机器能超过我创业的经验这我觉得可能比较难因为我创业经验只有我自己知道我也没有把这些东西数字化了在不同的行业里头大家都会有自己的经验在增加自己在某项工作中的一些wisdom他们是不是把他们所有知道的东西全都数据化了呢而且把这些数字化的这些数据都给到了某一个模型我觉得这个可能是比较大的一个工程所以就基于这点我觉得机器超越人可能没有那么快我觉得应该不会是这两年的事情吧主要我觉得就是一个数据的一个壁垒所以你觉得现在数据会是整个大模型训练中遇到的一个达到AGI的一个核心的门槛吗我认为还是模型自我提升的能力就还不到数据的能力我认为是它如果自己去提升人在学习的过程中其实你是不断地在寻找学习的信号然后自己去做一些思考的很多的这些思考都是内化的可能不是外界来的这个token不是说我们外界的整个世界的数据不够了所以我学不好这学不好还是我自己的问题然后还有第二点是说人就是你如果看专家的学习他其实是一代人比一代人更强的第一代人他我要反复尝试这尝试有点像是一个搜索的一个过程比如我有天在野外蹦蹦蹦蹦蹦蹦到一个地方然后跳出来一个蘑菇然后我可能会把这个记录下来它就变成了后人的一个knowledge所以人其实学习的高效性很多的时候也不是说因为我探索的高效性而是说我把之前学习最重要的一些knowledge记下来然后后面所有的人的学习效率都提高了不管是围棋也好音乐也好对吧每一代人他们探索出来的一些新的技术它会被记录下来后面的人就会用上这种高效的学习方法之前有一本写的非常好的书叫做Peak就是讲如何做专注的这种学习我其实觉得大模型可能来训练之前的大模型然后做出更好的数据然后再提升自己然后训练出来下一代的大模型也可能这会变成一个趋势但是说到底我认为还是要解决那个efficiency的问题就是说我们如何用少量的token获得那么强的泛化能力我觉得这个是一个圣杯问题之一啊现在业界有哪些流派最近其实争议挺多的我看Yan他之前就是你的博士生导师Yan Loquen他一直是不太认同纯强化学习的方式的Antheropic其实他们在Solid 3.5之后它一直还没有特别好的一个推理模型出来嘛但是比如说OpenAI-01的这个推理模型的思路包括这次DeepSeek放出来的R1的这个思路我觉得其实在业界在2024年可能也是一个就是稍微标准一点的做法了当然样态也有不同的看法所以我是在想在整个大模型的这个训练的范式的转变上你觉得业界现在还是一个争议很多大家有完全不一样的思路跟方法还是慢慢的就像你刚刚说的你就没有创新了大家都是皈依了我觉得有很多创新只不过说当你把很多的capital bring进来以后你说我要快速scale大家scaling的方式有点让我看起来感觉好多的时候是有点单调的创新的点其实还是有很多的我其实觉得Yang一直在推动的叫做世界模型这个世界模型其实当时是因为我们看了David Hart的那个文章叫World Model我觉得概念上没什么新的但是名字很酷一个polished的名字而不是说几十年前就有的这个概念然后我们就后来就adopt了这样的一个名字那在我看来这个定义其实超级简单世界模型其实就做的一件事情就是说给定当前的状态给定当前的action就是你的行为预测未来当然你能预测的越好就越好但只不过说大家有不同的侧重这个是一个非常重要的概念我觉得世界模型是一定应该发展的举个例子就是你刚刚定义的那三步能举一个具体的例子吗什么是世界模型一个具体的例子其实GPT你可以认为和世界模型相当像就是generative pre-training它里边有一个就是说给定之前的context过去的token就是所有的词然后预测下一个互联网上的各种数据对 我预测下一个这里面和世界模型唯一的区别就是世界模型有的actionaction是什么action就是比如向前走 向后走向左走 向右走有一篇deep mind非常好的文章叫做Genie2它里面就是说给我任何一幅画我可以变成这个幅画里的主人公我可以向前走 向后走然后就可以在这个世界里穿梭了GPT其实可以认为是一个没有action的一个world model它就做一件事就是给定之前你给我说的话我预测未来那么世界模型更general一点的形式就是给定之前发生的事情给定我接下来要take的一个行为预测未来世界模型当你的模型非常好的时候你就可以用它来做 reasoning和planning比如举一个具体的例子我们最近做的一个工作就是实现了这样的一个事情就是说如果我可以穿一个非常好的一个world model那么我们接下来可以完全的用这个world model来学习一个task几乎就是说你不需要再看现实世界了因为你已经创造了一个现实世界的一个copy了所以你这个时候可以在一些任务上你可以搭载上任何的一个强化学习的方法然后你把现实世界换掉你就用这个世界模型来做然后你就可以达到一个很高的performance当你的模型进化到一定程度的时候你能准确到一定程度你就具有了这样的能力就是说我可以在自我的空间里边来提高自己的一些行为甚至你可能不用强化学你直接可以用model predicted control你直接把它搜出来你就直接把这一条比较好的轨迹搜出来就是像我刚才说的当你的基础base模型已经好到一定程度的时候你生成100条已经能找到一些比较好的信号了然后你可以在对它进行强化以后让它在这个方面提高了很多了以后直接出来但假设你的模型已经好到一定程度的时候你生成这100条里面必然有一条是正确的那你不用再学东西了你直接可以搜出来了所以我觉得样子他所坚持的就是说这种世界模型我认为是一个非常重要的方向只不过这里面也有不同流派有人可能focus在生成有人希望能学到更高级别的感知然后有些可能强调空间的intelligence对吧有不同的这种声音我其实觉得这样是一个好事情大家还是有很多的不同的方式跟方法去达到我们说AGI也好对我觉得还是有很丰富的想法的在这一点上对因为现在关于DeepSeek他们很多的信息都已经公开出来了因为他们也是一个开源模型就是想问一下你们对DeepSeek有没有什么样的问题就是你们对这家公司还非常好奇的有问题啊那因为他这个文章里面具体的数据的composition这个在文章里面并没有写出来然后以及他去年的很多的细节也没有写出来只是大概层面上当然我认为不应该全部都公开出来对吧这个不合理但是如果有更多的细节讲出来能够让大家更好的去复现这样的工作可能是更好的就是你希望它的数据能写得更细对 但是这也是一个趋势所有的这些Frontier Research Lab都有这样同样的趋势就是说到数据这个地方也非常含糊有些事情就没有办法连OpenAI都不敢写就是所有的大模型公司问到数据都是他们不敢答的对 然后甚至你的连数据是如何balance的Curation的这个process是具体怎么做的这些都是不写的我可以说不写它具体组成但是我依然可以写它具体是如何curate等等的但这些细节好多的时候大家也都不写所以我其实觉得这些东西反而是最关键的其他的一些你说我用search的方法来做这个 reasoning planning这其实很容易想到当你的模型足够好的时候它的bootstrap的方法也可以提高性的这也很容易想到对吧小模型无法直接bootstrap用大模型直接bootstrap出来位给小模型这个也很容易想到所以真正不好想到的这些东西反而一个是数据的具体的composition然后还有呢就是说在这种architecture里边的一些底层的创新我觉得觉得可能这些东西是最关键的对所以整体上来说还是想从Deepseek上学到更多的东西对John我可能没有什么问题吧但是我可能比较关注的就是Deepseek这家公司它能不能持续地push the envelope它能不能持续地跟OpenAI去挑战它如果它后面能不断地给我们惊喜让我们看到大家可能最后做application都是在Deepseek上那这个对整个的芯片Infra这块的格局确实是有比较大的改变会是什么改变就我刚说因为Deep Seek它已经绕过Cuda去适配很多东西了嘛所以如果它能继续站住这个位置的话那可能很多其他芯片都有一定的机会对英伟达本身的这个生态也会有一定的挑战然后溢价是肯定要打下来但如果下一个就比如说Lama 4出来假如是比Deep Seek好很多的话那可能以前又回到Scratchboard回到刚开始好的谢谢宇北谢谢John好谢谢当然我们今天的播客有从算力算法还有整个大模型的演化来去聊Deep Seek那它对数据的影响是怎么样的呢如果大家对听到更多的采访感兴趣我们也考虑会将一些精华的内容放在硅谷101的视频号上当然我相信我们的很多听众也是AI领域的专家如果大家对于Deep Seek有什么样的想法或者想了解的欢迎给我们写评论写留言那这就是我们今天的节目大家可以通过小宇宙苹果播客Spotify还有YouTube上搜索硅谷101来关注我们我是红军感谢大家的收听再次祝大家新年快乐
