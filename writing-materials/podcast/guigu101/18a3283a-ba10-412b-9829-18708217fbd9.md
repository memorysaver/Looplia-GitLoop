---
id: 18a3283a-ba10-412b-9829-18708217fbd9
source_type: podcast
source_key: guigu101
title: "E170｜大模型应用之困与异军突起的“埃森哲们”"
url: https://sv101.fireside.fm/177
published: 2024-10-24T00:00:00+00:00
downloaded_at: 2025-11-28T07:16:01.244128+00:00
---

# E170｜大模型应用之困与异军突起的“埃森哲们”

欢迎收听硅谷101我是洪君今天跟我在一起的两位嘉宾一位是华印资本的合伙人Jonathan Cho嗨Jo 你好听众朋友大家好对 还有一位是Agent QL的创始人Kiss Jai哈喽 翟老师你好嗨 洪君你好谢谢 邀请因为今天其实我们主要想聊一下大模型方向的应用就大概一直在提应用应用但是投资人是怎么看这个市场的包括创业者最终在这个市场里面好不好拿融资好不好做商业化待会我们可以具体地讨论一下Kase你要不要跟我们介绍一下AgentQL它是做什么的对 AgentQL的话它其实我们是一种标底层的一个语言了但其实核心的话就是可以把所有的网页和所有的Document很容易地变成Structured Data就结构化数据抓完结构化数据的话你可以去来做分析做商业分析也好或者是做其他各种各样的东西也好这个是一个非常简洁的一种方式因为过去抓数据其实是一个非常复杂的一个过程了但是我们是把一个网页和文件都以一种语义的方式来结构这样的一种东西对其实说到生成是AI的这几年我们整个播客聊它的时间还比较早大概从2022年就是ChairGPT还没有发布开始是扩散模型的时候就文生图的时候已经在报道它了经过这几年其实我觉得我自己的心态上也一直是在发生改变的大家最开始说在整个的这个市场里面最大的应用就是ChatGPT对吧其实我是前几天看到这个Notebook LM出来我觉得它其实是比ChatGPT要更惊艳我的因为我是做播客的但是这个产品我们具体也放到之后我们可以再聊那在之前的时候我也想听一听大家在投资跟创业的过程中跟随AI这波浪潮你们在心态上的一些改变Kiss你应该是这一轮中才开始自己的创业的对我们是从去年下半年开始的吧这改变的东西实在太多了因为整个这个行业实在是太早了其实像红军你们聊的时候这个事儿其实更早嘛但是整个这一波AI的话对于绝大多数公司来说应该是在ChatchPT3.0前后吧很多人开始往这方面去看的在此之前的话就比如说上一代嘛现在大家会说上一代的AI和现在的AI在很多人眼里是完全不同的两种东西了归根到底它是一个非常年轻的小娃娃可能就才两个月大这样的一个小娃娃所以一切东西实在是太新了而对一个小娃娃来说它这个是日新月异的每天都在成长就比如说当时我们刚刚开始的时候那个时候其实连agent这个词都没有也就是中文讲的AI智能体这个词当时是没有的因为以前一说什么是agent呢那你按照中文的这样一个转换过来的一个理解那就是007就什么邦德对吧FBI这才是agent那别的agent其实是没有这个概念的后来那我们刚开始的时候其实也不知道这叫什么但是后来的话才慢慢发现哦这个市场开始慢慢有了一个定义叫agent那这个时候已经有这个定义之后OK这时候又发现一个问题下一个演化呢就是说当大家都在谈论agent的时候大家在谈论什么因为最开始当出现agent的时候大家说我们见面都会聊agent agent但是其实什么是agent呢这些东西是完全不一样的我说的agent和你说的agent可能咱们在讨论用一个词但其实讲的是完全不同的两个东西你可能说的是一个chatbot就是一个聊天机器人我可能讲的是一个动作的一个范式的动作模型后台的一个自动抓取对或者是一个工作流程的一个自动化所以说这就是很像村上春树啊什么就当我在跑步的时候你在想就是没有人知道你在说什么这个其实就是当一个很多的事物啊在它一个非常早期的时候的我认为是一个很明显的体现对Kaze如果听过我们博客的同学可能对你之前聊到的一期爆款节目就是我们讲东南亚诈骗的还非常有印象啊对那个时候你的身份还是华尔街日报的记者这一次其实你是以一个AI创业者的身份来继续参与我们的节目就是我很想知道当时你在选择AI这个赛道来创业的时候你是怎么想的然后当时市场是什么样的然后我们对比今天的这样的一个市场就是你觉得这中间不管是心态上还是融资还是大家对这个行业的认知上最大的变化是什么当时的话其实肯定有很多原因了因为我之前那份工作做了将近20年的时间应该做的还OK的但是离开的话其实肯定有很多的原因在里面但是我感觉其中一个让我跟本期话题可能是最接近的一个原因吧是当时我记得我问了一个不错的朋友他也是一个非常成功的国内某一家很大型上市公司的一个创始人之一因为当时我是想开始做了然后我跟很多人去聊这个事情聊AI大家怎么看我记得当时呢印象很清楚我们是坐在一个酒吧里他刚开始跟我讲他说Keith这是一个范式的革命paradigm shift什么是paradigm shift呢就是像电器像这样的一个不是一个行业的改变它带来是整个社会的一场改变这样的一种革命他说当你认为这个是一场范式革命的时候你不需要去想你要做什么你需要做的是进去开始做这就是为什么我最开始当时的一个最主要的决定点之一因为我自己作为一个知识的获取者或者知识的产出者我自己过去这些年用过好多好多的其他的语言模型类的就上一代的AI我用过好多好多产品但这些产品在我看来根本还是距离我自己写作都是没有办法去比的就差得非常远但是当我最开始用GPT3的时候就我自己心里的一个震撼应该是一个非常强烈的那我随着推移我能看到它是这样的一个范式的革命那在这个时候我是非常同意的那这时候干嘛呢你先跳进去先扑愣扑愣在里面再说吧基本是这样的一条逻辑对那现在的感受呢现在的感受当然就一直在里面扑愣着了作为创业那不就一直在里面铺愣着吗就是一直就是我们去年开始到今年上半年一直在stealth这个隐身模式中文可能是就是到这样的一个时候反正我们刚做完A轮但是整个过程中从来没有感觉一天是在上岸的一直在水里铺愣着因为像你刚才讲的黄金整个这个行业整个时代变化的实在是太快了跟过去不是一个量级的改变过去的这个十年来说和现在的话它在范式革命过程中因为尤其涉及到AI它对效率是一个根本性的一个调整那在这样的一个环境下它这更新换代整个迭代是非常快的对我来说在过去的一年多的时间里适用这样的一个快速的更新换代其实对创业的人来说可能就要不断地在水里去铺腾可能过去你做完A轮可能你会感觉是不是上岸了但现在的话甭说做完A轮了我们看到多少公司做得更大了融了更多钱的上百个million的这样的一些公司大家最后也都不行了所以上岸是一个很难去拿融资的阶段来界定的事情对 其实在我来看我觉得你们的融资已经是非常顺利了也很快是 我感觉是这样的但是还是距离上岸就是最终感觉是不一样的对 就在里面一直在水里扑通着对 对那我们现场正好有一位投资人John你会怎么看因为其实我知道你最开始是学人工智能的然后你一直都在这个领域也在这个领域做投资包括看项目你觉得当时GiGPT出来跟现在你再去看整个生成式AI引领的投资浪潮你觉得这几年最大的一些变化是什么首先我们从GiGPT刚开始出来到现在其实并没有核心的转变因为我们投资的最后都是以商业化为目的对吧其实我们其实都是以应用为导向的但是有一个小的转变就是我可能自己开始思考是不是纯用的在今天会有一定的风险所以它其实需要一定的整合这个是我现在的一个思考就XP自己它其实也是个叫垂直整合的应用它虽然是个应用但是它是有很强的一个底层能力因为刚才刚好也说到agent其实agent其实也是刚好是在整个技术站里面非常重要的一块刚才宏女也介绍了我其实最早我是学AI其实就是我世上是agent的方向所以我补充一下agent的其实在90年代就有了当时的agent是指什么其实是一样的一模一样就是叫智能体对我是叫multi-agent collaboration方向说的更完整一些就是叫多智能体协作这么一个人工智能的一个分支就人工智能其实有多个分支包括深度学那时候不叫深度学叫机器学习神经网络这个agent自然语言处理机器视觉其实都是人工智能的研究方向我当时南加大的PhD方向我们选了其中一个当时我没有选机器学习和神经网络但后来发现机器学习加神经网络深度学习就形成了深度学习深度学习其实是后来发现是整个的一个driver所以跟那个时候比那个时候agent跟今天的相比其实它一个核心的区别就在于说现在都是在围绕深度学习这个是我一直在总结的一个事情就是说从第一波我们叫机器视觉包括无人驾驶包括脸部识别就中国有四小龙五小龙开始到今天的大模型其实都是围绕着深度学习展开的所以在深度学习的这个范畴之内其实我们现在对应用的要求事实上会比原来要高原来我们就是有种说法就是分成两派就是看应用的或者看模型的其实这两派事实上是一致的就是我们其实两部都一定会看就底座模型存应用但是在看的过程当中我们就意识到一个事情就是说应用其实并没有大爆发然后它导致了模型其实也在面临一个挑战就底座模型因为上层应用不爆发我就变得说我的商业模式似乎就没有完全体现出来我作为一个平台我必须我上面的生态然后都能够很大规模的在各个垂直场里落地我作为一个平台的价值才体现出来了但是现在GPT为什么所以它其实它自己现在真正用的最多的反而还是它自己的这几个应用它其实Power的这些东西事实上现在还没有看到一个特别清晰的所以这个可能算是一个转变就是回到空军安装的问题其实我们是至少我自己是会更多的看一些能够从纯应用的角度跨越出去的这样的一种应用这种应用跟以前的互联网应用确实不太一样在互联网的这个时代里面是有纯运用的它可以不用考虑太多的底层架构的这些因为我的底层平台比如说浏览器比如说网络协议其实都是已经ready了就是established我在上面所以我具备很强的产品能力互联网产品经理我就能够做出一个很好的产品运用最早的时候是一个网页后来变成一个APP它是能够在这个上面很快地扑下去的但在AI年代其实跟互联网是有一些不同的或者说它加了一个维度就同样它也是一个产品它必须有产品的形态但是同时它有一条我称之为叫数据线就回到刚才叫深度学习因为我们现在都是围绕深度学习的深度学习其实一个最重要的基本点包括我们现在今天的agent跟当年的agent很不同的一个点就是现在所有的都是需要数据驱动数据定义的所以我们在我刚才说的相当于有一个叫产品但在产品这条线这是个互联网的一个角色但是我们在产品这条线的平行的还会有一条数据这条线所以我必须得问我自己我做这个事情即便我是个应用公司纯应用公司我有没有真正的数据这个在以前是会说但是没有那么的变成个前置了相当于是一个不是可有可无的这个说你对这个问题的回答很可能是你的一个生死回答我是不是真的有数据然后我最后我的数据是怎么用的对吧现在很多人做RAG也好做微调也好我是怎么样真的能把数据最后能够融合到我最后的这么一个垂直模型里面真正然后再跟我的产品合在一起所以现在相当于是有两条线所以互联网产品这条线还再加上AI的数据这条线所以比当年的互联网创业其实在应用侧是门槛多了一层所以现在的难度事实上是加大了对我觉得我们可以一层一层的往下去深抛啊就是产品跟数据线但是在此之前我注意到刚刚两位其实你们都有提到一个观点就是觉得他离大爆发或者像Kiss的表述就是说离上岸还很早嘛也就是说其实我们现在界定这些应用它是不是真的对我们有帮助这个可能是存在争议的而且这种你记不记得之前其实我们有一次在咖啡馆聊天你有问我用着怎么样我其实自己的感受就是我现在还很难用ChatGBT让他帮我去写采访提纲去写show notes因为他问出的问题不够好他整理的show notes我觉得跟我们所要求的他达到的一个水准还差很多你觉得这个是跟AI的能力有关系的吗是的这跟AI能力是有直接的关系所以我们看一个浪潮吧或者一个大的时代从我的观点我觉得至少有三块就刚才说的我们是叫底层能力这块是非常重要的对应互联网年代我们可以理解成就是当时因为我在硅谷第一份工作是思科嘛我从那个男家大毕业思科其实当时提供的就是这种底层能力互联网最核心的就是连接嘛其实就叫网络嘛它就是用网络协议对吧那时候叫TCPIP后台的路由器交换机把你连接在一起这个是最重要的但在今天的大模型或者人工智能时代最重要的其实还是我们把叫做涌线能力或者叫做是底座模型就是Foundation Model底座模型的这个能力这个能力其实还在迭代就你刚才说的这个层面其实还在这一块它的底座还没有完全就像当年思科可能就有点像我的协议都还没有完全的稳定就是你觉得基础设施还没有好就是我们即使看美国最先进的模型它的基础设施还是不够好还没有完全ready但事实上它已经很不错了实话说就是它已经能做很多工作了这是一块然后事实上今天还缺失的就是我刚才想说的有一块其实在基础设施之上其实还有一个东西叫做操作系统叫OS这个在今天其实是非常缺失的在今天大模型时代大模型时代的操作系统跟OS是什么呢应该怎么去对应呢首先OS的定义是什么就是OS跟基础设施的infrainfra的定义是什么infra更像是工具就你拿来可以实现就可以帮助你这就是今天你做的上面的这些应用developer他都可以用infra但是OS一个很重要的点就是说我可以把底层的细节跟上层的应用很充分的隔离开这样应用刚才说的你就可以就是个产品经理你就是一个应用场景垂直领域的一个专家你就可以来做事情了所以在互联网时代的OS其实就是浏览器所以在互联网时代一个叫Nescape Moment就在Nescape出现之前其实大家为什么并没有看到就Cisco其实比NescapeGap要早但Cisco那时候其实并不是很大Sysco真正大爆发其实真正也是浏览器出现之后因为浏览器出现之后在Sysco这个基础设施之上出现了一个操作系统操作系统出现之后才出现各种网页雅虎这些出现之后然后应用就开始爆发了应用爆发之后当然Sysco的价值一下子就体现出来了所以这个OS是非常重要的那大模型时代的OS应该是什么呢对 移动互联网时代是OS这两个都很好理解对现在就是难的难点就是在大模型时代人工智能时代很多人会觉得自己是个OS但是并没有比如OpenEye对吧OpenEye其实当时做了一个OS的尝试叫GPTS它觉得我自己是个OS它就是模仿iOS的做法然后我也充分地隔离了上下层在它看起来就下面是这个底座模型上面就是GPTS上各种应用甚至最早叫Plugin后来变成GPTS但是它的核心点就是说它的上层就是把应用层跟它的这个底座模型或者叫基础设施的这个中间的分界其实并没有那么清晰或者说如果你是按照它这个分界的话你的价值就变得很低了谁的价值变得很低了就是应用层的价值变得很低了你看很容易你被底座就给覆盖掉了是的因为你回到互联网时代或者iOS的首先比如你在上面做个雅虎你跟浏览器是没有任何冲突的是没有任何的重叠的对吧浏览器做浏览器的事情你做个雅虎.com你是提供内容提供流量提供用户运营提供商业化这个是你雅虎做的事情但是浏览器不做这个事情所以你两面是非常分割的就是它这个分界线是很清晰的这个叫上下层的这个捷偶是非常清晰的到iOS时代也是一样你做的是微信上的APP是微信和比如说Uber吧你跟iOS是完全不一样的你一听就知道iOS跟微信是没有什么可以交叉的点但在今天你看你基本上所有的所谓的GPS上的应用跟GPS本身都是会有一定的重叠的事实上是有相当大的重叠的我们应该提到那个notebook ARM对吧它其实跟GPT的功能GPT其实很多时候也能实现这些功能像在之前那个JASPERJASPER跟GPT的功能就是或者说你今天在GPS就非常清晰了GPS上所有的这些功能其实它很多是做了一层产品上的一个我们有时候叫壳但是GPT其实很多时候是可以实现的而且它在迭代的过程当中它可能会实现越来越好而且你们的数据就是我作为应用层的数据跟底层的数据就底座吧就是Fondation ModelFondation Model的数据其实它的数据跟你的数据有时候长得其实是会非常像的还有一个这个分界不清晰的另外一个特点就是说我们可以从另外一个角度去看就是说今天你做了一个基于GBT的一个模型出来垂直模型然后你用这个垂直模型去回答你的客户的问题这个时候客户回答了一个问题得到一个答案这个时候你能不能清晰地判断这个答案后面支撑的这个能力是由底座提供的还是由你的这个应用提供的其实在很多情况下并不是那么清晰这个跟互联网是不一样的比如互联网就是说我在UberUber上你实现了Uber的功能但其实哪一块是iOS提供的哪一块是Uber本身提供的其实是非常清晰的网页和浏览器的区分也是非常清晰的但在今天它在训练阶段它的数据很多都在一起了其实我刚才说一切都可以从数据层面去考虑这个事情其实数据今天是看出来没有一个特别清晰的一个切分的点的对 我们待会可以仔细再讨论一下数据但是回应你刚刚讲述的这一部分其实有一点我是不太同意的比如说你提到了像Notebook LM它的那一部分它是不是一个跟GPT非常相似的这样的一个应用我觉得表面上来看很简单的回答是但是根本上又不是就是因为它的底座模型其实是谷歌的Gemini它之所以我说GPT其实就指Gemini属于这一类就是底座模型对对对也是因为这个产品让我最近两周对整个大模型的看法我在心态上发生了很多的改变因为这个产品我发现比如说我把我的播客的一个链接放进去然后它最后可以自动生成一段这个英文的播客它其实不是为了生成播客的简单来说这个产品你可以理解成你放常文本进去它可以给你一个summary的研究报告同时你可以去问它这个研究报告里面的各种细节它也会给你一些引导性的问题在这个层面上有一点像那个publicity就是有一点搜索式的它在给你回答的时候呢他也会引用他的这个回答是根据哪几段来整理出来的他的这个体验非常好之所以能生成Podcast是因为他最近就新加了一个功能不知道是哪个天才工程师在Notebook LM的右边加了一个它叫做Audio Overview就是音频的总结但是他非常聪明地把这个音频的总结做成了一个播客的形式所以就是他现在是可以一个链接或者一个长文本就自动生成一个播客了我觉得就是你说语气语调很好交互非常自然我觉得这可能是有很多工程上可以调的问题但是我觉得这个产品最让我惊艳的部分是它抓点的能力非常强就翟老师我们之前都做记者其实一个好的记者他要非常会抓这个问题的关键点要会抓细节同时要会抓关键的案例就是我觉得它在这一点上是比我们招到的一些记者的平均水准是要高的但是对你说它的分析逻辑怎么样就不讨论但是整体上我觉得这个产品就我前面说了那么多它其实都有一个非常大的特色就是Gemini这个底层的模型它的长文本的处理能力其实在这次今年的Google I.O.上他们有着重地强调这件事情它是做得非常好的它可能是比OpenAI的底座模型要好的所以其实我就在想就像你刚刚说的你说这个应用到底是应用本身的能力还是这个应用底层的模型的能力它确实就是分界不清对这个就是我说的可以说是个特点但是在我现在看来其实也是在制约现在这个生态的一个问题就是说这个分界不清晰我们讲这个例子的时候不是在讨论GPT是讨论GeminiGemini跟Notebook RM就是一个底座跟上层应用的一个其实就刚才说它的这个功能比如它生成了这么一个音频的SAMRI你说这个功能这个里面一定有很多是底座在做的底座在实现的其实Notebook RM当然技术细节我们没有去但是我们从外面看就刚才你说的这些功能其实回到我刚才说的这两条线一个肯定是产品设计线就是我们之前说因为它的实质还是个互联网产品就产品设计线这个一定是它的一个特点詹姆来也可以做这个事情但是它跟用户这个交互的这种流畅性这个是互联网经理产品经理们做的这个最强项的一点很多其实是高于这些底座模型的这些团队的所以这点它一定做得很好它跟用户的交互所以让你会觉得很流畅很好用对吧也很耐用这个是它的第一条线第二条线然后它肯定是要做一些RAGREG做些检索增强生成这些功能所以这就是我说的数据线它会用数据线去增强底座的这个能力但现在的问题就是说所以我回到我刚才的这个核心点它是一个AI的应用它不是个纯数量的应用所以产品那条线是不能足以支撑它的长久的当然这个它有点特殊性因为它就是Google内部的一个但是我们如果假定它是一个外部的产品就是现在我有个外部公司也是对外融资的然后但是我就从一个第三方公司角度我去用JAMI的话所以你就觉得如果是第三方的公司来基于Gemini上面做这样一个应用的话它的核心竞争力就没有那么强核心竞争力就会比较有挑战的原因是说它长期的因为短期它可以就像这个Nobuco ARM一样借助它的产品能力和对于一些数据的处理能力就是刚才说可以做微调但长期还是要看底层模型的能力长期你再往下首先你的数据就回到我刚才的这个观点我的观点当然未必正确但是是我很重要的一个思考这个就是AI原生时代跟互联网时代的一个差别就是我一定要讲数据而且我数据是越多越好这个很多人其实同意的但是你用这个观点来看这个案例的时候你就会陷入这么一个就是说Notebook ARAM如果它是个独立公司它一定要不停地积累数据它数据会越来越多它数据多了以后我再怎么样再去跟底座去结合的时候我是继续可以用Fantune还是我继续用RAG其实都会有甚至我还有很多数据其实是更适合于预训练了其实如果我们在技术上看得深一点的话我们会知道其实不管是Fantune就是微调还是RAG其实都会跟底座有很大关系的你是需要很多底座的支持就是如果你越做越好的时候那这个时候你跟这个底座模型的就是我刚才说你其实是不太容易去解偶的你要这条路走得很长你的defensibility门槛 护身河要很高的话你是一定要去一种方法就是说你怎么样跟Zemulai做一个更深度的或者说你就要做一些自研的就会让自己去预训练一些底座某种预训练的方式去生成自己的一个底座去支撑自己的这个其实是我们可能看到很多包括像Propelcy这样的公司Propercy大家可能知道它其实是deep mind的背景对我们从各种渠道都听说他们其实是其实他们最开始肯定也是这条路就Propercy第一个产品很可能跟Node RM其实一样的它还是比较轻量的但它越来越重越来越重它也会去买显卡然后再去往pre-train就是一系列这条角度所以你的观点是所有的应用公司最后都会去拼自己的模型的这条路在今天的这个技术架构里面很不幸似乎是这么一条件但是就是说对于不同创业公司可以寻找不同的方向或者道路但是在今天的这个架构里面可能你没有太多其他的选择你只能先按照这个不然的话你总是要回答这个问题我需要把数据越来越多然后数据越来越多的时候我怎么样不断地维护我这个门槛同时推进因为你做个应用事实上你也是有这个责任是推进Scanning Law的这个是作为应用的一个很大的一个角色贾老师同意吗我感觉数据这个肯定是这样的我非常同意我感觉Johnson讲的这一点其实也是我们做数据这块的一个考虑了因为数据肯定是接下来的一个切入点数据的话你怎么去使用数据你得到的是什么样一个质量的数据就为什么说结构化的数据和就是你把整个网页随便抓下来的这个unstructured就非结构化的数据这些东西其实都会带来不同的产品甚至是但是你认为所有的应用最后开始都会卷到底做模型这儿吗我感觉主要现在是太早了说白了还是一个太早的时候就刚有互联网的时候没有各种的开发者工具什么都没有那这会儿中间这些层我理解张德森就这些层什么都没有其实说白了那接下来语言模型再往下发展那周围的这一套配套的设施因为互联网也不是一上来就把所有配套设施都建起来的也像你讲就是有了浏览器之后很多东西又开始往上再叠加所以他这个我个人的一个理解就说白了就现在太早了就跟那个苹果的这个App Store刚出来的时候应该大家也没几个人还能记得最开始那一批很火的这些application就那个应用都有什么了那其实那会儿应该是最早的时候第一代iPhone我记得那会儿最火的一个应用程序就是手电筒就我一下载之后就装个手电筒收我九毛九不收多少钱我也记不清了然后那会儿感觉哇这好了不起啊手机还能这么装一个东西就可以当手电筒用对吧都是各种现在回想起来都是特别又幼稚又傻的这些应用所以这东西就看怎么看了就是在当时的情况下不少的应用应该也都赚到了钱但是他们会不会都成长为像后来Uber像后来的Doordash等等这些非常成功或者是在某一些程度上非常伟大的公司呢它其实也没有所以说就看心态问题了或者说你把自己做的这个产品或者公司是放在一个什么样的时间语境下去看是放在一个风物长衣放眼凉的一个几十年为周期的语境来看你想做成一个伟大的公司还说我想赚个两百万我就跑了那这个应该是不同的一个逻辑来看这个事情的你们属于哪一种我们肯定是这个风物长衣放眼凉了对啊这肯定是这样的因为我们是数据总之也都是看第二种第一种叫utility对utility很多其实不属于我们看的范畴对对其实说到这个我其实还想问因为我们也在市场上看到了两种公司第一种比如说它就是一个应用它始终现在在Google Store或者App Store它的榜单的前十名但是呢这类应用它也不融资它可能就是靠用户付费它就能赚很多钱但是说实话就大模型一更新底座模型一更新甚至是大厂的一些手机升级它很可能就会覆盖掉这些应用但是他们可以赚一个短暂的钱而且还挺赚钱的这是一波对不对然后还有一类就是说我想去做基业长期的公司那可能就是投资人考虑的这一类所以我理解你刚刚说所有的应用都会做到底层模型其实你也是想说我们要抱着建立一家整个AI时代的独角兽的这样的一个想法去看待这些公司而不是说这个市场上哪些是赚钱的公司来去看待这样的公司的心态对 是这样对 我们刚刚其实反复在提到数据Jonathan我知道你对人工智能是有自己的定义的就是什么是人工智能你要不要跟大家讲一下你自己对什么是人工智能就是这个问题本质的理解以及为什么数据那么重要的一个逻辑对 可以在重点说一下这个理论其实人工智能的历史基本上跟整个计算机科学是差不多平起的1950年的时候有个达特茅斯会议从那时候人工智能就开始了所以刚才说的那些领域包括agent就是智能体包括像自然源处理我刚才说一系列的这些机器学习神经网络都基本从那时候就开始了但是我定义的人工智能其实是从2012年开始的就真正的我们把它叫做产业化的人工智能就是如果非产业化的人工智能其实我们不需要太去花时间因为它就是科研但是产业化的人工智能其实核心点我总结其实就是深度学习所以这个是我的一个很核心的一个但是跟我刚才说的数据是有关系的因为深度学习从2012年开始发生了一件什么事情呢就是2012之前所有的计算机科学包括那些所谓的传统人工智能的这些领域就我说的这些传统的agent传统的这些自然源处理它的核心点都是人来写算法有个说法叫人工智能有多智能人工智能有多智能背后就有多少人这个人工是什么呢这个人工就是我们马农对吧我是比较决定系的我可能从小学开始我就开始写代码了就是我们这帮马农在后面就是每一件事都得用代码去写但是2012年开始了其实第一个就是叫Alex Knight他做一件事就是把我刚才说的这两个传统的人工智能的领域一个叫机器学习一个叫神经网络这两个合在一起形成一个叫深度学习然后呢他的核心点就是说我现在不靠马龙这个一行一行人工的敲带马了我现在就是弄一大堆的数据当时要做很多标注然后我去用一个训练算法就那个时候AlexNet当那段时间就叫卷积神经网络那个是那一波罪然后呢你看数据这边就是李飞飞当时弄了一个叫ImageNet当然还有一个叫算力算力其实有个华人叫吴仁达其实他贡献最大因为他的算力第一次用了GPU所以这三个东西结合在一起算法就AlexNet然后数据当时有个ImageNet然后算力这三个加在一起可以称之为人工智能三要素但是加在一起就发生了一次大爆炸爆炸之后就把我们之前所有计算机科学包括人工智能所谓传统人工智能做的事情全都给颠覆掉了就是现在我不用写代码了我就出来一个叫做黑盒子就是一个模型但是这个黑盒子的效果反而比以前我们一行一行代码敲出来的白盒子的模型还要好还要精准错误率还更低唯一的就是它可能可指示性会差一些因为它是黑盒子这个是现在也研究了一个方向但是我们先不讨论这个这里面最核心的点就刚才说三要素三要素里面其实最核心的点就是数据就现在变成一个从2012年开始整个的这套浪潮变成一个我们可以称之为叫数据定义就是所有事情都是从数据开始那是第一波然后到了2020年左右把GBT3开始的时候它其实也是数据定义的也是第一次把我们以前人类积累下来这么多电子书也好Wikipedia Reddit知乎全都作为书记这样输进去往后训练出来一个这么大规模参数量的这么一个然后它实现的功能也比我们之前用一堆的所谓叫自然语言处理算法因为自然语言处理也是个人工只能领域传统自然语言处理的这些都被颠覆掉了都被这个大语言模型训练出来的这么一个大黑盒子把这些那么多的教授做自然语言处理的以前做的所有的这些成果都可以把它给超越了所以这个是核心点就是来流回回我们其实想说的一件事情就是说在今天我们已经完全不能绕开数据了就是在互联网时代我们在做创业做Uber的时候在做创业最早在做Yahoo的时候我们都知道数据其实是它的一个结果它是产生出来的因为我一旦有互联网的这个运营用户的这些行为之后我就会产生数据但是我在创业的那一天我可能不会想说我是不是只能拿到数据才能开始创业但在今天其实就要突破这个认知了就回到我刚才说的我们就有两条线了一方面我们把互联网产品要做好但一方面我们要把数据这条线要做得非常扎实什么样的数据是有用的这是个非常好的问题这其实就是整个人工智能浪潮里面不断地回答你的问题实际上它就实现skilling law的问题就是它在不断地寻找有用的数据就有用的数据其实要打引号就是它其实这个定义是在变化的你像在AlexNet出现之前我们世上是有大量的图片的但那时候是用不上的就是我用这些数据去训练我也不能去收敛为什么因为我的算法没有到就没有Alex Knight这样的训练算法出现就是我刚才说结合这种深度的曾经网络生成的集体学习的算法Transformer的主要贡献是什么对Transformer就是第二波了Transformer就是说它能把刚才说的这些语言的数据能够训练进去然后生成出来的这样的一个语言处理的模型的这个能力超过了我之前的所有的自然语言处理的这些算法所以其实Transformer它是替代自然语言的把传统的基于自然语言的这种RAW-Based的白核模型替换成了黑核模型它是产生了一个这样有益的算法它也是个算法它这个算法就是对于处理语言是最有能力的你可以这么理解但是传送文也至少经历两个阶段第一个阶段叫BERT它其实是一个encoder only的然后到了GBT是个decoder only的其实传送文也有两个阶段到了decoder only其实又打开了一层在BERT的这个阶段它其实Skinning Law也是到了一个瓶颈了其实我这些RedditWikipedia其实都有的但是在BERT这个技术路线的时候其实我这些数据也不是都有用的所以回到刚刚洪君说的其实有用数据这个词也是一个在动态的就是很多数据我们今天看到的实际上又是没用的所以数据永远是不会枯极的这是我的一个理论数据其实都在那只不过刚开始都用不上但是GPT出来以后就把所有这些Wikipedia都能用上电子书这是第一次之前也用不上CNN肯定是用不上这些数据的BIRT也用不上这些数不是用不上就是把它都灌进去之后训练出来的模型最后并不能完全收敛所以它是看你的算法怎么样就是数据是依赖于你背后的一整套的算法的算法来定义我需要什么样的数据跟这些数据需要什么样的标签打标签也很重要对不对对在语言里面你可以理解成它是一个自检督或者自标签因为语言等于是前后在互相标签自己图像可能更需要标签对图像是需要标签对对对但是现在Vision Transformer其实把图像也试图语言化就是把它也相量化也利用图像内部的这些语意去训练所以这是它的一个方向但是这也还是一个尝试这还是语言式现在是最容易去scale的它是最符合scaling law但是这个中间其实你看我刚才就提到包括像腾讯这些他们有很多这种数据其实现在很多数据并没有完全都能用上所以数据其实还是有很大的空间的有用数据的范畴和定义事实上还在扩展但这个扩展的过程就需要你对算法的一个更进一步的迭代对贾老师你觉得什么样算有用的数据你们正好是做数据抓取的对反正我刚刚听张德森讲我也在想就我是很同意数据和application这两层的因为人工智能嘛说白了就是和人要很接近嘛那这个是和之前的上一代AI是不一样的嘛那本代AI整个这个核心就跟人会很像他的写出来东西啊整个思维啊什么的你会模拟的非常像那你就想咱们人上网干什么咱们人上网用互联网用网页其实所有的所有的东西到最后就两件事第一件事是读第二件事就是写读是什么呢就是你从网上比如说你看信息听咱们鬼鬼101的播客看陈倩的视频所有这些东西其实就是一个事就是你在从上面摆数据抓取下来那你第二件事你要做什么呢就你有了这个信息之后有些人可能说那我要去做投资有些人可能说我要去trade某一只股票也好或者说买什么一个产品或者说我要去点一个buttonclick一个键这是什么呢这你就可以把它理解成一个应用层它其实就在写那数据这一块就是获取的一个过程这些大量的数据就像张晨说数据是在那里的但是对于很多它要是做vertical就是垂直领域的模型或者垂直领域应用的时候它其实这个数据是获取非常困难的因为这些所有的互联网上的沧海一般的数据打从有互联网那年开启这东西就是给咱人去用的所以当今天的机器去来学习它的时候其实是有好多限制的因为网上的每一个网站它都是一个护城河基本上比如有哪些限制它会反抓取还是怎么样就是反抓取是一个最基本的但是你想当一个机器去想获取某一个网页的信息也就是数据的时候才需要API它需要一个API call才能去获得这个网页上的数据OK那它没有这个API call的话就像你说的宏庆我要去做一个写一个script去抓取这个网页上的数据但这个script是最费人的写这个东西是一个非常累的然后你获取前端的就网页上的数据任何一个东西都是非常麻烦的一件事咱们可以不去讲技术性的问题但这些东西但凡做爬虫大家就说这是没人愿意干的活这是一个最脏最累的活互联网里面的脏活脏活累活并且是永远是cover不到所有的你永远干不完那这个就是现在在我看来就是对于很多垂直领域也好对于什么机器学习也好它是一个非常大的挑战所以这就回到了跟Jonathan说很多做的application的公司他们的其实数据差不多它没有什么更特别的一个数据跟这个大公司比因为现在大家获取的数据的方式是非常有限的是基于上一代的时候人们获取数据的方式来获取的这个是现在的一个很大的阻碍所以我们其实在解决的是这样一个问题对 这个非常同意从投资人角度Kiss做的这件事情我们其实都会放在这个叫Infra这个层面因为你们其实也会在support其他的这些应用公司其实因为我现在问所有的应用公司我这几个问题第一个就是你有没有数据第二点数据是怎么获取怎么抽取怎么清洗这其实每一步都是非常的昂贵复杂的你肯定要用大量的工具当然现在很多公司强一点比如OpenAI它是有一套数据站的团队它每一件事都是可能一个巨大的团队去做的大家都知道OpenAI可能随随便会获取最后整出了一套数据的成本都是在提议美金这么一个量级的成本这里面包括它的团队的开销和它的所有这些工具的开销对很多公司现在的话小公司商业化之所以很难是因为它没有什么一些特别的数据像刚才John Nelson讲的它很多的数据也都是同类的数据它顶多就是会从爬虫爬一些就是一大块的非结构化数据然后扔给这个语言模型然后剩下就还是做prompt来让语言模型把这东西做得更好技术含量实话讲都是很低的它的整个上面相当于它底下那个饺子我们包个饺子饺子馅儿全都是模型那上面的话我包个皮就是特薄那整个这个东西这皮其实没什么价值然后这个完全就馅拌的不好吃了但是馅有别人的你就包个皮这个价值是非常低的所以基本现在是这样一个情况当然就除非短期有一些做的比较好的短期商业化做的好的它解决的是个什么问题呢就是AI或者语言模型它解决的问题是生产效率的一个问题那这些现在短期内很多举个例子有点抽象语言模型解决的是生产效率它其实在现在阶段下它并没有取代所有人的能力但它是大大提高了人的生产力对所以说语言模型是在解决的是生产效率其实互联网的本质也是解决效率问题都是叫生产力工具就是这个意思但是呢现在大家呢很多做这个的嘛因为尤其是最开始你去拿语言模型做个东西哇这个一看就是做个demo尤其是都好牛啊感觉好了不起啊那大家就误会了就是有点把这个生产效率就误解成这就是全部其实不是全部的你人还是要解决的是价值问题AI没有办法解决你的这个价值问题就是所谓的产品在市场上的一个定位也好啊这个产品的价值在哪里这东西是人来定位的但是语言模型给人造成了一个幻觉让人以为说它可以取代所有的东西所以很多的产品它其实就是所以你觉得产品方向很重要这个产品到底是提升你的效率还是取代人这可能是根本上的两种产品你用语言模型的时候你可能在最开始的很长时间内你会认为它可以取代人这是语言模型给很多人造成的幻觉也就是像你还记得吗去年不前年有个很有名的事一个谷歌的工程师他当时还闹了很大一个事他认为是谷歌那个语言模型可以是个真人它在跟这个语言模型在沟通的时候产生了这样的一个认知说这是我在跟真人对话但那会儿还跟谷歌闹出了很多的纠纷所以说这个就语言模型在你最开始使用的时候你会认为它是万能的它可以解决好多好多你解决不了的问题然后你就把它看到的这个点你会把它以为是一个面然后把它推广到一个范式上你说这个都可以做其实不能的对你们觉得在这一轮的AI创业中有哪些公司是做得非常好的或者现在是非常赚钱的美国这边当然比较典型的像Proplexity这种其实是比较有希望其实它从某种程度最符合我刚才说的这个定义Proplexity它的底层是自己的模型还是它是建立在其他模型刚开始并不是所以我的总体定义是说有底座潜力和底座能力的应用公司因为它是demand的背景所以它是有这个思维的就是我从各种侧面渠道就知道创始人其实还是在跟各种做底座模型的人去做很多的深入的交流包括demand自身因为它本身就是这个背景所以他们是符合这个它可以有几个step它刚开始肯定也还是用就刚开始甚至就是套个壳我就有点像个GPTS的就是我直接用API call我做些RAG对吧RAG然后开始做微调但我想它是到了一个层面一定会自己做因为again它是要自己不断有自己的数据的叫Custom Data就是私有数据它一旦不断地要积累自己私有数据跟用户的这些所以它可以用这个数据再去做微调但是它同时它也应该把这些数据去生成自己的一个底座这是我的一个观点我其实比较好奇张老师就是那你看Proplexity它在做相当于一个检索那和Google比如说它要下场做同样的东西或者说Microsoft用下场做同样的东西比的话对 就是回到刚才那两条线我作为一个AI原生的一个应用公司其实我有两个角色第一个我是互联网产品就做得非常的好在这个层面其实很多创业公司甚至是大于这些模型公司对吧 或者大厂的因为你的视角不一样很多确实从产品介入刚开始可能我就是真的就套个壳但是我的应用性我的交互流畅性非常的好所以用户一下就上来了但这个是不表明你成功了就像最早Jasper这种它其实为什么当时比GPT用得好其实它还是产品设计确实会更优但是你现在就要思考问题你的护城河在哪里我最早跟那个大部分的GPTS其实我花了蛮多时间去聊这边的GPTS上的很多还算是比较成功的公司我发现他们都不太考虑私有数据有比较成功的公司吗应该是没有吧那个时候还是最火的时候就年初的时候你聊了哪些公司我就不具体说了当时我就是特别清晰地问这个问题说你有没有私有数据他首先他愣了很久然后他在说我为什么需要私有数据呢我们没有所有然后第二句话说那你会不会担忧你的护生核我当时直接问Defensibility他就说我的护生核就是我的产品设计这个在互联网年代是非常通用的一个思维为什么互联网的应用公司能够比大厂厉害其实很多时候是在产品层面它在产品设计上面它能够走这就是大家说的产品经历尤其是垂直领域的这些它肯定比做底座或者甚至大厂的人它都有这样的一个优先性但是你现在就要详细考虑你的护生核的问题了对在这个时候你就必须得去伸扎这个事情所以你觉得其实在大模型时代开始以产品切入可以但是如果你要找护生核的话你最终还是需要有自己的私有数据加上底层模型加上底层模型的能力底层模型的能力就是说你私有数据即便我一向的观点就是你即便只做RAG或者微调你对底层模型也是要有相当的熟悉度的最好是找底层模型的人对Propilicity有嘛他在做自己的低层慢的那这个可能是他的商业机密了但是我从侧面去了解但是这个我们后续可能可以去试图我们可以fact check一下我觉得他一定会再往底座去做当然这个他可以有多种方法你可以有开源底座去做一些这种继续训练你可以有不同的步骤就是因为你要从成本上考虑你当然一上来就全都重新训练但这个成本太高了但你可以做叫继续训继续训继续训但这个难度其实也是不低的但是可能比微调要更难一些但即便是微调微调和具体训训练有的时候它的中间的界限也开始在模糊就是它们的成本而且同时它有风险就是说你做不好可能效果并不一定好所以这个都是它的成本都要计算进去但大方向一定是往这走这就是你的护生核你要么就不要有数据就像我来说GPS那些人都不要有数据但很快GPS也都没有了就是你可能会有一段时间的商业化所以有的时候我们看商业化有时候也会有一定的误区它可能甚至一段时间用户好像也还不错甚至能够有一些收入但事实上它只要没有就底座的更新也能实现同样的功能要么就它自己不能够持续的迭代下去了但是我是在想以这种创业公司跟应用类的模型的迭代它怎么能卷得过你看像OpenAI这种动辄百亿美元融资的公司因为你做底层模型你是自己需要买卡然后需要自己去训练的那如果说一个模型它真的训练得越来越大它的智能真的涌现了这些创业公司他再去训练底层模型它的意义何在呢所以就是几种方法一种就是我刚才说你一个步骤一个步骤有点像baby step等于你的卡会越来越多但是可能你还是得不断的这个你可以理解这个skating law因为我数据越来越多了数据越来越多理论上我最后的成品的最后输出的这个模型的参数量或者知道它的能力吧参数量可能不一定是一个kpi但是我的能力一定是应该是越来越高的嘛但这个对于我刚才的三要素其实都得在里边我数据一定是越来越多我能力越来越强我对算力要求肯定也是越来越高这个你是避不开的这个你是可以通过步骤去实现的第二个就是说你聚焦就是你跟OpenAI的不同点包括跟国内所有比如这六家模型六小龙的不同点是说所有做底座模型的人都我刚才说的这么一个做平台的诉求所以他也在做应用的同时他在还是想说我要赋能所有的上层应用这样一下就把它给摊平了所以他对算力的这个要求因为他也要对所有的应用场景现在来了一个教育行的人找他来了一个制造业的人或者医疗行业的人他都得跟他去要能够service就是能够服务这些人这个是他跟你的最大的区别就是你能够放弃作为一个通用平台的诉求就聚焦在一个比如说就是AI搜索就是一个垂直的一个应用端到端的我把这件一件事情做好我整个底座模型的所有的每一件事情都是为了这个我不为了去赋能不是作为下一个IOS的这个心态出现的这个时候你其实你会简单很多这个在互联网时代其实是有这么一个时期的互联网在浏览器出现之前其实我们那个年纪的人都我们用很多叫FTP暴露年纪了没事继续对TileNet因为最早那时候没有网页其实那时候你有很多内容就比如我们在学校里有很多内容现在后来就是我就放在一个网页上你就能够访问了但那时候我们会放在FTP服务器上面但是FTP这个事情其实它是一个端到端的事情因为它下面没有像浏览器这么一个平台它其实挺难用的但是你做FTP的时候你肯定是前后都得去搭的这个就是我说的一个叫垂直整合的这么一个事情这个有点像当时的那个年代就有点像这个浏览器出现的这个时候所以你要做这么一个应用就是很遗憾你可能你门槛就得这么高但这也是你今天那个护生核它其实是一个相互的作用你没有这个门槛你也没有这护生核对 就还是约尔回到了数据上护生核还是你垂直领域的数据你的数据的优秀程度你的专业程度你的精砖程度约尔像大圆模型是个推土机那我其实就想凿个钉子难道我拿铲车推土机去凿它吗也可以也能弄进去但是何必呢其实我拿个小锤子绷一下就进去了那我就用小锤子不就得了吗是这么个概念对Kiss你有觉得比较好的案例包括是商业化方向的案例给大家分享吗我感觉商业化其实美国本土还蛮多的吧比如说现在有几个做coding的coding最近这几个月还是蛮火的一个嘛当然这个也涉及到它会有多大的护城河这个问题比如说Github要去做的话会怎么就是Github也有吗那这个东西它会到底怎么样还有一个特别火的那个coding的应用叫啥就是之前一直在排预约的Magic还是Cursor我就有一个那个就是那个见光死那个什么叫什么coding现在特别火大概有快十家多到十亿美金了应该非常多Augment Magic前段有一个挺火的之前做demo做的句号然后后来以正儿八经release出来然后就那是DevonDevon对Devon对对对Devon就是见光死的对就大模型时代见光死就demo最好看做完之后应用层你看完全用不了的东西太多了Coding也是我所说的这个分界不是那么清晰其实我也可以用GPT其实现在很多马龙就直接用GPT就已经帮他再编程了所以他就是我本来说你怎么去创造这么一个切分一个分界这个是所有做Coding应用的这些人的一个他很多时候产品肯定是做得很好的但是你要实现这个scaling law我Coding这个能力要不断的scale我也要用我的私有数据再去训练的时候我怎么去跟底座的这些人去竞争去做长期的竞争我现在的如果他们要问我我对他们的建议就是说你得拥有自己的底座如果你一直是用所有第三方的底座的话你的风险永远是大的就是说他一定也在不断的在训练你跟他要有一个division是你觉得还有其他方向吗其实他现在做的好很多可能也都是商业化做的比较好也就是说他对这个价值或者在这个方面上某一个点抓得比较准的像什么Harvey啊Legal的这样的一些东西它是一个处理法律方向的大模型对大模型应用应用对也不知道多好用或者多难用但是呢就能讲好故事这也是一个能力嘛如果要从一个真的一个大规模的应用角度来说其实就回到赵诺森讲的这个还是很遥远的了因为我自己总感觉的整个这个问题回到核心上还是太早整个拿新的一个生产效率改变的工具来解决什么问题这个应该是人来解决的而人现在还没有完全去因为这个工具长什么样怎么回事什么的很多东西还没有在摸索清楚前人们怎么用它其实是很多误会的大家是把生产工具很多人就当成了生产力比如说这个是一个比较范式我认为现在很多的一个情况对如果再补充一些就是我自己作为一个音频工作者我感受到的比较好的产品或者案例的话其实我刚刚有提到Notebook LM我觉得用它来做一个长文本的分析它还是一个蛮好用的应用的但是它其实是谷歌做的对它也不算是创业公司那另外有一家创业公司就是我自己非常喜欢的叫做Eleven Labs它是可以我输一段文字进去它有自己的一些英语的配音它可以把这个配音配得非常好或者是我的音频有时候我们说错了一些数据需要补录的时候它不用嘉宾现场到场补录它可以AI生成而且可能会比你们补的那个效果还要好是因为大家每次说话的生产环境不一样它的这个补录是比真人更加无衡的但是在整个的中文方面表现还不是特别好其实我觉得这个可能也是他自己的数据跟他的产品没有专门针对中文产品去做特别的优化按理说这其实不是一个特别难的事情但是他没有做特别的优化其实我看Eleven Labs这样的公司在融资市场上的表现也还是非常优秀的应该也快到了独角兽级别了还有像之前我们在节目中分享过的Suno文字生成音乐它是一个音乐模型其实它也是做了自己的模型层们我觉得至少是从融资策来看反正我们在聊完以后它也是过亿美元的估值然后也融了很多钱表现还是不错的这是我看到的一些戏份场景这两家都属于跨摩泰多摩泰多摩泰的这个产品我的印象或者我的预测它一定也是要往底座去延展我觉得他们其实是有底座的他们不仅仅是有底座而且其实他自己在这个声音的处理上他自己是有自己的独特优势在的对他是有一些paper的对 因为多摩泰反而不像语言模型因为语言模型已经有很好的第三方底座了你基本上就可以用它了但多摩泰很多时候你其实是要做因为如果你只用SD只用类似这种一些开源其实你像Me Journey肯定是有自己的底座的所以他们这些公司其实也倒过来要求他们的同时他也要有训练数据然后用自己的或者说半字眼的这样的底座去实现他的最后呈现的这个模型的功能我觉得这个其实可能是多摩泰从这个角度上多摩泰就更符合我刚才说的因为你没有一个可以利用的第三方的底座你反而是更会需要自己去做很多事情所以现在整个市场上会不会多模态的表现会更好一点对 这个也是我的一个预估当然它也是个双人件就它倒过来要求你要这么做所以很多人都会先就往这条路上去走这样你的护城河从第一天开始就是应该是有的而不是像在存语言模型里面你可以刚开始就没有护城河所以从能启动的角度来讲存语言模型可能更快一些我直接掉GPT我就能出来一个很好的产品了但是你要在多模态的领域你肯定是要先做出一些东西的所以它其实双生件但是我个人也其实也是比较看好多模态的这个多模态甚至包括跨到所谓的硬件模态就现在所谓的聚生智能它其实也是一个广义的多模态这些创业公司如果能够把硬件数据跟Robotic TransformerRT就是谷歌在尝试的这些事情能把语言和硬件的传感器数据和最后这个机械执行的数据能够打通的话它不一定要完全的断倒断但它能够从训练层就能打通的话我觉得这个它本身也是多摩菜的一种体现我个人觉得还是有蛮大空间的对 其实归根到底就还是数据的独特性数据的准确性 数据的优势了还是刚才Jonathan讲的整个这个核心吗反正我自己跟这边的几家比较大的美国本土的最大几家VC啊什么的聊天的时候感觉都是这样的就因为这些VC他们都有自己的一个相当于是business operation啊或者是go to market的这种类型的团队吧反正我记得上次在跟某一家的负责人我们在那儿喝东西的时候我就说你现在比如说这个美国这些大的企业接受AI都是怎么样的一个状态他的回答反正就是吆喝声还是非常多的就大家都想学都想知道都在讨论但是真正能落地的东西当然还是非常非常少的嘛所以整个这一块这里面呢你看大家做的东西呢其实都是关于AI的咨询AI的RAC这一块是上一年就过去这两个季度吧是最火的这些东西因为这个东西相当于是我要是一个公司的IT负责人我肯定要考虑我的公司接下来整个AI方面我要做什么呀我肯定要花钱啊怎么办呢那我先做什么我先不能拍板因为可能这东西我也不知道该做什么但是我最起码可以先把这个架子搭起来架子的话就是咨询AI方面的这些讨论所以呢在美国呢像艾森哲呀这样最大的这种科技类的咨询公司光咨询类它是赚的最多的它第一个季度的话它就是6亿美元的一个营收第二个季度呢这个营收从6亿美金呢涨到了9亿美金我之前跟另外一家就很大的这边的VC去聊天的时候他就说当然他说的是英文了但他意思就是说你说咱们这忙活什么呢忙活这么半天这个他去刷一下嘴皮子做两个rag这个9亿美金拿到手了就是这样一个现状你有用过艾森哲的服务吗我们用不起的这个太贵了多少钱平均一个项目那这个真很难讲因为就是他就是做自信像麦肯锡对麦肯锡也有很多对就一个项目就可以非常多的但是总而言之就这块你可以看一下不同这些公司的财报啊什么的这几家公司都是过去一年来增长最多的一块项目其实恰恰就是我特别想补充的咨询公司在今天的这个地位其实就是符合我刚才说的这个理论的因为我们回头看那个互联网时代互联网时代咨询公司爱生者也是存在的就是我一定有很多公司说我今天要做数字化我要开始做网站了我要做互联网化我也有这样的一个门槛要越过很多公司也会去找外包找咨询公司进来帮我把这个事情做了咨询公司他们提供的服务的核心是什么他真的会帮你把它搭起来还是说他只是动动自己的这个就看你的具体的核但你简单理解就是它把你整个搭起来就比如说AI年代据说我做VC我作为一个客户就是我现在要有一个我内部的我自己的GPT叫做投资GPT就是上面问我一些投资的问题你都能回答这个GPT实现不了因为我有一堆我投资的这些私有数据但是我不知道怎么去搭这个投资GPT这次我就可以找资源公司事实上我们现在就在做当然我不透露了很多投资公司也在做这个事情就找一个我们不会找艾森泽这么大的但是有很多这些但是在互联网时代这个事情就比如说我今天要做一个我自己的一个APP我也可以对不对或者我要做个什么我的网站但是在互联网时代如果你对比就是说整个商业化的版图里面一种是咨询公司不参与的这个收入和咨询公司来做的这个收入这两边是完全不成比例的基本上全是独立的互联网公司可以自己来实现这个事情你是说咨询公司参与的收入更多咨询公司参与的收入额其实只占很小一部分就中央之间也很大但是互联网的规模那么大,你把安森泽啊,马卡系东都加在一起,所有外包公司都加在一起,其实只剩其中很小,一部分是为什么呢?就是因为我刚才说的,中间有一个OS,就所以说它把这个门槛大大降低了,大部分公司都能自己做这个事情了,或者大部分的应用,你想做个应用的话,你其实可以自己很快弄一个团队,或者说你即便找咨询公司做这个事情,它的成本也很低,以前是有报价的,我一下记不清楚了,就是做一个简单的APP,可能就30万人民币左右,几万美金可能就能做出来非常低的但在今天这个AI的年代咨询的成本是很高的而且很多人都会用咨询的原因是什么就是因为中间有一个很高的门槛就是你做这个事情其实是不容易的我想做个APP或者说我公司内部我作为一个客户我想用底座大木星这个工具我一下就用不上我手上有这么多个数据而且这个形成一个矛盾就是我反而数据越多我越头疼数据多本来是个好事情大家在数据年代都知道大数据数据越多是好但数据越多首先成本抽取啊什么很可能就是需要用到case这样的工具本身也是个成本然后我抽取清洗整理这些都是成本然后我要再去训练我要把它放到相辆数据库里面做RAG那我就干脆就去找一个咨询公司所以艾森泽在这里面呢他的这个生意越新荣就说明这个生态越没有成立就你都靠第三方的交付公司去这个实际上是现在就是我们观察到的生态的一个现况但是这个其实就本身是个阻碍就是必须得卖过去大部分的公司都能我自己不用这种或者说用很小的成本对所以我理解其实就是说在互联网时代大家用艾森哲这一类的公司或者移动互联网的时代帮他们做一个APP它其实这部分的比例占得很小是因为基础设施比较完善大多数公司可以自己做对完善然后OS也比较具备对但是在这个AI时代因为它的基础设施不太完善然后比如说每个公司它要根据自己的数据去定制一个自己的模型现在还是门槛比较高的就干了这么多步从数据开始拿到后面的REGREG看上去很简单但事实上很多公司都做不好对我刚才说你其实需要对底座模型有一定的理解对 所以就是说现在整个在AI时代公司再去搭一个基于自己的数据的模型它的门槛是很高的咨询公司在中间扮演了一个桥梁就是我来帮你搭模型咨询公司你可以理解为它解决了三个问题第一个是就是一个全新的事物出现我要做什么定方向对第二个是怎么做第三个是用什么做工具就是对用什么工具做这三个因为太新了说白了就是大家也都不知道没人证明从第一个问题到第三个问题没有人知道怎么去或者大公司吧还没有准备好怎么去解决这三个问题所以艾森哲就出来了就像假如全球突然全都变冷了那可能所有这个我们东北人都可以成为艾森哲了那因为大家都需要知道说冬天到了我们要做什么呀那我可以告诉你冬天会冷到什么程度你要准备什么样的秋衣秋裤你要准备好家里打暖暖鸡片你需要做冬储凉大白菜等等等等我全都给你讲清楚因为我作为一个南方人或者没经历过这事那怎么办那这个就是艾森哲现在做的事对我们就是期望有一天如果用你刚才说的场景就是应该出现这么一层把所有刚才说的这些事情都已经隔离好对这群公司可能会变成中间层吗不可能因为商业模式上的它一定是叫做项目制的它的核心能力它其实不是大框架对 它不需要它也不应该这么做这不符合它的核心利益有的时候它会开发一些内部的一些工具去提高它自己的生产力就比如说它可能也用KISS的这个工具去帮它它的核心价值你可以理解成还是一个劳力密集型的因为它的收费很多是靠人时的就man hour就是靠人小时去做去实现对 再我补充一下有一个变化会是为什么呢因为恰恰就是按照小时计费的这样的一个群体这包括了资讯公司包括了律师等等脑力劳动的大量密集型的行业中反而我自己感觉到的或者开始看到的一个方向就是说他们肯定会来做调整了过去他们不会进入到中间层的但是因为你想当生产效率发生改变的时候就是这些按照小时计费的脑力劳动者们是很容易或者说很前沿被替代的所以我见到蛮多几家就是所谓四大呀什么这些人呢大家其实都在担心或者考虑的都是说怎么样把以小时计费的这样一些脑力的工种转换成一个中间层比如说它是不是可以做一个模型把它们的经验教训所有的知识因为这也是一个数据点然后转成一种小型的模型或者是一个什么样的模型把这个卖出去而不是卖人力的小时费对这很可能也变成一个垂直场景去实现但就它本身也是一个被颠覆被改造的一个行业它自己也是一个应用你可以这么理解但是我们观察到从互联网历史上就是这些公司它自己往往很难自己跳出来就往往还是需要有一个所谓AI原生的公司用这些新的你说工具也好Infra也好应用这些新的模式成为一个新的就好像你原来是一个出售的公司你可以把这些类似于Uber的应用装在你的四季盒这个上面但是你很难就变成个Uber还是需要一个原生的Uber或者说你原来是个零售公司你很难自己成为一个Amazon对我们还是期望第二类公司会出现但事实上历史上看起来也大部分都是第二类公司第一类公司就是艾森哲自己很难变成一个AI power的艾森哲自己杀死艾森哲的可能性还是很低的是不高的对也不是完全没有对那从这个角度讲因为其实我们刚刚一直在讨论模型层的创业应用层的创业其实是存在大量的中间层的创业的比如说像硅谷我知道有一家公司叫Fireworks他们其实是在做整个AI的frame就是框架然后他们跟艾森哲最大的不同就是他们其实是做一套标准化的框架让创业公司基于他们的框架去使用包括还有很多在做基于GPU的租赁可以在云上去训练模型那从投资的角度是不是这个阶段所有这些做中间服务甚至在建设整个大模型时代的基础设施的公司2B的公司做服务的公司做基础架构的公司是更有价值的呢在这样的一个阶段是很有机会的就刚才包括Fireworks包括我们也知道Laptor对吧对这样的公司你刚才说的那个用GPU应该是Lambda类似这样的公司这些其实包括做数据的对包括做数据包括Kiss这样的公司其实你可以理解从我们投资人角度我是这么看的这些我们都放在基础设施里面这个是比较容易去看这个事情的因为技术是很复杂的如果我们把它简换一下就是说就是工具就各种各样的工具你用各种各样的工具自己去搭但是他们不改变这个生态就是说如果按照他们这种其实还是不会大大降低应用层的门槛就应用层还是要有能力去用这些工具其实最好还是底座大摩星把这些事情都做了那当然这个就变得非常的叫做交钥匙工程嘛其实OpenAI他们是往这个方向在走的他们也都在做所有这些事情OpenAI自己当然他也有framework优化啊它都要做然后云居算公司也要做为什么微软跟open-i它是有一定的绑定因为Azure和open-i它是语音资源和底座模型所以他们都是可以理解成infora但是在哪个点上infora基础设施层能够变成一个操作系统这个是我们非常期待的我觉得刚才上述这些公司包括Kiss的公司我觉得都是有潜力的就是如果你能够充分的隔离应用层跟所有底层的这些细节让应用层能够充分的像个交钥匙的一样就是我就写一个网页我就是做一个很简单的一个HTML的这么一个编程我就能把我的这些私有数据把我的这些内容把我以前的所有这些用户我自己积累的用户的这些data都能够实现起来然后我产生我自己的一个垂直的大模型能够做到这么一点的话那这个生态就会被打开了但在今天这个生态没有完全打开的情况下所有这些点状的工具其实都是很有价值的但是风险也比较大因为这个生态还很不清晰你可以它是整个一个技术站这个整个计算都不清晰的时候所以他们每一个每一个都互相在重叠大家都互相竞争就每一个都可能会做对方的事情就比如说我做Leptum我很可能也要处理一些数据上的事情我要帮我的用户去做一些数据上的抽取也好清洗也好这样的事情所以大家会互相的重叠但是可能又很难找到一个完全互相配合的这么一个方式现在就还是处在一个很早期刚才那个Kiss说可能你说是两个月的baby我觉得这个比喻特别好我觉得基本上还是在这么一个阶段那一种方法就是说你就现在的很多应用公司就说我就是用这些工具我能够实现我的这个垂直场景这种其实今天是很有价值的对你刚刚其实提到了在你们投应用的时候其实你会去看它的数据持有数据包括它在模型上的一些训练的方法最后会不会训练到基础模型就是你有一套非常完整的投资逻辑那如果你在判断这些中间层的公司2B项的公司你觉得最核心的几点能力抽取出来是什么这是一个很好的问题其实不太容易回答的原因就是说因为我们判断应用层的时候我们可以有比较清晰的几个指标因为现在比较清晰的点就是应用层在这儿了就有应用公司在这儿然后有一个底座模型底座模型其实我也把它放在infra里面但它是infra里面是最重要的一个就像那一个最大的一个巨人坐在infra的这么一个池子里面但是周围会有很多围绕底座模型的小的infra是帮助它最后能够实现一个近似于操作系统的这么一个事情就是我能够充分隔离上层跟下层但现在最大的难点就在于说周围这一圈小的infra如何跟中间这个最大的底座模型的infra去互动去共生因为它也在挪移它可能会把你挤掉但是你又需要它但是很多时候你可能也是需要把它的中间切下来一块所以这个就造成一个不是那么容易判断就比如做framework就是做框架框架是里面很重要的一个事情但它也是会处在一个比较微妙的一个对就是有能力的应用我肯定就自己做框架了就比如你可以看到基本大部分的这些会自己做框架但是我一旦没有能力要么就用艾森泽了艾森泽可以自己帮你去搭一个这样的东西要么就是说我很多时候我也可以依赖底座提供的或者是云厂商提供的所以你看这么多人都在这个池子里边所以它产生的这个点是会非常的复杂对于做Infra的人的考验其实是会更高但是Infra在今天可能反而是最有希望的因为上下层都没有那么清晰所以为什么你看很多人去投底座模型其实投底座模型就是它也是就是我感觉说它是一个大的infra然后底座我们周边的这些配套infra我可以把它称之为配套的infra也是非常有价值的但是你怎么做这个非常考验他们作为投资人来讲我们可能抓一个基本点就是团队的能力刚才Kiss说的这个意思就是它是要在里面泡的是要做各种各样的转型和尝试的对Kiss你们自己也在这个中间做事你觉得护城河跟核心能力是什么呢我感觉刚才其实Johnson已经基本把整个这个链条讲得非常清楚了其实是这样的我自己在里面感觉呢这听着有点像废话但其实真的是这样的因为其实做EFRA嘛做基建嘛它从工程角度应该是最难的但我感觉呢解决了最难的这个问题之后其实是在语言模型的时代往上走一层反而是容易的就是我们解决了这个很难的一个问题之后我像张德森刚才讲嘛说加一个叫钥匙的这样的一个解决方案其实这个是简单的因为这都是有一堆既有的产品啊工具啊各种各样这就是回到上一代的互联网的这个概念上嘛这其实都有的难的是什么难的是选择一个角度就是底层的这个模型它很难走进去的赛道在这个赛道上你把它做到最好其实对我们来说语言模型不是我们的目标但是它是我们的一个很重要的工具这是我们对它的一个理解我们做的一个事我们认为是语言模型永远都解决不了的就是你把这个一个网页交给语言模型让它去帮你抓一些数据能做吗能做没有问题但是这个东西当你想到上到量想到一个大量的准确度一个连贯性因为语言模型都会产生幻觉一个网页越复杂你会越多的幻觉那你怎么去掉这些幻觉怎么解决掉刚才用一个推土机砸钉子的问题就拿一个巨大的一个语言模型来解决一个钉子的问题这些其实是很难的问题而语言模型以我们的认知上它很难走到这样的一个角度上其实我理解这还是对垂直行业的一个深度理解跟你基于大量扎实的工作建立起来的基本功去解决这个AI的幻觉问题它需要对工程的理解要远远深过对于研磨型的理解这个非常同意这个需要很多工程上面的你可以理解的程式包裹在上面要叠加一层其实我刚才很同意Kiss说的其实Infra的一个很强的可能性就是基础设施是找到一个可以交钥匙的一个点就是你成为一个小型的操作系统可能在某一类的垂直场景里面你变成一个操作系统你不用说我一下变成一个浏览器或者iOS但是我可能是在某个垂类里面可能能成为一个iOS交要是意思说我上面的应用层我拿过来还就能够实现它了但是你想做一个非常范的一个操作系统其实肯定是有难度的就是一下让所有的应用都能直接用你的它就可以上了直接就不用爱生哲了这个其实确实是有难度的但是我觉得可以探索这么一条道路这样你跟底座的关系也比较容易切分因为还是这个意思底座都想通用他们一定不会想在任何一个特别垂类的一个里面去生扎的他总想把所有的这些行业他就想做那个叫做AI加他说我是AI我要加所有的东西所以这块事我觉得是有机会的对 其实我最近有跟一些创业者聊天他们就觉得其实如果是做2C的应用的话在硅谷融资没有太多的优势就是因为他们普遍判断硅谷是更加偏2B的市场的我不知道中国的情况怎么样就你觉得中国这种做2B的市场跟infra架构附近的事情成立吗因为其实在过去的这么多年里面我们看到硅谷的SaaS公司发展的还是非常成功的但是在中国我觉得整体上下次没有起来当然我觉得用户付费意愿是一个方面还有中国的大公司它其实把创业公司能做的事情都做了也是一个方面但是这次在基于大模型的这个创业我不知道你们会不会看中国的2B市场以及你觉得它的中局它能不能起来这样的一批独角兽对 首先我们肯定两边都看2C2B其实是个非常复杂的问题因为传统来讲确实美国的2B文化更强硅国的2B文化更强中国历史上都是比较因为2C的退出是最多的就大的退出这些巨头其实都是从2C开始的中国的2P文化相对是偏弱了那我们如果打破地域上呢如果我们只是看因为现在AI其实太早了你很难说我其实不是那么相信就是一定会一下就分成一个哪个国家的AI因为现在大家都很早期嘛从我个人的判断来看的话我借用互联网的这个经验其实还是应该2C先起来你说中国是2C先起来美国我觉得也是2C先起来美国也是2C先起来对我是说做投资我从那个融资的角度来看你是说哪种项目掀起来吗还是不是我的意思是说哪种项目更好融资对就是在中国投资人你们会看2B市场的这个赛道会投2B类的公司吗确实在中国会2B会看的少在中国看的2C更多一点对中国的这个相对来说的习惯惯性思维还是会偏2C一些对但是你在美国会看2B对美国2B2C都会看但是我觉得可能还是2C会先跑出来但是现在你看到的很多其实是比如XGBT很多其实它还是C端其实还是2C的流浪目前看来会更大一些但中国对2B的这个其实也有它的一些历史上的原因但事实上你看到国内投的真正的量投的多的比如说这几个底座因为底座模型的核心其实它是2B但是他们现在很多角色其实可能也会有点像爱森泽因为它是底座模型但是一旦它要商业化的时候就发现很多客户其实是它需要定座模型对 没有能力去做这事了其实它就所以这些底座的公司就承担了爱森泽的角色这其实也是他的商业化的一个那这个事情为什么让爱生泽去获利呢还不如我自己就把团队放进去这样当然实话说他的这个人力层面是很高的他也变成有一些劳力密集性的但是这是他商业化的一个很好的但他你从他的实质上的而言他还是2B的所以他是也有点割裂就是说一方面大家对2B其实是有担忧的但是真正农资最多的这些公司其实你可以理解他还是2B会多一些因为他很多还是在做这些项目爱生泽也是个2B公司嘛是理解理解最后一个问题就是我们刚刚其实有不停地提到RAG跟FineTune你要不要简单地用一两句话解释一下这两个名词是什么意思RAG就叫检索增强生成FineTune就是微调其实可以这么理解就是说这两种都可以放在后训练里面应该公平来说OpenAI其实是做了努力的OpenAI GPT这个路线其实它是有一定的思考的他们其实是说底座就是基础设施跟应用层希望以这种形式来分开就是说我先做一个预训练然后剩下的是我可以把后训练交给应用层来做后训练就包括RAG和微调那还有一些公司说他们是在LAMA的基础上再加数据进去跟原有的那个模型一起训练这个叫什么继续训练我听完你说的这话大伽利他们也是用微调和RAGLAMA其实就开源模型它也是当然LAMA的好处就是说你可以本地部署了就比如你的私有数据你用来做RAG和微调的这些私有数据你可以部署在你的本地但是如果你用B元模型的话大概率你就得放在云上面了这个是它的一个好处从这点角度来讲对 其实是很类似的就这个Fintune其实就很容易讲到一个刚才赵丹他一直讲的观点你Fintune之后你可能是因为你的多了一点数据然后看着确实比ChashPT也好或者是Gemina等等什么稍微好一点但是当下一次这些大模型在更新的一次的之后多了一点数据了一下就把你这个全都给撵过去了对 这是一个风险这就是我刚才说在设计这个GPT架构的时候预训练加后训练的时候它其实算是没有完全解决的一个问题但是呢这个后训练就RAG和微调一定是非常有价值的不管你底座再怎么样更新因为你毕竟有私有数据这个其实可以做个比喻我一直喜欢做这样的一个比喻也不是我发明的其实在很多其他的地方预训练很像是一个本科院校它是做这种通用的一个教育你一定要是有很多这种下游场景的所以你会有很多这种研究生院就是针对每个垂直场景比如说法律我会有法学院金融我可以有个什么商学院对吧医疗我可以有个医学院让他们去继续对你进行教育但现在大部分的后训练的这个能力呢我个人是觉得他们还没有能做到这些他们做的很多是什么比如RAGRAG想做的什么事情呢比如说我有一个本科生出来了但是我想让他去做很多律师的事情但是RAG的核心点因为他叫检索增强生成它其实是什么意思就是说你不一定能够去上完法学院的所有的课但是我把法学院所有的课的书本都整理出来了然后放在你面前然后这个本科生就是我在解决这些法律问题的时候我就随时去查这些书他给你一个很强的一个查书的能力就叫检索能力这个大家都能理解它实际上其实很像这么一个过程有人把它叫开卷考试为什么叫开卷考试就是我是没有学的我没有学这些书本我并没有上过这些法学院的课这是RAG微调就更复杂但是可以简单就是说我也没有办法把你全都送到法学院去但是我跟你说很多有点像上岗培训就有点像短期的一个我用以前的监督数据其实就是说我以前的这些例子我以前在法学院的这些例子告诉你然后你按照这个去一个一个的针对后面的这个事情对吧但是我觉得它的难点就在说你用这两种方式后训练的方式今天其实就没有像我希望的那样能够真正在后训练的过程中能够加速这个Skilling Law就是我数据大大的时候我怎么样真的能变成一个法学样而不是只是一个一堆法学的书放在桌上给我看或者是一段时间的法学的培训RAG其实现在是一个最火的一个商业用最多的用最多的但是呢其实我也很同意像Johnson讲的我们也非常认为现在的RAG呢做法呢应该是不对的这个比喻非常好我给你一本上课一本书因为你很强然后我问你我给你出道题然后你从中翻翻翻你把这个题告诉我了说这个你看这题这么回答对吗对没有问题好我给你十本书你去翻翻翻又找着了又告诉我这答案没有问题给你一万本书我不告诉你这个一半本书是什么我就给你一半本书OK这一万本书你现在我给你一道题你给我回答这道题更难了非常难的但是按照Skilling Law它本来是应该更简单的结果它越变越难了因为所以我刚才的观点就是说现在反而数据变成一个负面的就是我数据越多我如果用现在的这种后训练的方法就后训练的人数据越多反而对他来说当然他都可以放到RAG里面但RAG能不能是scale就是这个问题一万本书能不能实现我这个十倍的这个能力观点就是说因为这个数据都是原始数据就是非结构化的原始数据在这里面是大多数现在都这样的就我把整个篇文章全都扔进去我也不告诉你哪个是作者我也不告诉你哪个是开头哪个是什么就没有这种标注的他是把整个一大段东西全都扔到VectorDB里面去然后就结束了基本上所有人都是这么做的因为你去做标记这个成本是极高的所以大家都这么做就是像刚才赵诺森举那例子我有给你一万本书了你去说我现在要找这个的作者是这篇文章的作者是谁他在哪天写的这是一个就语言模型几乎他是完成不了的事情所以说他可能这把对下把是错的他没有一个连贯性他可能从头到尾不仅没有连贯线都给你猜说是3月7号其实是12月6号完全没有关系的这是现在一个非常普遍的事情就是因为整个数据所以回到之前张作霆一直讲的我感觉很有道理用国内大厂的话讲就是这个数据的对 颗粒度的问题现在的话RAG有很大的问题了对 但是我觉得就是因为现在其实有很多细分方向的应用就是不管它难还是简单事情我们还是得做还是得给大家效果感觉这些应用也会标配RAG所以从大家的观点来看就是说其实RAG是现在我们没有办法去达到细分垂直领域的这种精准度我们暂时用的一个开卷考试暂时用的一种解决方法但是长远来看这种解决方法它的数据并不是越多然后它就效果越好反而是相反的所以它可以是一个过度阶段的产物但是它不是一个最终方向的产物这个结论也不是那么容易做但目前观察到的是这样就是我们也希望它能够持续地这样迭代下去所以我还是刚才的观察就是你持续做RAG可能会有一些风险但今天确实没有特别好的解决方案因为你再往下做继续训练也好重新预训练也好肯定成本都会很高好的好的那我们今天的节目就先到这里谢谢Jonathan和Kiss谢谢红军谢谢红军谢谢大家好的这就是我们今天的节目如果大家喜欢我们的节目欢迎在你所收听的音频渠道来订阅我们中国的听众可以通过小宇宙 苹果播客 网易云音乐QQ音乐 励志FM 蜻蜓FM来订阅我们海外的听众可以通过苹果播客Spotify 还有在YouTube上搜索硅谷101播客来关注我们感谢大家的收听
