---
id: 22d16de2-5827-46db-9994-27f87402cacb
source_type: podcast
source_key: guigu101
title: "E180｜量子计算的Transformer时刻与科技巨头的路径之争"
url: https://sv101.fireside.fm/187
published: 2025-02-14T00:00:00+00:00
downloaded_at: 2025-11-28T14:17:51.478977+00:00
---

# E180｜量子计算的Transformer时刻与科技巨头的路径之争

现在处在敏感阶段的三个行业先进半导体AI量子我们可以总体来说先进半导体是一个非常传奇的过去然后AI是一个非常蓬勃的当下量子基本上是不可避免的未来所以在一个加息周期里面的话政府会对这个不可避免的未来更感兴趣但随着减息周期的开始我觉得像VC对整个行业更加关注特别是Vilo的出现我觉得会run pop哈喽大家好欢迎收听硅谷101我是洪君那大家标题已经看出来了这又是一集非常硬核的话题量子计算2024年的12月谷歌宣布基于Vilo的计算机芯片的量子计算机只需要不到5分钟的时间就可以完成一项标准的数学计算那我们把这项计算交给传统的计算机需要多久呢10到25次方年这是什么意思就是说这个时间已经超过了我们知道的宇宙年龄我相信听到这里大家就有疑问了谷歌的量子计算机如果已经能执行这么厉害的任务了那量子计算是不是实现了呢并不是因为谷歌的机器执行的数学计算是一项专门用于衡量量子计算进展的测试而不是一个有用的可以在医学或者人工智能领域进行的有目的性的一些运算过去30年困扰这个领域最顶级的学者们的问题呢就是量子计算机它会犯太多的错误那谷歌微露芯片的主要贡献呢就是它可以在扩展至更多的量子比特的时候指数级的减少错误那基于这一点呢它其实是解决了一个困扰科学家们30年的难题所以业内人又将Google的Vilo今天称作是量子计算界的Transformer Moment这样一来量子计算机距离执行人们觉得有用的任务我们离完全纠错的量子计算机就又进了一步我们离有用的量子计算还有多远英伟达的CEO黄仁勋在CES期间也被问到了这个问题那我们这期节目的录制呢是在1月份的CES之后刚好是黄仁勋回答了这个问题所以我们会讨论他的回答以及量子计算还有多久实现同时呢我们也会提到啊刚刚对节目开头谷歌Velo芯片的一些解析那第三部分呢我们也回顾了过去几十年硅谷巨头它是如何去布局量子计算以及它们之间的线路之争这一部分听上去会有点点难啊大家可以一边看show notes或者使用AI工具的辅助去理解这期节目那最后一部分呢我们会聊一聊量子计算的应用以及它与加密货币银行还有运营商之间的密码学博弈下面就请收听我们今天的节目那今天跟我在一起的两位嘉宾一位是安阳Technology的创始人也是加州理工大学的博士与伯克利大学的博士后Roger罗哈喽Roger你好你好啊你好啊很高兴能参与这个节目然后跟大家聊一聊关于最近量子计算的一些前线信息吧对欢迎欢迎那另一位嘉宾呢也是Roger的同学他是加州理工大学的博士与博士后同时呢也是安阳的CTO Jared 仁哈喽 Jared 你好对 我们是加州理工博士期间的同学欢迎 Jared那在开始的时候大家要不要介绍一下自己包括你们跟这个量子计算的关系好啊 好啊在过去十点多的时间我们基本上一直在做量子芯片相关的事情我和 Jared 2014 年来到加州理工做博士的我们的教理工导师是Oscar Penter也就是现在AWS的量子硬件部门的负责人实际上我们在量子计算这个赛道上面从14年就开始了有10年的共同从业经验了也是基本上在19年我博士立业再去博士后之后然后我觉得时机比较成熟了就跟我之前的同祖同学也就是Jarrett一起创立了这个公司目标就是结合我们在伯克利和教理工的相关的前沿技术因为我在伯克利的博士号组也是整个量子计算芯片的先驱的组就是Professor Francis Dickie他基本上在超早量子电路这个赛道上算是20多年的历史了也是最早的一批教授基本上跟John Martinez同一代所以说实际上我们当时创立这个公司初中就是一是看到了很多像很多公司基本上所有的云计算公司都在做量子计算特别是AWS把我们之前在Caltek的组给整体的拿过去创建了它的量子计算硬件部门之后我们觉得这个实际很成熟那我们既然有技术有实际我们就why not对吧去做一个公司将我们的技术变成商业化产品然后服务于下个十年的计算行业这就是初衷吧那Jared你要不要介绍一下好啊由于我跟Roger的轨迹比较相似吧所以Roger基本上也帮我介绍过一些了在我们2019年2022年博士毕业期间Roger去了Berkeley做博士后我继续留在了加州理工继续跟Professor Oscar Pinter继续做博士后这个期间也是亚马逊开始开展量子计算正在把我们的博士生导师整个的研究组挖到亚马逊AWS的量子计算部门这么一个过程所以说我也参与了一些初期的交接的工作和准备工作当然像Roger刚才说的我们最终觉得是一个非常好的时机来成立自己的公司按照我们自己的理念可以走出跟大公司不一样的发展路线所以说我们就一起创立了现在这Anyan Technologies这个公司那我觉得在节目的最开始可能还是一个非常通识的问题能不能用尽可能通俗的语言跟我们的听众解释一下什么是量子计算它是用来做什么的好 我用我一直以来比较通用的一套浅显易懂的解释介绍一下量子计算吧理解量子计算可以跟经典计算机做一个类比那我们现在市面上几乎所有的计算机无论是CPU GPU或者是手机或者是很简单的计算器都可以理解为是经典计算机对啊那我们想理解量子计算机的话用经典计算机来做类比是比较容易理解的我们其实可以理解为每一个经典计算机都是一长串的字符串由0或者1组成的就是我们所说的BitsBits只能是0或者是1的状态那所有的计算机无论是它有多么复杂还有多么简单无非是一个比较长的字符串或者是一个比较短的字符串那类比于量子计算器的话其实它也是一长串的字符串只不过它的组成部分我们叫做Qubit量子比特那量子比特跟比特的区别是什么呢就是说量子比特它不仅仅只能存在于0或者1的状态而是它有一个叠加态它可以同时存在于0和1之中的状态那量子计算机呢或者说量子比特还有另外一个特性那就是量子的另外一个原理就是说它的纠缠态它不仅仅是说每一个量子比特不仅仅是它自己单独的量子比特而是不同的量子比特之间可以纠缠在一起同时发生改变那这两个一起发生作用呢就产生了跟经典计算机显著的不同经典计算机比如说如果是一个只有三位数构成的经典计算机那它的所能存在的状态就是0000001一直到111一共八位数那如果想要进行运算的话它只能一个一个的去改变每一个位数如果它要去到这八个不同的状态的话它要进行八次运算但量子比特不同量子计算机不同它由于如果说我们有一个三个量子比特构成的量子计算机的话它其实是由于叠加原理和纠缠原理它可以同时存在在这八个状态里面然后同时对这八个状态进行计算那如果只有三位数的话它们的差距可能不这么明显一个要进行八次运算一个进行一次运算就可以完成但是如果比特的数量继续加倍的话那量子计算机它其实是一个指数增长的过程如果有四位的话静电计算机就要进行16次计算才能穷尽16个状态但是量子计算机还是只需要一次就可以穷尽于所有的16次状态这就是所谓的量子计算机相对于经典计算机的计算来说的话指数的加速过程所以我可不可以理解成量子计算机它其实是非常适合去解决非常复杂高难度的计算的越难的计算它越有优势我们可以理解为它的核心优势在于能够在某些特定的问题上实现指数级的加速量子计算机它不是经典计算机的代替品就像GPU不能像是完全是CPU的代替品一样它们两个是一个共同存在相互协同的作用量子计算机特别擅长某些特定问题上实现指数级的加速像是矩阵运算、因数分解、量子化学模拟和组合优化等领域它会在这些高复杂度计算的任务中发挥非常重要的作用哪些领域会运用到这些高复杂度的计算就比如说如果你们能想象未来量子计算它会去应用的话相比于传统计算机它一个非常有优势的场景跟它最有优势解决的问题是什么能不能举一个具体的场景的例子它有几种特殊的算法有的特殊算法对矩正运算有特别好的指数级的加速效果有的运算对因数分解有特别好的加速效果它本身是量子的然后这个世界本身是量子的用经典计算机对量子世界进行模拟本身是非常困难的也就是说我们的一些化学运算它本身是量子的所以说用量子计算机进行这方面的运算将会更加的容易那我刚才提到的三个例子所对应的其实就非常的明显其实矩阵运算我们现在所有的人工智能机器学习本质上就是矩阵运算那因素分解的话很能想到的就是舒尔算法所对应的安全问题加密问题现在大部分的加密手段都是通过类似的情况进行加密的那量子计算对于破解这样的加密就非常有优势而量子化学模拟那很明显就可以想到油气啊化工啊药物的研发等等是一个非常直接的作用还有一个领域就是量子计算机对组合优化的求解过程是非常的迅速也有指数级的加速作用所以说对于一些物流啊之类的需要优化的内容这些领域也是非常有帮助的嗯 理解理解你刚刚提到了好几个点嘛比如说在矩阵运散方面它对人工智能的加速表现在哪里了比如说有了这个量子计算机那大家在去训练这种大模型的时候它会有特别的优势还是说它只能在一个极小的领域里面针对某一个特定问题它可能会有一些特定的解法我理解的是人工智能无论的模型是什么它的本质是矩阵运算其实回到了根本的问题就是GPU为什么在人工智能中作用这么大它比CPU为什么做人工智能的模型动画速度快这么多本质上就是GPU对矩阵运算的速度会比CPU快很多CPU擅长比较复杂的问题的比较少线程的运算而矩阵的运算本质上不需要特别复杂的过程比较重复的过程而且需要特别多的核心同步运算那这就是GPU的作用也就是说人工智能为什么在GPU上比CPU上优势这么大就是因为GPU对矩阵运算会比CPU快很多像量子计算器中用到了HHL算法之类的算法对矩阵的运算也能加速的话本质上就是对人工智能整个大模型开发的类似的实现了从CPU到GPU的这样一种跨越式的加速发展对 因为实际上第二想表达一点就是实际上量子计算在这个具体的问题上通过加速矩正求力算法这相关的算法我们实际上可以总体的加速整个人工智能学习的和Inference的Pipeline也就意味着比如说你的人工智能模型有 say 100 billion的参数你用100 billion参数你用GPU去跑的话对应的大概是一个比如说100B x 100B 的算法复杂度就要跑这么多步骤去算它对于量子计算机来说的话就是一个求指数底数的 log求 log 的一个方式就是100B 的话大概相当于 log 100B 的一个算复杂度相对来说你在处理巨大的模型的时候的话它的整个操纵的数量会指数去下降相当于你可以以更少的能量和资源付出去计算一个巨型模型对刚刚我们提到了量子计算应用的几个方面我觉得在之后啊我们还可以详细地去谈讨它的商业化跟它在各个行业里面是怎么应用的但是呢在此之前我觉得就有一个问题了量子计算现在到底能不能实现比如说我们说的来去训练人工智能它发展到哪个阶段了那在问这个问题的时候呢其实今年英伟达的创始人Jason Huang他是在今年的CES上其实也把这个问题提出来了嘛然后我记得他说的是如果你说15年内能实现非常有用的量子计算他觉得这个是一个非常偏早的预测如果说是30年实现有用的量子计算可能偏晚所以他觉得一个合理的区间是在20年但是他这个话一说有一批量子计算的股票大家的股价就纷纷下跌所以也是想听一下两位你们怎么去看Jensen说的量子计算他的实现时间首先Jensen在他们对于NVIDIA的投资者会议上被问到且正面回答这个问题本身其实已经把他认为的20年confine到了远不止20年了比20年还要久因为一旦你开始回答这个问题在这种会议上那就意味着投资者在考虑是不是要price in你未来10年量子计算对你公司的股价影响了因为大家都知道华尔街算股价的方式是price in未来10年的assume的gruce和monopoly的所以实际上这一个对他而说有点conflict of interest的问题就如果它有任何地方表现出未来实验这可能会对GPU产生影响的话那明天NVDA股价就要跌了相比让NVDA股价要跌来说的话让量子计算的股价跌对它来说是一个非常合理的决定毕竟坐在哪个位置上回答哪个问题吗它另外一个角度来讲的话呢我觉得Jensen是很厉害的人我也很尊敬他但是人你就不要看他说什么要看他做什么对吧Jensen公司在量子计算里面算是一个非常大的一条鱼了他也是我们的合作伙伴他们也有非常主动的各种partnership和合作还有包括我们等一下参加的一些超算的会也是我们跟他们要一起做demo的所以整体上来说这个就代表一个逻辑从它做的角度来讲我们可以回顾一个历史CUDA launch的时候是07年CUDA DNN就是CUDA专门为DNN的package launch的时候是14年而Transformer是16年GPT 3.5是R20就算你从CUDA算起15年都是一个从维迪假作来讲它开始做这个方向到最后这方面完全落地都不会超过15年所以第三点它用词非常精准它说是very useful quantum computer在这个context里面其实可以认为它理解为叫large scale full tolerant quantum computer也就是量子计算的完成体就类似于AI里面我们谈论AGI它是一个非常长远的go或者它是一个非常powerful的一个dream一个go它如果能被实现基本上人类文明在下一个阶段就会被define了因为我们开发出无数的新材料和无数的远超人类强大的人工智能都可能出现所以它这个very useful的意思就是量子计算彻底站在了现在GPU站在的计算中心的一个核心位置这个的确我个人不认为在15年之内有比较大的概率能出现我觉得工业界共识来说就是large scale for current computing这种处在monopoly一段的量子计算可能差不多也要15年的时间这个我觉得它的说法本质上没有deeve from他们自己公司内部调研和这个工业界的公式它只是把它phrase了成了一个可能投资者听起来会更加的friendly的一个说法对我在想要怎么样去理解这个量子计算出来对NVIDIA的冲击我可不可以理解成如果量子计算真的实现了一个是它是不需要那么多GPU它就可以去实现这些运算的所以它对GPU跟芯片的需求没有那么大所以我挺想知道这个对它股价的冲击大家这个思考的逻辑是怎么样的对量子计算首先它在很多复杂问题上因为NVIDIA现在他们对公司的定义叫做A super computing infrastructure company所以他们认为未来的super computing超级计算涵盖了AI天气预测还有一些化学模拟这种高复杂度的聚算问题从它的角度来讲认为是NVIDIA未来的核心business这个是fact对吧而这里面有一个很有趣的点Quantum也是这么说的但是实际上就会发现有一个点就在于Quantum在一定程度上的确会不能叫做侵蚀严格意义上说是会参与到NVIDIA在更复杂运算Domain的应用里面的一些存在感比如说我们要做极其复杂的C 蛋白质反应模拟不是AlphaFold这样的预测而是低性原理去模拟它去精准地找到这些药品这种任务来说的话呢NVIDIA去低性原理算是肯定不现实的量子计算可以算但是在NVIDIA角度来讲呢当然成本太高了对公司来说对如果有个中心愿意买100万个NVIDIA未来的GPU芯片去算这个问题对他们来说股价肯定是好的对吧但这个时候如果量子计算给到一个我说我不需要100万个GPU的成本对吧我是需要差不多100万个GPU成本就能实现这些目标这个相当于它的市场就夺不到了但是Jensen说的就是very useful就是说你的quantum computer基本上不需要跟GPU分担工作量就能完整地去处理这些复杂的问题的时代还是有段距离的所以我觉得Jensen把它放到15年二审这个年段相当于就告诉华尔街不要去pricing未来实验quantum computer对我们公司股价的影响未来十年随着计算量需求上升公司的股价应该是水涨船高这个是合理的我们认为而且我觉得未来10年从量子计算的假如来讲我们也很需要GPU做混合量子计算这也涉及到为什么我们跟NVIDIA合作所以实际上未来10到15年这段时间其实是一个共同存在共同生长的一个阶段并不存在谁取代谁严格说是一个扩大的增量市场而不是一个存量上大去抢空间的问题是的 对你们跟NVIDIA的合作大概是一个什么样类型的合作我们更加重视的就是产品技术层面我们是个硬件公司他们的这件公司一方面就是用GPU对他们的这套软件和GPU算法去优化量子计算机的芯片设计优化它的量子测控还有一个就是你用GPU去优化量子计算机的运行另外一方面就是通过量子计算机去结合GPU增强AI模型的泛化能力去训练更泛化的模型就是用你更少的parameter更少data去获得更能有泛化性更generizable的AI model这个其实也是一个叫Quantum Enhanced AI的一个路径也是大家也听到有一些非常知名的AI公司最近也在hire量子机器学习的Talents去做相应的开发其实这也是一个trend哪些公司大家都听过的应该是SSI吧Safe SuperintelligenceEli德那公司另一点来说的话我们跟他们合作当然不是在软件层面我们更多就是去构造这样的计算平台也就是说我们把它的QDA Quantum这个软件作为一个胶水联合它的GPU和我们的QPU到一起成为一个完整的量子增强计算平台同时我们通过高速直接互联让我们的量子计算机和GPU能形成实时的数据交互来增强量子计算机实时运行的同时去增加它能解决的增强的一些比如说人工智能学习这样的类似的问题这一系列来说相对于我们在NVIDIA的那个网页上叫做Quantum Backend Provider他们自己称自己为GPU and the backend provider所以我们像是个并行关系同时把它变成一个完整的quantan enhanced computing platform我们是有自己的量子芯片我们有自己完整的量子计算机我们只是将我们量子计算机跟Vidia的GPU系统进行了一个互联然后用他们的软件去协同两边的工作通过量子硬件去增强GPU在进行智能学习问题中的一些作用那你们的芯片是自己造的还是说市场上有专门给量子计算来造芯片的这个问题很好我们的芯片是我们自己造的因为我们自己的独立的设计和专利和制成但是实际上有公司在卖量子芯片好不好我不comment但是基本上美国的公司都是自己造我能这么说吧因为很多技术来说你要在一个快车道的计算面进行突破你把这个这么早就给到一些可能并没有那样技术系列的团队去给造芯片是有点不算明智的嗯 理解你怎么看Google新发的这个Vino芯片他们其实一直以来都在向这个方向走从14年开始做就一直往上走这是公开路线图实现掉的纠错证明的可扩展性的情况下去基于这个来造出监森黄口中的very useful quantum computerlargest scalefotorrent quantum computer这是他们一直以来的Go但我觉得这个是为什么大家有点confused因为不同公司的Go不太一样有些公司的Go就是像Tutiful AGI directly而有些公司所以像OpenAI我们能launch一个GPD3.5就coit the day了基本上所以Google推出Vilo这个芯片寄Sigma之后从我们的角度看是个延续性工作他们基于Sigma之前的一些demonstration发现Sigma的无论是规模上还是从一些芯片的performance上面不足以demonstrate量子计算特别是基于量子约错的计算的可扩展性你要证明可扩展性就意味着the more the better就你造的芯片造的越来越大反而你的计算机的可靠性和计算率越来越大以前来说我们从实验上发现的一个规律就是你造的越大你的整体性能并不会上升的原因在于你的总体错误率也会上升所以实际上纠错在你把你的芯片把你的量级性能造到所谓的very useful quantum computing这个路径上是一个非常至关重要的一个技术点一个前置科技可以认为是一个所以VLO相当于基于他们过去10年的发展终于证明了量子计算加上纠错的一个可扩展性它这个芯片它是在一个什么样的阶段知道了呀对他们有的论完了他们用了不是全世界最领先的量子比特和保证度但是加上各种别的工程提升让这个芯片做到了能demonstrate量子计算在硬件层面在实验实现上的一个可扩展性这一点我要强调实验实验的可观认识因为量子计算本身能做到复杂超级计算这个本身不是个问题从算法层面从原理层面大概10加20年基本上就搞得很清楚了Google过去10年Ibicol时整个工业界干了什么事呢就是从实验物理可实现的device层面去证明这一点证明我们真的能做出一个足够理想化的芯片去做到这里做到可观认识做到大规模预算所以相对Google这个维朵芯片的意义就在于从实际的物理层面我把它做出来对它会开放给第三方的合作伙伴采购吗还是他们只自己用Google从来都不是个硬件公司从来都不靠卖这个所以这个无论像TPU嘛他们最早做出TPU他们也没有卖啊基本上都是自己用他们更多来说就是这是一个非常好的验证我们能做到就是所谓的Viral Use for Prime ComputerWithin 10 yearsaround 10 years的一个阶段一个证明那你觉得它的芯片造出来了会对它的整个量子计算的研究加速吗这个我觉得从加速层面来说的话呢肯定会的但是更多来说就是他们证明了我们能做出来这个情况下来说加速层面的话就能更加的促使他们这个部门因为他们是历史于Google AI嘛历史这个部门能获得更多的资源去将芯片就是做得越来越大越来越能解决一些实际问题所以加速层面更多不是说用这个芯片加速他们别的可以发展而是用这个芯片去作为一个证明一个活生生的证明然后去获得更多的资源把这个东西skill up到成为一个eventure成为一个商业化或者成为一个very useful quantum computer这样的一个形态加速肯定会加速的因为管理层现在被convince了被convince了什么就是效果是OK的就是你看那个Google CEO嘛不是发在那个post的吗因为管理层也要看到你这个proof concept嘛对吧你说你的那些skill那一个scale给我看所以现在基本上从Google层面来说的话呢从管理层讲出来讲这个scalability从基本层面上是验证了的我举一个可能有点模拟性的例子来说吧就是所谓transformer moment你证明你的Machinery model能scale那现在这个scale给我看把scale到足够大能不能做出一个类似GPT的模型来就是这样的逻辑所以VLO芯片相当于量子计算界的transformer moment对这个我有点食人压惠的因为是有个投资人问我是不是Transformer的我想了想好像点像因为的确是Google相当于我做出了一个活生的代码水平这玩意能skillOK那how about we scale itactually如果从AI的路径上来说的话呢实际上我更加乐观地认为就是为了适应眼泪我对Jason的这个comment觉得有点过于保守但是anyway你的估计比Jason的这个估计更乐观而且尤其是在谷歌的Windows芯片发布以后你觉得它对真正实现的非常有用的量子计算它能够加速到多少年比如说没有这个芯片以前跟有了这个芯片以后本质的区别是什么其实我觉得如果没有这个芯片的话大家会更倾向于像Jensen的预测大概15到20年收紧但是有这个活生的Demma水井之后我觉得这个进程大家对未来实验线的收敛的预测会更加预测到within15年当然这个可能也是为什么Jensen在这个会议上会被投资的正式地问到这个问题因为那我们就开始考虑是不是要press in这个事情嗯 理解威露芯片你刚刚有提到它其实是有解决量子纠错在实验实现的可扩展性那Jerry的你要不要跟大家大概解释一下他解决了量子计算中哪个最核心的问题他的原理是什么科普一下那我大概谈一下量子纠错的基本原理通俗地解释一下量子纠错本身吧我们一直都知道量子计算的实用化最大的障碍之一呢其实就是噪音同样的我们这里也可以用经典计算机来类比量子计算机中的噪音其实所谓的经典计算机也是噪音非常严重的现在我们正常的使用日常生活中的电子产品手机电脑从来不会感受到这些噪音是因为他们在很早很早以前就有底层的经典领域的纠错算法已经把这些问题在硬件和软件的衔接层面就已经把这些噪音或者说错误给纠错了打个比方在GPU中如果我们是一个1.2伏特的GPU那理想情况下1.2伏就代表的是逻辑1然后0伏就代表的是逻辑0但是在实际操作中由于量产的GPU芯片不可能是完全一样的每一次运算它可能所施加的电压也是有一定的不同的所以说这个电压并不一定一直是1.2伏或者是0伏可能不同的晶体管制间不同的时间不同的输出会有不同那计算机的底层就会把一个范围内的误差都算作0都算作1比如说出来一个1V的点压那可能也会被认为是1.2V也就是逻辑1那1.5V可能也会归类为逻辑1这样来说对经典计算机是一个相对比较简单的纠错过程但是回到量子计算中这个就非常不一样了因为不像经典计算中它可以达到一幅这样相对来说比较大的一个数值来方便进行纠错量子比特的能量是非常小的像我们所用的超导系统中它只有一个光子的能量所以说量子比特非常的脆弱然后也极易受到环境的干扰和内部误差的影响从而导致量子信息的丢失再进行跟一些经典比特之间的对比的例子的话比如说经典比特只会出现0或者1的翻转错误而量子比特像我之前描述到的它其实是一个叠加的状态不仅仅包括0和1的翻转它可能还会包括一些相位上的偏移的错误这也会对计算结果或者说计算过程造成一些噪音的影响然后由于量子比特它是有纠缠的特性所以它不可以像经典计算中每个比特可以单独的拎出来进行纠错如果要对量子计算进行纠错需要对所有纠缠在一起的量子比特他们密切联系在一起所以说要对他们统一地进行纠错这也就是为什么量子纠错会被认为是实现量子计算然后推动量子计算真正走向实用化的一个核心技术OK所以谷歌的微漏芯片核心它是极大的解决了这个问题我认为微漏用现在最主流的一个量子纠错的方案这个纠错的方案叫做表面码这个表面码也是源自于加州理工的量子纠错的技术它通过利用表面码的纠错码和它比较优化的量子的硬件向世界证明了我们可以用这种方法用这条以前已经规划好的路线继续走下去只要是按照这个路线继续走下去我们就能逐渐地扩大量子计算机的规模扩大量子计算机的运算能力而同时呢不会使它的错误率随着规模的更大而变得更加的严重反而是随着规模的更加扩大它的错误率反而是下降的也就是说计算能力整体是提升的按照我们这条路线继续走下去最终我们是可以实现像刚才描述的非常有用的量子计算也就是我们业内人士叫的叫做完全纠错的量子计算机完全纠错的量子计算机那大家觉得谷歌有了这个芯片以后就是刚刚你们也提到了其实你们之前也是跟亚马逊有过这样的工作交集它会对其他的做量子计算的公司比如说IBM 微软亚马逊 英特尔还有一些创新型的公司明星的三只股票Uncube  Rigetti还有Devive这些公司就它会不会形成一个显著的优势我觉得从这个层面来说其实Google是个很好的公司为什么呢因为它首先有微型他们愿意去花早期的像他们发明Transformer一样给大家证明这个大方向是对的然后大家就沿着这个路子走就好相当于扫清了很多所谓的不确定性在里面我们可以看一下别的大公司的response吧比如说IBM以前从来没把量只有错放在他们路线图里面至少没有明确放过现在放上去了什么时候放上去的就是前几个月因为Google这个东西工作也不是一刻出来的说实话内部的话我们早就能看到Paper了因为这叫同行审议的就是peer review的大家可能看到的所以paper其实它只要发出来类似于这个东西它就开远了对吧大家可能都知道这个方法了首先它的路线图一直是名牌对吧我们要做一样纠错通过纠错的skill包括纠错算法算法是来自于Caltek的Caltek的表面码或者叫service code是Caltek的Alexei Kitev发明的纠错算法所以实际上就像硬件公司跟软件不一样的一个很大的点在于硬件我可以把physical process这个大方向给指清出具体的实现很多所谓的物理哪里都一样对吧那你就要大家根据这个大方向进行努力了所以IBM不放上去的原因在于IBM它认为量子纠错的实现时间线会拉得更长它认为量子计算机通过暴力出奇迹的方式去增加量子比特数量能更早地实现商业价值或实现所谓的very useful quantum computer换一个定义方式首先IBM这条路为什么它作为这个行业最早参与的大公司反而在这方面有一点点保守呢因为很多事情大公司其实往往倾向于更保守更坚定的它的早期路线图所以IBM之前更多是想说我们怎样用现在不纠错的这样决定能做出有用的应用呢是它的路径所以它不停在堆它的区别数量不停地探索一些商业化途径就它的确做技术但是现在做商业化Google的话呢几乎完全不做商业化它就专门去做纠错然后IBM几个月演换的嘛现在大家知道了IBM觉得纠错反而可能毕竟这个已经proven是可以within reasonable effort可以做出来的而且关键是Google的人还比IBM少很多所以这个事情就IBM一直干这种事情嘛作为行业先锋但是有的时候年轻人员比它还是要高效一些的像另外一家大公司我不看问哪家公司因为有些人这是非公开信息但是也在把自己路线图换成纠错了也是要对标Google的这个大公司嘛你看到另外一大公司做出了突破他们也想突然间倒戈换上去嘛因为以前觉得可能很晚做出来的东西反而现在做的是最早的Devail呢有点难因为Devail他们的路径他们一直是做的所谓的退火计算就意味着他们其实路径完全是跟量子纠错完全是背道而驰的但是也有历史原因为什么Devail是最早的纯量子计算公司他们是90年代行的创立还是2000年初他们那个年代的计算机他们说实话那时候大家认为可编程通用计算机是不存在的所谓的数字量计算机是不存在的或者很难很难很难造出来所以他们的公司创始初衷就是通过简单易实现相对简单易实现的退伙量子计算去做一个专一化的量子计算机它不能被用来去编程来做所谓的量子纠错也不能通过编程去做通用量子算法但是他们认为通过做专一化的量子计算机可以更早地实现商业化价值显然我现在回头开始错误选择了你不认可这条路线是吧那他们现在有转变吗他们公司的创始到现在都是走这个量子推火方向所以他们要转变也是要有过程的相当于要彻底换方向了只能说不是完全不认可吧他们也许只能找到很多use case但是实际上会发现之前认为很难实现的量子计算的路径反而现在可能更早实现而且关键实现之后的影响还更大你说在纠错这条方向上所以纠错现在看起来是一个比较主流跟大家认可的方向对 因为你做出来活生的例子你摆在那里了最像老黄或者说很多人说张口闭口就是什么要20年 15年 20年但是大家仔细想一想有什么技术人家开发到十几二十年或者说到现在这个阶段还要开发十几二十年的可控核聚变但是可控核聚变其实说实话它本质上规模完全是个技术实验问题因为想当年人类做核物理从证明做出了第一个裂变反应就真的只是做了一个实验室很小很小规模的裂变反应只分成几个原子那种规模到最后产生一个两代产品直接落地字面一落地用了三年的时间再跨越一个世代从下台面用了可能不到十年的时间所以实际上会发现核酷核变本质上它可能就是我说的就是如果还要实现什么说明这个东西在市场序设计上并不那么破清因为人类有大量的可裂变反应堆可以用说白了一你一定要用巨变的话你可以用氢氮其实也是可以发现苏联有相关的方案然后你要用可控口巨变的话那是一个非常elegant且非常ideal的goal但是坦率来说RI可能还没把裂变做大点高就人类现在的能量需求的话所以我觉得如果还要几十年的话这种技术大概率实际上它可能前置已经成熟了比如说巨变已经有氢氮了所以巨变这个反应其实已经落地了它相对于是second generationeven further improvement的一个过程像量子计算呢我们谈的更多是第一个落地的本身这个东西其实我觉得并不存在有这样的技术真的是发展了还要十几二十年去做出来的OK 对那我们刚刚其实点评了一些公司亚马逊现在的路线是怎么样的公开来说他们做的还是一种比较新的超导量子比特来进行scale超导量子比特的路线所有大公司做的都超导量子比特Google啊IBM啊亚马逊只是不同的超大量子比特从公开性来说呢亚马逊做的是一种比较新的超大量子比特叫Catcubit但是Google显然是产生了影响的是微软呢微软他们当年也是有历史原因的他们当时觉得量子计算很遥远他们其实开始的很早应该不比Google晚但是他们走的一个是叫拓扑量子比特的一条路子就是一个完全到现在为止都没有能证明Proof Concept的东西他们巴城已经放弃了所以他们现在最新的进展他们更多的是想去做因为他们硬件就把你废掉了跟别的量子计算公司进行深度合作比如说他们现在之前跟Honeywell的Spin-Off公司叫做Quantinion合作了所谓逻辑量子比特计算最近又跟Item Computing也是Berkeley的一个Spin-Off company做基于原子的逻辑量子比特计算微软其实一开始也很像Google一样重视容错量子计算Google其实更保守Google为什么选超导超导量子路线其实是个工程上早就被证明的那个路线因为你可以真的是把芯片造出来能用所以说从公司层面上来说的话实际上你只需要对它进行所谓的engineering improvement你就可以慢慢地去deliver这个成果至于快和慢很多时候跟你的投入和市场需求有直接挂钩的关系就像刚说的曼哈顿计划的例子市场有巨大的需求那就三年就能deliver市场需求相对来说要等待时机的话或者商业上的合理性的话那就可能会拖得长一点但是总体上说用超达路径你是可以直接把它给project out出来的微软当时就觉得这条路子可能都要走个时间就像说最早期大家的对未来的估算都是容易diverge的很容易就会说30年之后所以他们选了一个叫霍博量子比特那种量子比特的好处就是上来就容错然后它也对应的开发了很多软件他们也算比较早的量子软件开发公司然后现在硬件废了之后他们就把他的软件跟那些现在别的量子计算公司进行合作去做逻辑量子比特在别的量子计算上的运行所以实际上它跟Google很像也很重视所谓的容错量计算只是事后实现路径的时候Google其实选择一条硬件上更能proven的方式去软硬结合的去做这个事情而微软因为决策上的一些失误所以现在只有软件跟硬件公司合作所以我觉得整个过程大家对技术方向的把控还是蛮关键的一些决策的对那还有几家创业公司呢比如说IonQIonQ的路径主要是离子井离子井路径其实曾经很长一段时间甚至在10年以前被认为是比超导更有前景的路径因为简单一点就是基于离子井的量子实验其实是人类最早的量子时间拿了不少多本讲超导在很长的时间在2007年09年之前被认为是一个非常差的平台因为当时能实验上做出来的量子比特都不太行都非常差人类大概在09年从耶鲁开始把量子比特做得越来越好了然后终于所谓到了14年的时候可以到了所谓的纠错的预值也是Google参加的一个实验点IonQ他们那条路径呢为什么最好呢因为IonQ的这套量子体系其实是历史追求的然后同时也是在小规模量体系里面是最好操纵的可能就能讲所以说他们当时的路径就认为Traped Ion就是黎智景这个路线可能会更早地实践所谓的商业落地和所谓的Useful Quant Computer但是事实来说他们公司黎智景从他们公司创始到上市到现在一共他的量子比特的数量可能就翻了个倍吧差不多也有快多少年了现在是多少个量子比特他们17年创始的时候大概因为是学校大学出来的嘛所以上来从大学实验室搬的那套东西就有11个量子比特可以相互纠缠和计算你当年发了很多论文其实都还不错的工作但是后来发现你自己的这个路径就是当你要超越11个量子比特的时候工程上面有巨大量的科学挑战一个是工程挑战大家都很大但是你可以一步去实现它一个是有科学挑战科学挑战会更难它需要依靠基础科学的突破就是有更多的不确定性在里面你需要有更多的innovation去drive它所以你刚刚说他们翻了一个倍现在是22个量子比特现在差不多他们俩差不多20多个到30个之间吧现在业界最多的是多少个量子比特李子锦最多的应该是Honeywood那个32吧没记错的吗但是现在的问题就变成了当你的量子比特变多的情况下其实他们的一个trade off就是会发现李子锦的性能越来越接近超大就是量子比特变多它的运行性的比如说保证度这些指标越来越近超导了我应该说超导越近他们了导致一个现在很有趣的一个crossover就是以前认为超导不可能做到保证度大于99.9现在能做到了做到不止一个从小规模实验上来的话随着你自己变得越来越大反而从实验过程中应该说有各种挑战导致实际上你的tradeoff就是你的变大同时你的quantity在下降然后两个就像crossover了现在OK技术发展其实是一个很有趣的过程你会发现很多人当年玩到超车在其实发展早期的时候并不存在的可能性就像AI例子嘛Transformer去到GPT你不能为了避免用Transformer换一个别的完全不一样的架构去试错对吧但是很多以为自己可以玩到的例子反而就会那边翻车了玩到翻车所以说IonQ的问题在于它没办法一个clear way去做到现在超早这种skill他们会说我们有rude map了但是 yeahshow meHL Demonstration对这个是黎子锦DV我刚才说过的它那个完全不一样都不是Digital它那个是个叫量推火没办法用来做纠错对Rigetti呢Rigetti这个公司很传奇吧Rigetti本人就是当年在也有把第一个高保证度抄到比特量怎么做出来的人他的毕业论文就是他然后他把这套带到IBM和他同学在一起所以IBM最早的路径图就是根据他的那套架构起来的然后他自己开公司嘛反正各种原因吧他的公司的萨洛比特的一些小细节也变了变Rigetti我觉得其实在量子公司Starter上算是前辈了先驱但是因为可能有点太早了他13年创建了已经太早了所以说实际上你就 way too ahead of care然后就像说的你在Transformer某某某某之前创建一个AI公司你可能会end up变成先驱但是可能后面你就会momentum就display掉了你就没办法去用最新的技术最新的一些信息去做更明智的决定所以Rigate其实是一个我觉得我还是很respect他们的但是他们的整个公司的performing方式无论技术层面还是商业层面其实都现在有点falling behind但是他们CEO现在也不在了嘛Rigate现在也退休了实际上现在like all the startup stories所以我现在听下来我觉得是不是整个量子计算领域还是巨头的路线会稍微solid的一点比如说Google这些公司相比于创业公司它还是在一个更加领先的位置首先亚马逊不一定IBM因为之前选的路径稍微有点偏也真的不一定他们stay with他们自己的那个路径大概stay了个十多年然后他们在24年的时候就去年在他们发布他们1000量子比特的那个量子芯片之后把他们路线图改了改到跟我们有点像了其实你们的路线是什么我们算是很早就是用多个量子芯片做modular quantum computing这条路径的他们发布的所谓long range copper其实当时我们都做了我们公司创建就有加盟专利了这个事情NW就很有趣了我们创建的时候现在我们的路线图之前都没人明确放到自己的更新图现在IBM批尾过来了但这个也是我们从博克利Spin-Off的时候因为我们看到了过去10年整个量子行业的发展我其实不一定反对SATUP说玩倒超车的说法因为你做一个完全不一样的路子就像说你去搞一些完全新的量子比特去做这个事情不现实但你在架构上你可以比大公司要创新一些用一些更加矮角的更加灵活且更加高效的架构对因为更新对更新就IBM这公司以前我们COVID之前其实我们也跟他们那些人聊过嘛其实他们的manus side就是我认为我的这条路径只要我能走下去我有公司有钱有人甚至有信心那我为什么要去试一些新的东西呢我就直接做就好了呀所以他们不是很careover time的这种创新他们也不是觉得那个自己公司的一些小的架构的低效性对他们的整体商业落地有任何实际的影响因为对他们说技术进步的高效率上面那一点上下浮动对于一个百年企业来说其实一般对所以实际上这个大公司的话呢我觉得Google是一个很好的例子Google就是一个会去用创新的方式因为它的架构跟IBM也不太一样无计价格来说大家都吵倒了但是不太一样但是他们用了一个非常从UC Santa Barbara出来的一个路线就是可调性非常强非常灵活所以导致他们可以用这个灵活性先于IBM去做一些IBM不肯做到的事情对然后我自己还有一个问题你们怎么去衡量量子计算这个事它应该在学界做还是在工业界来做就比如说你其实也可以继续在学校去做这个科学研究也可以成立自己的创业公司去做科学研究我觉得这个问题如果对应到我们现在比较熟悉的AI领域的话比如说当Scaling Law它已经成立的时候那么其实你在工业界你有更多的钱跟卡你是更容易出成果的那么量子计算它现在是一个什么样的权衡跟评估呢就是量子计算其实在19年之后就很明显了学术界根本干不过工业界包括我们以前组的同学不是去亚马逊就是去Google就是去IBM就大公司来说的话现在基本上我们无论是Caltek还是Berkeley出来的那一届同学或者后面这届几乎没有进入学术界的为什么你也看到AI是这样子的美国学术界认为学术界的作用不是去跟大公司比谁先落地谁先把东西做出来谁先有什么商业化成果谁先有应用时间规模做大学术界不惯这个美国学术界的特别是越好的机构学术界的这个核心的职责是干嘛是去做快速试错快速的开发去做探索比如说在大家都不觉得量子计算能做出来的时候我去做超导线路我去做离子进然后我去电这个机举个例子吧Google做量子计算的时候是13年UC Santa Barbara的Martinis组它在超导量子计算平台上跨越了所谓的量子纠错预指就是保证度大于99%李三丽丝念的时候所以Google那个时候认为量子计算从科学问题变成了一个工程性问题所以那个时候才后面这些话所以从学术界干嘛呢就是在大家还是科学问题的时候去探索能不能去proof concept这个是工业界可以接手的所以从现代来说的话呢现在基本上学术界为什么现在大家都不学术界因为学术界没这样的资源而是学术界其实现在也不怎么hire做出版了就是这种我说我的构是为了把量子源做得越大越好学术表示那这个东西但我说的是比较好的大学大学跟我们好顶级大学有什么关系呢所以其实我理解工业界探索的是落地然后学术界它其实还是在最初的那个小苗头的方向上的一些探索对 就是工业界完全觉得这玩意儿没有ROI的时候学术界是蓬勃发展的时候当你证明了你现在不是个科学问题现在是个工程问题的时候工业界就完全takeover因为工业更有目标工业目标是把它做出来而不是发轮文是的造一台量子计算机大概需要多少钱如果只中了目标成本上来造一台量子计算机的话呢差不多在100万左右如果你知道怎么造的话也不是错的话比我想象中要便宜然后Google现在他们的量子计算机大概是有多少Qbit微楼啊100吗100我发现大家在提到量子计算的时候经常会用量子比特的这个计量单位然后会去看它有多少的量子比特就是你可不可以跟大家通俗地解释一下这个是什么意思为什么每次当它的这个量子比特数要增加或者翻倍式的增加的时候就会去遇到一个难以突破的学术问题其实增加一倍的时候就是典型的就像造芯片一样当你把芯片的规模就是它的那个硅片如果你只是把硅片造大然后放更多晶体管上去的时候你的芯片整体工作的良品率在下降所以你造更多的时候你的芯片对于一个所有量子比特都在理想它工作的这个范围里面的那个微纳加工之后精度的要求越高比如说你造1000个量子比特可能其中真的能串联起来Work的可能就300个所以如果造1000个有意义没有就变成了一个pure show就没意义了对吧像离子井刚才说过的离子井去禁锢离子的方式会导致它当离子的数量超过11个到20个的时候它的禁锢难度会越来越高一个是个物理问题一个是个fabrication微纳加工和设计问题That's why就是很多大公司都会选择超导路景因为微纳加工说实话半导气工业已经四五十年都变成西洋产业了做个100纳米飞圈的东西还做不出来这个有点说不过去今年开始从去年下半年开始会发现半导体公司也慢慢开始了比如说硬材还有一些传统半导体的设备加工和芯片工厂已经慢慢开始有自己的量子芯片的流片的一些工作了跟一些创业公司开始量子计算并不是AI早期或者说半导体早期这种情况就是逐渐的你的下面的公司像Google像我们慢慢证明这东西可以做做得越大你越有回报那上面的那些像半导体设备公司办到几斤原厂那就开始感兴趣了这个意味着我们就可以接受呀对吧这个是个很典型的一个商业逻辑我觉得所以今年VC投量子计算你们有感受到这个市场有在变热然后钱在大批的网里面涌吗我觉得现在来说因为降息也是一个相对近期的时间嘛并没有明显感觉到传统VC的投资变多嗯 什么样的投资变多战略VC国家主权VC比如说John Martinis就以前Google的那个量子计算的负责人或者以前Usses & Barbara的教授他的新公司叫Collab他这个公司就在去年拿到16个Million从日本的发展银行还有一些别的机构拿的钱所以总体上来说就更加偏向于就是一个Syses吧就是现在处在敏感阶段的三个行业先进半导体AI 量子我们可以总体来说先进半导体是一个非常传奇的过去然后AI是个非常蓬勃的当下量子基本上是不可避免的未来所以在一个加息周期里面的话呢政府会对这个不可避免的未来更感兴趣但随着减息周期的开始我觉得像VC对整个行业更加关注特别是Vilo的出现我觉得我就会Ramp up但是就看下一个加息周期的持续到什么时候对你刚刚提到的这家公司就是日本发展银行投到他们我理解是不是量子计算如果实现了它对整个全球的密码系统会要求有一个整体的密码系统的升级然后大家在安全层面上来有一些布局呢这个已经开始了已经开始了这个都不用说大家都知道了两年前那个拜登的那个行政命令了要求所有联邦机构在应该是今年会形成法案还是去年就行进法案我都忘了要求联邦机构将自己的加密数改成那个所谓的抗量子加密国家标准制定局大概在去年的时候定下了三个标准加密数已经抗量子加密所以实际上两三年前就开始了然后去年二月份的时候新加坡金管局建议了所有新加坡的金融机构采用抗量子加密数和安全密钥叫QKD一种量子通讯手段然后让你的金融数据可以不被泄露出去这个逻辑其实也是涉及了刚才大家说时间线的问题为什么大家从两年前金管局就是新加坡央行都在做这个事情呢然后汇丰你也看到汇丰其实都已经在英国做过抗量子加密数和安全通讯的试点网络了很多银行也在做像JP Morgan Chase他们也算是这个领域里面非常大条鱼他们有active的抗量子加密和量子通讯的那个基础设施和项目发展都是公开信息所以密码学也是在蓬勃发展抗量子算法的密码学抗量子发展算法和量子通讯因为通讯其实可以抗量子计算其实这些东西会发现很有趣的就是之前说政府在主导这个我可以理解其实从去年开始是金融界在这方面的进步非常大基本上你听过的银行都有这方面的独立项目和共同项目甚至央行所以这一点其实回到刚才的问题我觉得很多人就是不要看他说什么对吧说得保守点再看他做什么如果这个量子可以破解加密数的量子传机还有10到15年出来为什么现在大家最有急着去改变自己的技术设施呢是所以你觉得大概量子计算它什么时候可以破解这个银行的密码呢因为是这样的就是在谷歌威乐芯片发布的那一天然后那天观察了一下比特币的价格是大跌的因为其实市场上已经非常广泛且非常长的时间就流行了一种说法说量子计算它是非常容易去破解比特币的算法的因为比特币的算法其实分成两部分一部分是它整个挖矿的机制的算法那还有一部分就是它的私要的椭圆曲线签名在这两部分的算法里面据说椭圆曲线的签名它是最容易被破解的甚至它比破解传统银行系统的密码还要更容易不知道你们理解是这个样子吗对 像刚才红军提到的比特币确实是分两种加密系统的那我们这里就要提到一种刚才已经聊到的算法就是数二算法它是一种专门针对大数分解和离散对数问题的一种量子算法它可以在以多项市时间内破解这个椭圆曲线签名这种针对的不仅仅是比特币系统而是所有的它的公钥是公开的所有的加密系统跟这个相关的都会被针对然后可以比较相对轻易的会被这个数尔算法所攻破这与银行系统不同银行系统它是没有公开的密钥的银行系统的密钥它本身也是机密信息不会暴露在外但是比特币用户的钱包的公钥是公开的在链上可查的任何人都可以通过区块链网络去访问这些公钥所以说没有量子计算机的时代你拿到公钥是绝对不可能算出也不能说绝对不可能吧是一个非常大的cost可能几万年才能算得出私钥但是有了量子计算机和舒尔算法的情况下在量子计算机有足够的能力的情况下拿到公钥之后算出CL是一个非常可行的过程多少量子比特才能破解有人说需要4000个但是其实我们现在离4000个量子比特还是有很远很远的距离的这点我先correct一下4000个3000个比特数量呢它们assumption是什么呢Shware algorithm要求的是你的量子比特是没有错误的就是完全容错或者完全纠错量子计算机的就你要有一个4000个量子比特所谓大规模容错量子计算机去跑所以这个就是老黄的very useful quantum computer按照老黄的预测大概在15年之后但你看大家的动作来说显然不设送15年之后毕竟当这个东西已经开始威胁到自己的钱包的时候大家的敏感度就变高了所以我觉得能破解到加密数的量子算机就是所谓的very useful大规模容错过量子算机的出现可能还是要10年之后而很多机构和公司特别是银行还有比特币特别是银行你好现在已经自己implement这套加密数了的原因在于万一呢对因为这个不是说一个绝对的吗这是一个estimation对吧像GPT moment说实话在2022年初的时候21年的时候大家不知道这个进展会觉得啊那你当时的普遍认为就是像GPT这种能通过图定测试的AI还要8到10年的时间但实际上也就几个月的时间所以说实际上经过这套之后很多的议题有点技术突破有点像技术爆炸你无法预测它什么时候发现我只能说我合理推测10年左右会出来但是如果5年之后出来甚至明年出来我不会极端的惊讶但是没有说完全不可能没有物理规律说不可能这个Fundment是工程学问题你刚提到了银行他们是都有去做这种抗量子算法跟量子通讯的布局的嘛同时我也看到比特币他们的核心团队Core团队他们可能也是在看有什么样的方法可以抗解量子计算机但是就是因为你刚刚提到了量子计算机它可能实现的就very useful的完全容错的量子计算机它出现的时间可能是快速的它不是匀速的它可能是快速的大家不经意间就很快实现了的也可能是需要比如说10到15年甚至15到20年那我可不可以理解成那现在就变成一场竞赛了看谁先出来就如果说有这么强的非常powerful的量子计算先实现了那就会对还没有来得及升级的这些密码系统造成非常大的威胁另外一端就是大家在抗量子密码学的改善上大家有很多的升级那它可能是一个非常平缓的过渡首先密码学的替换这个相对来说比较简单抗量子加密数本上是个加密mechanism的替换这个很大程度上是个软件升级问题或者是一个硬件的替换问题比如你要高速加密的话你可能需要一个单独的硬件ASIC但这个包括去年国家标准设计局制定了三个标准抗量子加密算法之后实际上大家商业化层中讲书来讲你就去符合标准去implement就好这也是为什么你会看到像汇丰其实去年也发布了他们的crypto在香港发布的他们那个crypto还带了量子抗量子加密抗量子加密这东西其实转变来说加密数据本身并不是一个所谓很慢的过程你得去做跟复杂的反而是像量子通讯叫QKD这样子的很多银行也在做QKD完全不依靠你的加密数本身抗量子加密而是靠物理层面的格局这个也是一条路子但这个更慢一些因为它毕竟涉及到光线网络这些东西但是很多银行行事也自己在推甚至我们接触的一个银行partner他们说现在很有趣的情况是是银行才去要求这些通讯公司像ATT去deploy量子加叫光线QKD网络来帮助他们在华尔街可以进行安全的通讯这个还是挺有趣的反而是银行倒闭通讯公司做这个事情因为公司干不出来他们自己大银行也自己在搞还有一句话任何这种potential data breach他们是billion dollar loss他们不会take the risk的所以说实际上我不是很担心真的是因为解密的能力的提升导致所谓的金融体系或者虚拟货币体系的崩溃从技术方面上我不觉得但是还是那句话三题有句话说的很好嘛傲慢才是最大的问题还有我消灭你与你无关对吧我觉得现在大家都而且很好包括银行机动机构你跟他们很傲慢的时候但他们其实在这好运气里连着不傲慢他们反而是想play safe所以说实际上我觉得包括像crypto他们其实也可以再迭代他们的加密方法是让他们更加 secure这个我觉得是可以做到的并不是一个Rocky Science的问题我觉得它不是很难的像你们这样的公司的商业模式是什么因为我理解其实量子计算要把它实践都很难然后它也是一个高研发驱动的你们会是怎么样去找这种商业化的场景呢这个挺有趣的我们公司的主要业务是什么呢刚才说的就是研发制造和销售有量增强性或量子计算平台计算设备俗称量子计算机OK我用了很多定义但是量子计算机因为大家的理解不太一样有的理解是very useful有的理解就是partually useful像我们的理解就是更多的补充适合这个未来五年到十年这个阶段当量子计算从leer turn到变成very useful阶段里面所有的应用落地你会发现其实现在很多大公司他们也在做量子应用包括量子机学习这样的事情Viral Useful量子算机是完全融出量子算机是你完全可以通用地去编程的量子算机基本所有算法包括解密加密都可以装但是我们这个毕竟是一个连续性过程你在中间这段时间之后这个金山我们都知道你把它跑完了之后肯定全是金但是在把土跑完之前你有没有办法攫取最大的红利这个是很多中间用户在思考的问题无论是那个中单用户是一个大型银行是个央行你也看最近那个新加坡的央行金管局在七月份发的那个program就是促使新加坡的金融机构去开始利用量子计算来进入到他们的一些业务里面去去辅助他们的业务的发展现在处在一个很有趣的阶段就是很多大公司和国家都在想这个肯定有地方可以决到第一笔红利与其别人决到不如我去决到所以就给我们这种带来了比较大的一个气息我们可以向大公司和一些基础设施发展项目计算设备进行配套我们的量子计算设备或者说量子增强设备就是我们本质上变成了一个服务器供应商这点其实也是我们目前客户的主要的角度他买我们的设备买我们计算机过去干嘛呢其实我们最大的revenue来自于将这些数据中心提供我们的量子计算机所以你们现在已经是有收入了对不对那我们有能打拼吗严格意义上说从Gloss角度来讲是profitable的我们确定是哇 厉害厉害最后一个问题就是对于普通人而言你觉得量子计算它会去影响普通人的日常生活吗还是说它其实只是会在比较高精尖的领域里面去默默运转我觉得普通人的话呢更多这个东西就能像计算机早期诞生的时候它会服务的什么呢就是一个大型跨国机构或者说甚至一个国家政府的基础设施的需求它提供的是更多的后台的需求为比如说未来的能服务于普通人的化学产品或者金融产品或者AI产品提供助力有点像GPU嘛GPU其实很多年以来大家都指这些游戏玩家在玩嘛有段时间是给挖矿嘛然后现在其实GPU才慢慢真正的是所谓的无理玩玩游戏你都得跟我打交道但是也是从数学中心的角度来服务大众的我觉得这样计算也会经历这样的过程我们会先去服务一些比较特定的高价值客户对我们的角度来讲像计算机早期一样服务基础设施项目计算机构然后通过他们去间接服务不同人那随着根据老黄的Very useful quantum computers出现在那个年代其实不光意味着这样的计算机可能到了一个完整形态甚至我觉得在那个年代这个产业链也更加成熟生产效率也更高所以这个成本也会变得越来越低计算机早期很贵的当IBM最早做的计算机产品的公司那个Watson他的当时的chairman经典的误判就是说全世界只需要五台计算机因为他数了数需要计算机的政府 军队 银行然后后来发现明显误判了因为就是有点计可弹的问题有更多人去用了然后发现更多的用途了然后就会有更多需求然后更多需求drive了更多的产量更多产量会让成本下降因为本质上来说量计算机几乎没有用到稀有金属是什么驱动了它的成本呢很多人来说就像航空航天部门一样是因为这个量没上来OK 懂了懂了所以也是先服务于高精尖再慢慢地蔓延到普通人好的 谢谢谢谢两位谢谢Roger 谢谢Jerry的非常精彩给我们文科生做了一下量子计算的科普谢谢 谢谢您的时间很高兴跟各位分享然后有任何问题随时follow up就好了好的 好 谢谢两位谢谢宏君如果大家对量子计算以及本期的节目内容有什么样的想法欢迎大家给我们写评论写留言那中国的听众可以通过小宇宙苹果播客喜马拉雅倾听FM网易云音乐来收听我们海外的听众可以通过苹果播客Spotify还有可以在YouTube上搜索硅谷101播客来收听我们我是红军感谢大家的收听谢谢优优独播剧场——YoYo Television Series Exclusive
