---
id: 254c28f3-cfcd-4fe7-b3de-0f8392c5d386
source_type: podcast
source_key: guigu101
title: "E161｜聊聊大模型如何思考与深度学习科学家Yann LeCun"
url: https://sv101.fireside.fm/167
published: 2024-07-29T00:15:00+00:00
downloaded_at: 2025-11-28T14:23:38.260736+00:00
---

# E161｜聊聊大模型如何思考与深度学习科学家Yann LeCun

欢迎收听硅谷101我是红军从ChatGPT到特斯拉V12自动驾驶神秘的大模型一次又一次地在工程界给人们带来惊喜当人们输入一个数据大模型就能直接输出一个答案但整个中间过程是怎么样的没有人知道我们把这个过程称为黑核也正是因为黑核的不可解释性所以AI的安全问题在当下受到了很多大佬的质疑有一群科学家他们在尝试去解开这些秘密业内称之为白核研究今天我们邀请到了加州大学戴维斯分校的助理教授陈宇北他博士是从加州大学伯克利分校计算机神经科学家Bruno Oshausen博士后是从纽约大学的深度学习专家杨勒困教授杨是2018年的土林奖得主被业内称为卷辑网络之父同时他也是Meta的首席科学家今天我们就来和于北聊一下黑盒模型的拆箱进展以及与之相对的白盒模型也许不用所有的人都了解黑盒的秘密但是总要有人打开它哈喽 于北你好你好然后今天跟你聊这个话题呢其实我主要是想聊一聊白河模型所以你现在是在研究这一块对这个方向呢其实它的一个比较大的目标呢就是把我们现在看到的这种深度学习从一门纯经验性学科向一个科学学科来推动或者说工程变成科学其实主要的一个动力是来自于这种工程上的一些进展而它的科学发展相对来讲又缓慢对那在你自己做这个白河模型研究的过程中啊你有没有发现一些我们怎么去解释GPT它的输入输出它到底是怎么推动已经出来的一些研究成果我自己的工作呢早期做过一些以前有一个模型叫做词的嵌入吧Embedding它可以学到一些语言的一些表征大家当时其实就有一个疑问说我们做任务的这些性能变好了可是是什么导致这个性能变好的所以我们当时做过了一个非常早期的一个工作就尝试打开词汇的这些表示当你把它打开的时候你会发现一些很有意思的现象比如说苹果苹果这个词苹果的这个词它有一个机器学区出来的一个表示当你把它打开的时候你会发现你可以找到里面的一些原意思比如其中的一个意思可能就是代表一个水果的一个意思然后另外一个意思它代表甜点的一个意思然后你再往下挖下去你会找到有一个是技术和产品那当然它就指的是现在这个苹果公司的这些iPhone这些产品所以你就会发现在所有的这些意思里边你能找到这些原意思那么顺着这条路呢你就可以去把这样的方法延伸到大语言模型里边当我们学完一个大语言模型以后我们也可以尝试在这种大语言模型里边去寻找它里边所带有的一些原意思然后尝试去打开当你做这些事情的时候你会发现一个大语言模型它有很多层嘛在初级的这些层里边它会出现一个现象是说词语的消奇比如说像在英文里边有个词叫做leftleft这个词它既有可以当作是向左转的意思也可以说我离开的一个过去式那么具体它是什么意思在当前这个语境下要取决于前后的这种上下文所以它的语言模型你会发现它在初期的几层里面它就把这个词语的消奇就做了在中期你会发现有一些新的意思也可以产生当时我们觉得一个很好玩的意思是它就做一件事情它就做单位转换一旦你说多少的公里变成英里这个转换然后一旦你说多少的温度从F就是华氏变成摄氏度的时候它就会被激活就这个意思会被打开所以当时我们觉得这就很有意思你可以顺着这个路找到很多相似级别的这种原意思然后你可以再往上走再往上走的时候你甚至会发现有一些这个原意思它只检测一种规律这种规律就是说当你的这个上下纹里面出现了一个重复的一句话的时候或者重复的一个意思的时候它就会被激活比如说在星空联谋的广播里面当你说广播播放了两遍你就发现这个意思它被激活了然后或者说你说在歌词里面我重复了一句歌词它也会被激活所以就是说你会用这样的方式可以去打开大语言模型以及小语言模型对吧那么当然这些思路呢也并不完全是新的它在视觉的模型里面其实已经有相当的历史了就比如说从马苏·赛勒开始就是有一些这样的探索那顺着这个思路是不是如果我们知道了它部分是怎么运作的我们可以从工程上对它有很多的优化对这个是一个非常非常好的问题我其实觉得理解的比较高的标准或者是说做任何的理论它的一个比较高的要求是可以指导实践所以在我们当时做这种语言模型还有词汇的表征的时候其实当时也有的一个目标就是说当我们理解以后我们能不能反过来优化这些模型其实是可以的就比如说举一个例子如果你在这种大语言模型里面你找到的一个原意思这个原意思它可能当它看到某一种原意思的时候它就会激活那这个东西它这一个神经元它就可以被作为一个判别器你就可以用这个东西来做一些任务当你找到了这么多原意思以后呢你可以通过对这些原意思的改变改变之后呢你就会说我这个模型以前它有一些这样的一个bias或者说这样的一个偏见然后你可以通过对这些偏见的一些调整如果我能发现它的话那我可以调整它然后我看到去年OpenAI它还有一项研究它的那项研究就是用GPT-4去解释GPT-2看GPT-2到底是怎么工作的比如说GPT-2的神经元在回答所有跟美国历史1800年前后的事情的时候是第五行的第十二个神经元会被激活在回答中文的时候是第十二行的第十三个神经元会被激活那如果说我们把它回答中文的这个神经元关闭的话它对中文的那个理解能力就会大幅地下降包括我们去看它说到跟加拿大有关的信息的时候就是第21排的这个神经元但是我们就看它越往后的这个神经元比如说它的神经元到了2000排左右的时候那它整个的可信度就已经下降了很多你有没有观察到这样一篇论文具体这些数字我还没有读到这篇文章不过这个方法呢我觉得其实你如果要仔细想这件事情的话它非常像是给大脑的神经元做手术就是相当于我现在如果有了一个神经的网络如果这些网络的它的意思从某种意义上它能找到一个局部的一个存在的话对吧它不是完全分散的然后它是相对能够找到这个意思的话那么我就可以相对来讲对它进行一些操作比如说我把这个神经元切掉了那你就可以认为它这一块的能力相对来讲就损失掉了就是人其实也是一样的就比如说我在人如果有癫痫然后有的时候做完手术了以后可能会出现某一些语言的一些障碍对吧但是其他的功能不受损失多少我觉得是从原理上看起来是相似的OK那你觉得你的研究跟OpenAI包括Atherapic他们大家都在研究这个大模型的可解释性他们之间有什么区别呢就是说白核模型的研究呢是否我们将来能成功这件事情我不知道因为在这件事情上实际上我也跟了我的导师我们也都讨论过大家一致的看法呢是说这件事值得尝试但是是否会成功我们都不知道如果我们回到这块的话我们其实是想理解这个人工智能并且通过我们的理解重构它对吧构建出来一些从根本上不一样的东西那么观测就是说从解释性这个我觉得只是一种手段就是说打开这种模型也好我做这些实验也好我尝试去根据我打开的这些东西来对我的这些模型进行一些调整也好我认为这都是我们在理解过程中所谓的一些尝试的一些手段但是我觉得真正重要的一个白盒模型它的本质呢实际上要回到这个信号的本身因为不管是人脑也好还是机器也好他们学习的本质呢是因为这种信号我们这个世界中存在一些结构他们也要通过这些结构来进行学习学的也正是这些结构那么我们是否可以找到这些结构背后的规律以及表示他们的一些数学工具然后把这些东西进行重组构建出来一个不一样的模型如果这件事可以完成的话我想可能可以带来的一个希望是说我们可能会提高我们的系统的鲁棒性也好安全性也好可信度也好但是还有一点其实我觉得是如果我们看历史的话最重要的一点可能它的efficiency也就是说它的效率会提高就是这个例子多少有点像是一个以前我们一开始是这种蒸汽机先出来了后来才有了这些热力学这种理论出来了才能支撑把它从一门完全的工匠的学科变成了一门科学那么同理到今天来讲的话我们现在就好像我们第一次在数据上有了我们的蒸汽机一样我们从以前不理解我们的数据终于可以开始做出来一些AI的这些算法把数据中的规律给抓出来所以它会更节能你要说到节能的话我可以给你几个有意思的例子第一个数是说肯定是节能因为大脑呢它相当于一个基本是20瓦的功耗的一个灯泡那我们现在的超级计算机呢它可能要超过百万瓦那它这样的一个功耗首先这是节能对吧第二点是说如果我们看自然界的各种各样的这种生物大自然进行演化的时候它演化出来的这个生物它其实效率非常非常的高比如说我们举个例子像有一种生物叫做Jumping Spider它是一种特殊的蜘蛛这个蜘蛛它只有几百万个神经元但是你如果看它的在世界中的这些行走的话它其实是可以做出非常复杂的三维的群线去捕捉它的猎物比如你在一个很复杂的一个草丛然后这边是它的猎物它可能要分析整个的结构然后它发现我应该先从这下去然后再走过来再上去它要能理解这种三维的结构然后达到它的猎物它有这么强的能力还要控制自己的话它只有几百万个神经元那么我其实觉得最有意思最有意思的一件事呢实际上是人对于数据使用的效率我觉得这个很有意思你看我们现在AI在过去其实不长的时间对吧就是大概有12年这个样子12年是从哪一年开始的14年吧我觉得从ImageNet我觉得可以作为一个分水岭因为ImageNet多少可以认为是一次对数据scaling大范围的一次尝试就是数据李飞飞的那个项目对对对对是的很多人说就是把AI的发展的这个年它断到叫AlexNet就是AlexNet出来那一年也就是说在ImageNet上它的性能提高上去了但是我其实更倾向于看到的是说在这之前2010年的时候这个数据其实从原来的小数据变成大数据了这个是一个分水岭那么在这短短的十几年里面它取得的进展其实是巨大的到今天来讲我们的这种大语言模型比如说LAMA3我印象中它现在可能也变得数据量更大了应该是13个Tillion的这个token但是如果你想人在自己的一生当中就在你的成年之前你到底能接收多少的数据呢不管是图片也好还是文字也好我认为这个magical的比较神奇的这个数字呢是10个billion就是你假想这样我每秒钟都可以获得30帧图像那么这30帧图像的话你一个小时有3600秒你每天假设你这样做12个小时然后你做20年那你得到的大概就是10个billion同样的话我可以不间断地在做阅读对吧我每秒钟我可以阅读30个token大概10个词这个样子那我阅读也是像刚才那样阅读20年的话我得到的也是10个billion那问题来了就是说人是如何通过如此少量的一个数据看似少量的数据跟大模型比是已经很少了对吧这样一个数据获得如此强的一个泛化的能力呢我觉得这个又是一个efficiency里面最让我觉得神奇的一点那你觉得我们去揭开大模型到底是怎么运作的跟揭开人脑是怎么运作的哪个更难我听起来都很难这两者它各有各的难法我觉得它们方法上是相似的对吧就是不管是人脑也好大语言模型也好我都是我尝试去观测它看它对什么产生了响应这个方法我其实觉得从Hubo and Vessel就是当时他们得诺贝尔生理学奖他们是研究在视觉皮层里边的这种叫做simple cell就是人的这种视觉皮层大概就是在后脑的时候这个地方然后从眼睛过来然后再传到后边的这个枕叶他们找到了这样的这种simple cell并且尝试研究人看到什么东西的时候这些神经元它会产生冲动然后他就可以分析我让你看不同的东西看你有的时候完全不响应有的时候那非常的高兴这个神经元然后那我就想知道你看到什么东西能最佳地让它兴奋他们就找到了这个神经元的Receptive Field那我们今天来研究这种大语言模型的话其实也是相似的我们就来找这种不同的输入让我们的大语言模型我们尝试理解它内部的哪些神经元是对哪些输入感兴趣对吧其实是相似只不过它有个区别第一个区别我认为是对于大语言模型我们的优势是其实所有东西我们都可以观测并不是受限于我们的观测手段对于人脑你就有很多的受限手段你以前是可以插一个电极然后后来你可以插一个电极上面比如说12个电极再后来就是脑机接口的那一套对对对是的然后现在你可以比如插上几百个这样的上千个的这种但是你毕竟你的观测手段是受限的不管你是用FMRI还是用不同的这种Neural Pixel这种侵入式的非侵入式的它们各有各的局限所以大语言模型给你一个天然的好处就是说你的观测手段不再受限了如果你有更好的方法你就可以尝试去分析甚至你还可以整个的模型还是可微的对吧你可以通过一些微分的方法进一步的分析但它的缺点是大语言模型的能力呢我认为还远远不及大脑尤其是这种大语言模型如果我们给它一个例子的话它只从这种语言里面来学习这个世界它的对世界是理解是不完整的就觉得好像是说一个人他没有了其他的感官只有语言大脑处理的是更多维的信号对不对它除了语言还有嗅觉非常多维对听觉对就是说他的这种感官的丰富的程度他对世界的理解呢很多的时候甚至有的时候我们可能会想一个问题就是说语言是否是完备的如果没有其他感官的支撑的话语言里面是不是所有的概念都可以独立的存在还是说他一定需要其他感官作为支撑你才有可能说来最终的理解那一部分的意思就比如说举个例子我说在语言里边我可以说冰箱这个东西呢你如果不和现实的这种世界构成一个这种冷热呀等等的当然你可以通过冷热的这种方法它有门的这个东西来描述这个冰箱这是通过它这种统计特征但也许这种描述永远是不完备的但具体是不是完备的我也不知道我感觉是不完备但我也没有办法去把它完全的用数学证明或者所以说其实现在整个大模型跟大脑相比它还是欠缺非常非常多层的但是因为我们可以看见的更多可以把它拆开来研究所以我综合你的观点就你觉得它还是会比揭开大脑的秘密的这个野心稍微更进一步的理解大语言模型它的难度当然就在于你观测的手段多你可能能对它理解的更加多一点我的感觉是这样对吧有两台机器一台机器你完全可观测一台机器部分可观测那我从直觉上来讲是一些完全可观测的这台机器更容易被理解当然它有一些能力是这台机器没有所以不能取代对人脑的一些理解对 我跟听众简单介绍一下于北之前是学Neuroscience的所以也是懂非常多神经科学相关的知识其实我挺好奇就是你觉得之前你学的这个学科背景包括我们对整个神经科学的研究对现在你来做AI方向的研究会有什么帮助吗或者说它会不会有一些跨学科可以相互借鉴的研究方法在里面对 我学过一些计算神经科学但是我是个半调子我其实一直也不是专业学计算神经科学的我本科的时候在清华是电子系在伯克利的时候其实是在伯克利A Research也是电子工程计算机系然后还有一些纯数学的一些背景然后呢 我当时我所在的那个研究的研究所它是一个理论神经科学的研究所所以我导师自己是计算神经科学的专家那么刚才的这个问题是说计算神经科学也好神经科学也好对于我们研究AI有什么不一样的帮助我的感觉是说对于我来讲的话这种帮助通常来讲是一种启发因为当你知道自然界的这些系统有的时候你知道它可以做到什么的时候或者它面临的一些情况是什么样的时候你可能会有不一样的想法会重新看待我们眼前的这个问题我可以举几个例子这几个例子很好玩就是说我们现在习以为常的一张图片这张图片的话它是一个像二维的一个输入信号它有很多的pixel像素这个像素呢它会分有横向的有纵向的然后它形成一个网格但如果我们看人眼的话你看人眼的视网膜的话它不是长这样的首先它的这种不同的感知的这种接受器感受器它是非常密集但又不是非常规则的方式排布的而且它中间非常的细密像两边的时候会变得稀疏当你面对这样的一个输入信号的时候你会想首先一个问题说我们习以为常的这些卷积神经网络什么的这些东西所有的这些东西都失效了因为连卷积在这里都没有定义所以当你看到生物系统它所面临的这样的一种情况的话你会重新去想我们所谓的这些卷积到底从何而来所以你会重新去想你的方法是不是对的是不是一定要以这种方式来实现对假设你第二天你醒来的时候所有的神经元都打乱了然后你还能再去理解这个世界吗就是因为你已经看到的已经不再是一张图片了你也不能再用卷积神经网络来做这件事情了那你怎么去理解这个世界呢你需要什么样的方法其实还是可以的我们没有完全解决这个问题但是我觉得做了一步那它挺有意思的这个是怎么做的呢你就可以说虽然我的所有的神经元都打乱了就是我们的感受器图像里面的这些像素打乱了可是相邻的这些像素呢它们有一些关系比如说我们看图像里面的话我会发现如果一个像素是红的那周围的像素也更可能是红的这是它们统计上的一些关系那么通过这种关系呢你就可以去让这些像素它们重新去找朋友然后你就可以把相似的这种像素呢让自己自组织成一些关系这样的东西然后这个时候你再加上我们的大语言模型的这里面的这种Transformer啊这样的结构你就可以重新的对这种图像做出一个表示而且这个表示的最后的它的性能还不错这个就是一个具体的例子就是说完全就是从一个自然的一个启发那我们重新去审视我们现在一些工程上的一些做法然后提出来一些不同的方法嗯 对感觉整个研究AI大模型跟看人脑跟神经科学是怎么运作的还是有很多相似之处的我好奇会有神经科学家从他们的这个角度来研究跟你们产生这种跨领域的合作的吗其实有很多的神经科学家以及统计学家然后数学家他们想要理解自然信号中的一些结构同时呢也会关注大脑中的神经元他们是如何运作的然后把这两者结合在一起尝试去提出一些极简的对于信号的一些表示举个例子就是说在大脑里面啊你会发现有一个现象就是说这个神经元虽然很多但是同一时间在工作的这些神经元就是兴奋的这些神经元它其实非常非常的稀疏也就是说比如我给你一百万个神经元可能几千个他们在工作那么这里边的问题是说那他们到底学了一个什么东西其实早年的时候神经科学这边就提出来一个方法就是我当时导师他们的参与研究这个工作叫做西书编码那么西书编码当然它不仅仅是一个神经学方面的一些看法同时他在统计学下也在同期在提相似的一些思路也就是说在这种高位信号中那么我们能不能找出一些稀疏的低位的一些表示从这样的思路出发你就构建出来的一个算法它也会学出一个神经元的它的表示然后你会惊奇地发现你学出来的这个表示它和你在大脑里面观测到的这些神经元的这些表示非常非常的相近所以这个是当时计算神经科学的一个早期的算是无监督的一个成功我觉得到今天来讲的话我们的整个的这一支我管它有一个名字叫做自然统计信号的研究叫做Natural Signal Statistics它的目标就是揭示信号背后的一些基本结构它的发展其实相对来讲挺慢的你会和这种大模型它的进展来看的话你会发现大模型的进展非常非常快但相比之下呢这种白核模型啊这类的神经科学的结合它相对来讲走得慢一些我其实觉得一方面呢可能是因为问题复杂但另一方面也是因为投入这个方向的人比较少简单来说就是研究白盒模型的人太少了但是像我们之前研究的比如说传统的机器学习的这种算法线性回归决策术等我们都可以理解它是白盒模型简单来说在大模型出现以前我可不可以理解成整个传统的机器学习它可能就是属于白盒模型的范畴我觉得这个说法可以认为是对的就是说以前的这些机器学习的模型相对简单你都相对来讲可以理解它们类似于现在我们看到的这些大模型包括扩散模型它们其实是可以算作属于是黑核模型的为什么说现在整个的黑核模型看起来它在研究跟进展甚至在表现跟大家的观感上对白核模型它是实现了一个弯道超车甚至降维打击对对对对为什么它的速度可以快这么多这个问题你问出来我们就先是紧张一下对吧然后再回答那么我为什么紧张这个问题就是因为它很尖锐其实这个问题就是说那是不是白核模型或者说可以理解的这条路径我们应该放弃了呢就是说我们是不是在AI的研究上从我们这个时代开始我们已经不再研究科学了就是说它从以后全都变成一个经验性学科呢我觉得还不是但如果回到你刚才的这个问题就是说到底发生了什么在这个过程中为什么现在这种黑核模型往前跑得快而白核模型跑得不够快那我认为首先一点呢就是说黑核模型的包袱少你既要这个方法可以工作可以work然后你同时又要这个方法可以解释你有两条要求他放弃了一条放弃了一条我可以让他工作那这一条是一个非常非常重要的一条第二个我认为一个很大的一个被大家所忽视相对来讲甚至被很多科学家所忽视的一个东西呢我认为是数据的密室增长或者说规模扩大的那么我认为这个在过去的十几年来讲甚至有一个我记得Richard Sutton写了一篇博客文章他就讲叫做Bitter Lesson一个痛苦的教训他里面提到了一个事情就是说在过去的20年里面有一个一直没有被打破的一个东西就是说当我们有更多数据当我们有更多的计算你总是应该找一些比较能够真正扩张的算法他能够把所有的数据的这种规矩找进来我认为这个是黑核模型里边或者说我们现在的经验性的这种进展里边很大的一条就是说我们有更大的数据更好的数据更多的计算更大的模型然后我就能学的更多但是我们回到这个问题的话你可以想白盒模型你说这个里边大家有一个追求是说我想要做出来这个模型呢它要简洁性然后它要这个模型本身要简洁为什么白盒模型要简洁性我是不是可以理解成如果它过于复杂你们要在中间加的东西会更多然后它就很难被设计对我其实觉得做理论你可以只有简洁的东西才可以被理解对吧你肯定是要做一次一次的简化但是呢如果你考虑到这种skilling aloud这件事情的话你会有一个问题就是说当我们在追求模型的简洁性的时候可能会做了一次又一次的在英文里面叫做oversimplification过度简化就是一旦你出现这种过度简化的话你的模型就无法完全的刻画数据的形态那么数据更多的时候你的模型就更无法刻画它的形态那你就会出现将来这个模型就走不下去了它的能力会被限制住所以我认为这是以前大家在研究白盒模型在研究简单模型相对来讲面临的一个困难我不仅仅要带着那个包袱我这个模型需要工作同时我还需要它可解释同时我还需要它剪辑当你把所有的这些东西带上你会发现这个包袱太重有点走不动然后你会引入错误对吧当你做过度简化的时候你就引入了错误错误会积累在后来就走不动了但是现在推荷模型发展得很快了然后我们又开始尝试去解决它对这次如果我们在解决它的时候你可能就会重新来审视这个问题就是说我们不一定需要让这个模型完全地简化到那个程度它还是能够表示这个世界比较复杂的一面但是你还是要知道我们的包袱还是很重要希望它工作同时希望它还是比较可以理解的那么还是希望它有相对来讲简化所以我认为如果有一天我们可以做到白河模型的话那么在此之前呢我认为每一次的尝试都是一次过度的简化但是我们希望每一次简化呢每走一步都往前走我们甚至不需要完全做出一个白河模型也许我们可以做出一个白河的但是没有大模型那么强的模型但是也很强做到一个相对来讲不错的模型但同时它又相对来讲非常简洁非常简化同时还要保证功能对部分功能对部分功能那它对于我们理解学习背后的本质是有帮助的同时这种理解可能能反过来又让我们对大模型的训练什么的它的效率又会上去因为我们要回到这个效率这个问题这个也是我跟杨之前讨论过几次的事情就是说如果我们发展这个背后的理论最后我们就可能可以让我们的工程的这种实践呢它以数量级的方式效率上升所以杨勒昆他的观点是什么他是更希望发展白核模型还是黑核模型如果是在我看来的话我跟Yang聊过这个事情我认为Yang他是一个科学家但同时呢他是一个以工程方面所组成的一个科学家所以他的很多的尝试呢还是要走第一步要让这个东西工作起来但是作为白河模型的话我认为这件事情是Yang支持但是他也不知道能不能走通的一个方向比如说我跟他讨论完他会觉得这条路值得探索但是是否能实现呢他也不知道就是一个过于有野心的目标总要有人做的吧是的而且感觉白盒模型就像你说的黑盒模型它是一个类似于工程问题白盒模型它是一个科学你必须用科学解释它感觉它对商业化或者应用它在你真正能出成果以前它看起来投入产出比不是那么高但是呢如果你最终能做出来这个东西我觉得对AI的安全性包括我们说最终对应到它的商业化还是很有价值的对商业化这件事情其实我认为所有做基础AI研究的人首先他工作的初衷不是以任何的应用为初衷他是一个对于智能这个问题一个比较纯粹的一个好奇心来驱动的紧接着你可能会发现他有一些应用在这个之上比如说这个中间的一些过程你所发现的一些规律他反过来可能能帮到你在工程的实践但是你由于这个研究本身它并不是为某一种应用所设计的所以它并不是一个那种直接的关系举一个例子那你正常来讲做无监督学习的话你可能会需要训练很多个epoch就是它训练一遍一遍一遍那我们现在就可以问一个比较疯狂的问题就是说我们能不能所有的数据只看一遍能学多少是多少那么这个时候你会怎么办如果你这个时候不知道学习的背后的它的一些基本的一个原理的话那你可能就不容易达到一个比较高的效率我们当时也做过一些这样的尝试你会发现其实当你知道背后它在学什么的时候你是有可能数据只看一遍然后也学得非常好的虽然还没有完全把这个区别消除但是它其实可以比你正常不了解这个原理的话它的效率高了很多很多它的区别是很大的还有一点的话我认为说当我们在追求这种白核模型这个过程中还是极致的这种效率的过程中的话你会回来追问这个问题就是说我们现在做的这个大语言模型是不是只通过这种规模化或者scaling law这一条路走下去就可以了我认为其实还是不是的因为人他其实做不到接受这么大量的数据那如何用少量的数据还能获得比较高的泛化能力这个也是我们在研究的一个重要的问题我觉得这个也是黑核模型的学者在研究的一个问题对对对这个就没有本质是是是那现在白核模型它有哪些学者跟流派在研究这个事情呢白核模型的话我其实觉得就是看AI的三股力量第一股力量的话就是说我们在研究大语言模型研究这些工程模型的过程中我们可以产生了一些经验然后我们可以对它进行一些可视化这个我认为就是一种流派Anthropic最近OpenAI他们也参与在做的这些事情然后对它进行可视化之前就做了一些然后现在又做了更多这是其一那么其二的话就是计算神经科学这边神经科学这边我们要尝试对人脑进行理解然后在人脑里面比如找到了视觉和语言的它们交叉的一些区域找到了一些记忆可能的存在的一些方式找到一些层次化表示的一些迹象这是一种流派还有一种流派是从比较数学的角度来出发比较统计的角度出发我们问的一个问题就是信号的基本的结构是什么呀大家研究的甚至我们会追问比如三乘三的一个像素空间它长什么样子它的形状是什么样的然后去追问这个信号本身背后的这个结构这是三种吧然后在这个之间呢还会产生很多的交叉嗯你属于哪一派其实这三派我都或多或少的有受到一点影响因为之前在博会利的时候跟我的导师然后以及马亦老师他们都属于多少有点像是计算神经科学和数学统计的这个流派然后在样这边呢是工程这边受的训练多一点所以这三种方法我也觉得都可以接受因为它最终都会让我们往同样的一个方向前进同样的方向是哪个方向现在有阶段性的结果吗那最终就是理解这个模型那之前有一些阶段性成果就比如说我们能不能做出一些哪怕是两三层的一个网络然后它还能表示把这些比较高层的这些概念学出来那每一层我们都可以看它学的是什么东西最后你发现真的可以做到一个数字你要想表示它你会把它一个一个的笔画全都学出来笔画之间呢这些相似的笔画它们可以把它联系在一起在这个之上呢你就可以构建出来下一个层次的一个表示就像这样的一层一层的最后找到了数字的这样的一个概念有意思那你现在的这些研究会继续有真正的对黑核模型产生优化吗黑核模型优化的话会有一个是就是说当你对它的理解加深了以后你可能会比如优化这些黑核模型让它的效率变高第二个是说可以让不同的黑核模型你可以把它们统一起来这样的话你就是减少了很多不必要的浪费同时呢我觉得还有一个涉及到我这个实验室的另外一个支柱性的工作就是要给研究不仅仅是感知但是还有控制就是当你给了这些大语言模型也好给这些不同的model它能够和世界交互的这个能力的时候这个过程能不能让它的整个的学习的效率变高然后之前我们做过一些很好玩的一些尝试呢就是比如说在控制系统里边你能否获得同样的泛化能力但是这个是什么意思呢就是说在感知系统里边你会发现我学了苹果我学了梨然后来一个桃子由于我之前学了一个相似的苹果和梨的概念你可以很快就学会桃子的这个概念那么在控制的领域的话你能不能达到相似的性能比如说我现在这个机器人他学会了向前走然后我学会了原地跳跃那我能不能很快一变就把它变成了一个向前一边跳一边走的一个机器就是有这样的一种控制的泛化能力这是我们之前做的一个比较好玩的一个工作那综合来说如果让你给一个结论的话你觉得白河模型的研究到我们现在去解开这个大模型它是怎么运作的这个秘密它大概是一个什么样的进度条它的进度条到哪里了它的进度条我都不知道这个进度条有多长我感觉我们距离这个目标其实很远就可能是还在1%它其实有的时候发展它不一定是一个线性的它可能是一个这种比较像量子的这种跳跃当你有一个什么东西你一个新的一个认知出来以后你可能会马上往前走一大步我倒是觉得我们有可能能够做出一个比较强的这种模型完全可理解的但是它复现当时的这个像比如AlexNet这样的performance或者说这还是要看你的阶段性目标是什么对 看你的阶段性目标是什么如果你想做一个白河的Chat GPT我认为这个还挺远的但是你如果说我们要是想做出来一个还不错的这种模型我觉得这个还是非常有可能的就是根据我们现在的还不错的白河模型还不错的白河模型比如说它有它可以用来干嘛它可以做这种ImageNet的这种识别然后我们可以理解它里边的每一步它是怎么做的然后它是如何一步一步的变成了一个猫和狗然后这个猫和狗它的这个结构是怎么产生的就ImageNet的识别它算是白核还是黑核就我们还没有发现它的工作原理是什么我们还没有完全发现它的工作原理但是我们之前比如从Matthew Zeller和Rob Fergus他们做的一些早期的visualization后期的又有很多的研究者他们做的这些visualization就是观测嘛可视化还是有一定理解但是没有人能够创造出来这样的一个模型然后每一步我们都可以理解然后它且还能工作得不错所以我觉得可能这目标就分阶段第一步我们先解释这个ImageNet是怎么工作的这个谜底揭开以后我们可以再来解释比如说一些小模型是怎么工作的就像用GPT4去解释GPT2是怎么工作的然后再慢慢地来解释这个大模型是怎么工作的对对所以这个过程我觉得还是有相当的一个过程的而且也需要更多的人来投入到这个方向上因为毕竟工程上面的话现在主要是进展所以导致大部分的工作也就集中在这儿那么如果我们放到学校来做的话,那你其实需要有一些原创性的一些想法,而不是说你去scale,我也去scale,大家都是scale,那最后其实是没有区分度,就看谁的机器最好了,和谁的数据最多了。那倒也是。对。那接下来我想跟你讨论一下你博士后的导师Yang乐康。虽然在开头的部分其实我没有介绍过Yang,但是我还是想给不太了解的听众来去介绍一下Yang的背景。Yang他的中文名字叫做杨利昆是一名法国计算机科学家那因为他在深度神经网络概念和工程上的突破他和Jalfrey Hinton以及Yoshua Benjo一起获得了2018年的计算机学界最高奖项图灵奖他们三个人就被称为是深度学习三巨头可以理解成现在我们在人工智能上的巨大突破跟他们的科学研究成果跟他们的推动是有很大的关系的Yang在2013年呢他是成为了Facebook人工智能研究院的第一任主任当时Facebook是专门为了他在纽约成立了一个研究院现在呢他还是Meta AI的首席科学家可不可以给我们不懂技术的朋友稍微解释一下Yang主要的科学研究成果跟他为什么这么知名杨洛琳他相当于从80年代的时候就开始研究神经网络AI这个领域它经过了很多次的高峰和低谷高峰低谷也有不同的学派出现衰落Yang的话它从早年它就选定了这样的一个方向它坚持深度学习网络它相信这个一定能做成不管它的高峰低谷它走过黑暗的人所以也就是说他们经过了当年2000年的时候因为有不同的学派起来然后衰落在2000年的时候曾经有一个非常有意思的一个小故事他们发文章的时候你会发现非常的困难困难到什么程度呢如果你的文章里边存在neural这个词就是神经或者是说你存在network这个词之一的话你的被拒稿的概率就很大了但是如果你存在neural network的话基本就一定会被拒稿所以当时对他们来讲这是一个至暗时刻对吧但是他们那个时候可能经费也受影响但是他们能在这种黑暗当中他们能坚持不放弃最后能走出这个黑暗一直坚持他们所相信的这条道路到今天神经深度网络也确实改变了世界对吧我觉得这个其实也是他们得图灵奖对他们当年早期作为前期的先锋的一种记忆吧嗯对我对你的个人经历也挺感兴趣的就比如说我知道其实你在博士后的时候你是选了杨勒昆的组你当时是为什么会选他的组这是一个比较有意思的奇遇我当时其实挺迷茫的我甚至没有想过那个学期去毕业因为我当时觉得我在博士的工作其实没有做好当时是我博士当时的决心是说我在博士期间就要做出一个白河的模型而且要和AlexNet他的性能要可比当时我觉得就差一点我就想好那我再拖一拖再毕业但是呢我那年去开Neurips嘛反正也在温哥华然后同学们就说你做博士后反正也是做做博士也是做你也不用说非得说博士把所有的东西都做完他们说你不如就这个学习毕业我同学他们说的对吧就是那年很有意思很多事情都不是我自己决定的我以前事情都是我自己决定的那一年我感觉我是在被推着走其意有很多对对对基本上就是他们说什么我想一想有有道理然后我就好我就那时候决定毕业了然后决定毕业十天基本就把毕业论文写完当时我就想那要毕业的话我要找博士后那要找博士后的话我去找谁呢我本来想的是给别人发邮件同学他们说你都在Nurips在开会大家都在这开会呢你为什么不是当面聊呢直接聊我觉得有道理啊然后我就当时去当面去了当时我想到的其实第一个想到的人是Ero Simmichelli如果你这么看的话他有点像是一个东海岸的我的导师这个风格我们在西海岸嘛Ero Simmichelli也是计算实际科学领域的一个领军人物嘛他在东海岸那边所以我一开始想到的是他但是他那一年呢刚好他要去有个Simon Foundation就是James Simmonds开创了一个Simon Foundation是一个研究机构他要去那个地方去筹建他们的一个计算神经科学的研究所他就非常忙然后我其实跟他聊也没有聊出来一个说要约meeting约一些会啊然后我们也聊一聊聊得挺好但是也没有得到一个结论对吧是不是要一起工作啊等等的然后在会场上就碰到了杨那我当时想的话是说大家肯定都想找杨去做博后嘛我不想是one of them我其实不是特别投机的一个人所以当时碰到他的时候我其实主要想的是聊一下他对我工作的一些看法以及对于未来方向上的一些大家可以谈一谈这个观点比较有意思的时候当时在会上聊聊得就非常好当时觉得非常的至少我们相信的这种方向以及我想的一些问题他曾经也都想过只不过是从neural network就是从这种神经网络的这个角度来想这些问题以及最终追求的一些方向的话我觉得也很切合所以当时他就问我招postdoc你有没有兴趣申请一下那我说那我当然申请了那所以就是当时就是这样一排集合哦 有意思所以我最后博士后也就只申请了他的博士后杨是一个什么样风格的导师他是属于非常多的给学生自由空间探索的还是属于他其实就是实地上来跟大家一起讨论帮忙很多的首先是后者的话他现在这个情况下已经不可能了他现在太忙了我觉得这个事情比较多指的他太忙了是比如说meta那边的事情很多研究的事情也很多当你变得很有名的时候你自然就变忙了很多人都需要他的时间从这个角度来讲他能够分给每一个人的时间也相对来讲就没有那么多我觉得Yang呢相对来讲呢我认为是相当放羊的他其实和我的博士的导师相似就是说在一些大面上是非常放羊的但是我认为他们有另外一点相似的事情就是说对于他们所相信的事情他们会坚持就是他可能会跟你说往这个方向走那么具体怎么走你走哪条小路你是乘船还是乘车这都没有关系但是这个大的方向我认为他会有自己的一些品位吧我会觉得另一方面呢我认为他对不同问题的直觉还是非常不错的其实他会给你指一个大方向他不会去控制这些细节然后我们会有一个比较大的一个愿景或者说一个目标吧Mission在这个mission下面那我们就会要坚持着沿这个方向走它的大方向是什么其实很多年也没有变过让他想什么实际上是非常透明的因为他会出去给不同的地方给演讲然后他讲的这些东西基本上都是他坚持的这个大方向在过去的这些年里面我觉得他坚持的这个方向一直是自监督学习然后自监督学习的话其实分两部分一个部分是我做感知感知上面的话我可以做自监督但是更重要的一点的话是当有巨身的时候我如何用巨身的方式来做自监督或者我们现在给它一个名字叫做世界模型World Model我认为这是它Believe In的一个方向这个名字呢其实还是我安利给它但是因为我当时读了David Ha和SchmidtHuber的那篇文章然后他们起了一个名字叫World Model然后我觉得这个名字挺酷的虽然是一个传统的想法就是以前也有这种Model Predictive Control然后Forward Model就是有各种各样的名字但是这个world model我感觉挺酷的所以我们当时强力的安利了一波你觉得Young它的研究方向跟脉络跟OpenAI的这一套Antherapic的这一套会有什么不一样吗如果说真要说什么不一样的话我觉得Young可能想要的是模型它需要有几件事情第一件事情它要有巨身的能力我觉得它要可以在这个世界里不是只是堆数据而是说这个模型最终它可能会可以自己去探索这个世界这个有什么不一样呢大家都希望最终达到这样的一个结果但是你如果说看它的执行的方式的话我觉得每一个地方它执行的时候它的最坚持的我其实觉得是比如说在OpenAI我认为它是scaling law对对对就是我认为这个其实是OpenAI一直做的比较相对来讲是他们做的很对的一个东西那我要更多的数据更好的数据然后更多的计算更大的模型更general模型对吧基本上坚持这个对于Yang来讲的话它其实还是比较科学化的它会说如果我们想真正通向比较像人这种level的智能的话那你到底需要什么而不是说我就把数据给你堆上去只是做这样的事情那我可能会觉得只是堆数据是不够的这是它的不同点所以它其实也是相当于你说的黑盒白盒一起研究就是它对对对于Yang来讲的话甚至我认为它没有那么在意这个是否它发展成一门科学目前我认为它的观点是它还停留在经验性和工程上面然后让这个系统可以工作得更好我认为这个的话在短期之内是会走得比较快的对吧也是它其实一直非常擅长的一个东西因为当年其实在开会的时候在会场上它就会带着它当年做的卷辑神经网络去售给别人看你看这个可以做数字的识别啊等等的它其实很擅长这个工程的这种让这个系统可以工作起来嗯 对我好奇的是在OpenAI证明了Skilling Law可以达到很好的效果的时候你觉得Young他在科研方法跟他的思维上他会有转变吗还是他非常坚持的还是远路线我其实觉得他并不反对Skilling Law对对对就更多的数据更好的数据和更多的计算我觉得大家在这件事上并没有冲突但真正的可能分歧就是说比如说在OpenAI很多工作其实还是要以产品为导向的对不对对于Yang的研究组来讲我其实觉得OpenAI的很多东西一个是工程上执行的极致另外一方面也是产品上的一些突破对比如说对话的形式的最先的引入对这个还是需要一点商业上的天才来做这样的事情然后我觉得对于Yang自己的组呢它其实更是一个科学形式的一个组他想这些问题的时候想的就是里面不太涉及到产品的这些问题他想的只有一个问题就是说我怎么能实现这样的智能对吧那到底是需要什么因为他在这个领域已经太久了已经不像是我们我们进入这个领域其实也有一段时间了对吧那但是他八几年的时候就在这个领域在深耕了所以他可能看这些问题的时候他还是坚持自己的理想说我怎么能获得更强的像他看到的这种方式来让这个智能的能力提升对你刚刚一个说的是让这个智能自主地学习这是第一个观点就是让它的一些大方向其他的还有一些方向是什么还有一个方向的话让一直相信的一个东西我其实觉得这个是一个有意思的问题这个问题就是说它一直在谈的是JEPA Joint Embedding Predictive Architecture这个结构它其实表示一个观点就是说我当然要有巨身能力对吧我当然要有自主学习的能力但是比这个更重要的一点是说它其实不仅仅是一个压缩的一个问题它是当你在学习数据的时候你是希望把数据中的一些比较高层次的一些规律学习出来那就是两派一派是说那好我学到的这些东西我要能够对数据进行完全的重建你可以认为是一个挺压缩的一个思路但是Yang说的这个东西呢他认为说他说数据中呢他所具有一些高层次的规律呢你不希望他完全的去回到这个图像当中因为你如果要还能重建这个图像的话你就带有了太多的细节而这些细节并不是对你的这个系统做判断的时候最重要的一些信息所以在这点上的话我认为是他也一直在坚持的一个东西这点他跟你伯克利的导师买一老师的观点是不一样的吗我其实觉得严格来讲他们是很好的朋友OK所以我其实觉得这个观点上并没有本质的冲突只不过是表述的方式我自己看这个问题的话比如马老师觉得这个世界的规律是简洁的一样觉得说这些细节其实对你做下游的这个任务或者做一些很多的判断是不利的所以你要把那些高层次的规律找到但如果你仔细想这两个东西实际上是一样的对吧因为高层次的规律它是简洁的但只是说当我们想这个问题的时候我们可以把这个完全看成一个压缩问题对吧马老师经常说所有的东西都是压缩如果你拿一样的这个观点来看的话你会发现没错所有的东西都是压缩但是呢这个数据的它的这种层次的结构有不同对吧因为现实世界是复杂的那么现实世界如果你深入到这些细节里边你会发现有大量的东西它其实是低层次的一些结构不是说这些规律不存在只是说这些规律呢并不像我们人类比如说咱们人类知识的高峰就像万有引力对吧我们找到这样万有引力的几个公式可以基本上在我们可观测的范围内都是对的或者说在我们常规的物理的可观测范围内都是对的那这个可能只是很小的一段信息但是如果我们去看外面的这个森林的树叶的样子的话那它这里边很多的结构是局部的那这些局部的这是什么意思呢当我们在谈压缩的时候数据中有结构任何存在结构的东西都是从噪声偏离的一个反应就是说完全没有结构的东西就是噪声任何离开噪声你就是有结构了对吧然后我们要学习的本质要学习这些结构但结构有不同的层次低层次的话比如地毯它的样式当你上升这个层次在更大的一个尺度的时候你会发现这个东西呢这个结构其实已经不重要了它甚至已经没有更高级的结构了那它在那个层次来看的话这些东西就已经变成相对来讲像噪声一样的东西了所以样的一个观点是说我们需要有这样一个层次化的学习能学习出来越来越高的几个结构所以我如果我们做压缩的话这对我们做出了一个挑战我们要压缩是没错我们要学习信号中所有的结构不同层次的结构但是最高级的结构呢它往往对于压缩的整个的所占的这个比啊它不大在优化的过程中可能会丢失对吧就是因为你大量的东西都是在低层次的这些像噪声一样的这个信息量是最大的越往上走越往上走越往上走就越难发现这样的结构为什么呢因为在你的优化的Loss Function就是你的目标函数里面你找到这个规律和找不到这个规律可能对你的Loss影响不大我觉得主要就是这么几点吧它一个是对这种世界模型一个是对于这种层次化的表示你觉得他们身上有哪些特质是特别打动你的我觉得他们身上特别打动我的特质呢可能就是他们做事情的那种专注和纯粹吧对因为我跟Yang有一次吃午饭然后我觉得我们聊一个事情我觉得他说的一句话很有意思他说你们在年轻时候想要的所有的东西我都有了但是我已经没有太多时间了所以他只能用自己剩下的时间做自己真正相信的事情我觉得当你跟这样的一些科学家工作的时候你可能会被他们身上的这种气质所影响以至于你即便你还没有达到他们现在所在的这个地位以及他们所拥有的这些东西之前你也能以他们的视角来看待这个世界一点所以你在做选择或做事情的时候你可能会超出你现在完全你所在的这个位置可能会想一些我如果我有一天也都像他一样全都拥有了以后我会做什么对吧那这样的话你在选择一些研究的问题的时候以及事业的这种方向的时候你可能会被他们的这种气质经过长时间的这种气质所影响我觉得这个可能是我觉得收获挺大的一个东西所以它有改变你的哪些决定吗有啊它会让我做很多的选择的时候会想到这个事情其实这点的话我在读PhD的时候读博士的时候也会被我的导师影响本身他们几个人都是朋友对所以就是学术圈子很小对学术圈子很小那他们以前也是有合作那么我读PhD的时候第一天其实我的导师他讲了两件事情他说希望你不用发很多的文章后来他不承认这件事情就是出不来结果还是要说对对他后来我跟别人讲的时候他也在场我说他说不需要我发很多的文章他说他没说过这个但是他有一个他承认他说过他就是说他希望你能发出来这种文章能够穿越时间就是说在20年以后看到这些文章依然不旧我后来觉得这个很难因为很多的工作它带有鲜明的时代感但是真正一些深邃的思想他可能穿越了100年穿越了几十年他依然看起来还不是很老那这样是高质量的工作那你那个20年还不旧的工作那至少是能推动人类往前前进20年的一年不就就是推动人类前进一年对这个是一个很高的目标而且短期无法被验证只有在你退休的时候他可能才能被验证当你快要退休的时候我们才能重新审视这个人但是至少他提出了一个灵魂的拷问对吧就是你能否坚持去做一些能够与时间共存的工作我觉得这个要求很高第二个是呢他希望说一个学者应该具有自己的一种态度如果你觉得一件事情呢是A可以做B可以做C可以做你也可以做你就不要做就是说当你做这件事情的时候你会发现并不是这个工作需要你而是你需要这个工作这是一种投机的心态就是我其实觉得他们身上有相似的这种气质就可能就是说他希望你做一点不要随大流能有自己的态度寻找到自己的一些voice的一些东西所以你在选这些研究的方向的时候你也会自己时不时的判断一下我现在做的这个工作到底是一个投机的还是一个真正的中有砥柱的工作对吧有的时候你还是会做一些投机的工作但是你自己心里要有一个判断对我觉得这个就是独立思考且坚持自己的热爱对而且就是说我觉得他们尤其是像让他们比较伟大的一点就是说你可以穿越了这种几乎是绝望的过程中然后迎来曙光因为我觉得没有经历过低谷的人沉淀的可能还是不够当你经过至暗时刻你还能走出在至暗时刻没有改变方向走出来对当然你不是说不撞南墙不回头就是完全错了而是说你的眼光可以穿越短前的这个时间你可能真正有一些坚持的东西而且你是证明它是对的我觉得这个是挺有意思的一种气质有哪些样在科学上的看法是你不同意的吗比如说样的观点会有点挺鲜明的一些特点它有的时候会铁口直断比如说最近他有可能说如果你是PhD的话那你就不应该研究Large Language Model那他认为什么阶段应该研究不他就是说你如果做一个研究者的话你再读博士的话就不应该研究这个东西他有很多种理解从他字面上意思的理解的话你就会很多人就会不同意包括我可能会觉得大语言模型可能它里面有一些结构是值得被理解的去研究一下的但是他可能他真正想说的也许我有的时候听他的这个话他背后想说的可能是你不要去做就像刚才说的这种A可以做B可以做C也可以做的这种投机性的工作而是说你真正有自己的一脸坚持找到一些比较原创性的贡献如果是这样的说的话我其实觉得我会更同意一些但是我其实觉得有的时候他表达的是这种意思可是呢由于他是大V嘛他这个他说如果说这个所以认同他的理念不认同他的表达话术他有的时候这个话讲出来会吓你一跳什么意思对吧很可爱很可爱对我觉得这他比较有意思的地方但是他有话题性这样的好处是说大家看完了这个以后大家觉得哎你就瞎说然后然后我觉得挺好玩的对因为你也在Meta工作过嘛你觉得Yang对Meta最大的贡献在那几块Yang对Meta最大的贡献我觉得首先他应该算是帮助筹建了Meta AI当时他筹建Meta AI的时候首先是Mark找到他第二个是说他自己也有一个理想因为他早年是贝尔实验室的他很向往当年的贝尔实验室的那个状态所以他其实想在Meta复制这样的一个对对对它秉承了这样的一个理念做了Meta AI也招了一批非常不错的人结果呢其实也是给这个领域做了很大的贡献我认为这个可能是它真正比较大的一个贡献在Meta AI然后借助这样的一个平台呢把这样的一个理念给贯彻出去这也是它现在推动整个领域发展的一个方式如果你只是自己一个人研究的话可能不如能搭一个摊子然后让大家这些聪明的人一起在这样的一个框架下一起推动一起玩OK 对我觉得开源应该也算是它的很重要的一个贡献比如说MetaLama之所以走了开源的路线跟整个Yang的思想应该也是非常一致的对 对这个说开源的话我认为这是Yang所坚持的至于将来在商业上因为商业上它总是有一些竞争嘛这条理想主义的道路到底还能走多远我也不知道将来Meta是不是会一直开源下去就是所有的东西都开源还是说因为毕竟Meta也会面临竞争它作为一个公司来讲它要发展的话它会面临它那个层面的竞争比如OpenAI啊Google啊什么这些公司的竞争那在这样的一个竞争情况下你是否还能以一个比较现实的方式一直坚持这种开源的这种理念我其实不知道但是我觉得这是一样的一个理念最终能执行到多好能走多远其实也要看整个的这个群体Community它的发展吧那你觉得现在整个大模型的研究它是一个必须是一个科学家驱动的吗还是它会慢慢变成一个工程驱动的事情我觉得它已经变成一个工程驱动的早期是科学家驱动的对就是当东西它不太work的时候就是它还不太好用的时候就是它没有做出来的时候它是科学家驱动的对你需要有一些belief就是说你要有一些坚持但是在过去的这些年里面我感觉这一两年里面我觉得主要的这个进展都来自于工程的执行执行的极致程度对吧数据的质量是不是变高了数据是不是变多了它的distribution是不是变丰富了计算是不是能够变形就一个一个的这种工程的非常重要的细节导致的就感觉现在大家都是在做优患早期从零到一的时候是科学家在带着大家从雾到有去创造这件事情对它的发展嘛它前期是从零到一它需要这种突破性然后从一到一百它其实需要工程的严格性和执行能力它也是不同人在不同阶段它的角色的变化反正要让它发展的话可能需要不同角色的人一起来推动那大家现在都在期待GPT5你觉得如果GPT5就是下一个这样非常大规模的大模型出来了它更多是一个科学问题还是一个工程问题呢我觉得工程上面可走的路是很远的还是有相当的一段路可走了甚至我们可以认为Skilling Law它还有相当的路可走它完全没有到尽头就是数据还有很多数据还有很多算力还有很多算力可以扩展那你的数据的质量以前大家光说量其实质也很重要这些我觉得都能走相当的一段时间但是我认为不够的Skilling Law肯定不是It's not enough就我们这很多现在大家喜欢说的是什么什么什么It's all you need我觉得更好的一个方式我们都觉得是什么什么东西It's not enough即便我们现在找到的最robust最鲁棒的一条路就像是skinning law这样的东西我认为 it's not enough那么我们还需要什么呢我其实觉得需要的就是类人的这样的efficiency就是这样的高效率那这个效率如何实现这样的一个效率那么有可能是数据出发有可能是data driven的对吧完全是数据驱动的但是也可能是还有其他的一些东西所以我觉得如果我们说要通向AGI的过程中应该还会有这种完全从0到1的一些比较大的一些转变就是既要有科学上的进展然后工程上我们还有很大的空间可以去提高对对这个总结非常好好谢谢于北感谢感谢好了那这就是我们今天的节目如果大家喜欢我们的节目欢迎在你所收听的音频渠道来订阅我们中国的听众可以通过小宇宙喜马拉雅苹果播客蜻蜓FM网易云音乐荔枝播客和QQ音乐来关注我们海外的听众可以通过苹果播客和Spotify来关注我们另外呢大家也可以在YouTube上搜索硅谷101播客来关注到我们那我们的搜索词是硅谷101播客如果大家在搜索的时候出现了我们硅谷101的视频大家也可以一起关注好感谢大家的收听谢谢
