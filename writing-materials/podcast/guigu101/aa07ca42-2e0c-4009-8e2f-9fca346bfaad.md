---
id: aa07ca42-2e0c-4009-8e2f-9fca346bfaad
source_type: podcast
source_key: guigu101
title: "E201｜OpenAI挑战通用型AI Agent，聊聊Agent的底层架构、AGI转折点与RL人才分布"
url: https://sv101.fireside.fm/211
published: 2025-07-26T00:00:00+00:00
downloaded_at: 2025-11-28T14:15:16.546481+00:00
---

# E201｜OpenAI挑战通用型AI Agent，聊聊Agent的底层架构、AGI转折点与RL人才分布

Hello 大家好 欢迎收听硅谷101 我是红军上一集节目我们刚刚复盼完AI agent的投资逻辑OpenAI就发布了它的第一款通用型agentChat GPT agent我们今天有一个热烈的热烈我们将来发布Chat GPT agent 很多网友问怎么感觉这个有一点点像我们经常用到或者提到的Manus跟James Park这些通用型的AI agent那这一集呢我们就来聊一聊这些看上去很像的通用型AI agent们他们不同的技术架构和设计逻辑有什么不一样 我们邀请来了Poke AI 的创始人朱哲青他也是前Meta AI应用强化学习团队的负责人本科与斯坦福博士的研究方向都是强化学习所以这集我们也会聊到全世界最顶尖的强化学习大本营的人才分布以及AGI 的五个层次 从这两三年的AI发展来看,OpenAI它定义的前三个层次的AGI可能已经实现或者是部分实现了。而对于一些前沿研究者来说,我们现在正处在一个从第三层到第四层的跨越期,而强化学习正是揭开谜底的钥匙。 另外再发一个高能预警嘉宾的学习与工作语言都是英文所以今天的播客呢专业术语中出现了很多的中英夹杂而且我觉得它可能对非技术的听众听起来有一点点不友好但比起语言的问题啊这依然是一期很高质量且极具前瞻性的对话如果大家理解有困难可以在B站或者YouTube上来看我们的字幕版 那欢迎Poke AI的创始人朱哲青Bill朱哈喽Bill大家好对我们今天录制的时间正好是在Open AI刚刚发他的ChatGBT Agent的这个周末他其实是周五上午发布ChatGBT Agent的我不知道在他发布以后差不多过去一天半的时间你有没有使用 对我们确实上来第一手就使用了它因为在它发布前一天大家其实都已经看到了他们在推特上面的一些预热我们在当天下午的三四点钟就开始适用它了感觉它的总体效果可能比我想象中要差一些 速度也比我们想象中要慢很多核心的原因应该是跟它原本的Deep Research和Operator本身的速率有关因为Deep Research相对于市面上所有的产品来说它还是相对比较慢的一个Research产品再加上Operator本身我们也知道它的那个Benchmark上面它的速度也很慢所以它把两者结合了以后整体速率就更慢了 比如说有一个比较简单的大家都在对比的一个用力就是先做deep research然后再去创建一个slides像这种用力的话时间基本上在35分钟到一个小时之间所以它是个非常非常慢的一个过程我觉得它的一个优势是在于它在browser上面真的要做operation的时候是相对有优势一些 比如说他去定个定制的衣服或者定制的旅程的时候他在browser上面的去点击的能力是要超过市面上的大多数的browser-based agent所以非常取决于你的使用的方向是什么如果是偏运营相关的一些工作的话可能不算实用但是如果是偏consumer相关的他可能会更实用一些 你可不可以具体举一下例子就是你具体用了它的哪些方面因为刚刚其实你有举到在挑衣服或者在做旅行的时候它会看起来比其他的这些基于浏览器的agent它会更有优势一点可不可以讲一下你的整个的一个使用场景包括我们对比它跟其他的一些使用浏览器的agent来比它的不一样是什么 对我可以简单举两个例子一个就是我想要去新加坡待三天我就问他说你能不能帮我把整体旅程定下来然后去找对应的航班酒店信息把它定下来他确实是花了很长的时间他一开始先去做了规划那个规划所有的LM现在都可以做所以这个没什么可impressive的地方之后就去搜了往返的航班以及所对应的酒店 其实难度也没有很大但是目前市面上大多数的browser based agents这方面其实做的都不是很好ChangePD在这上面会相对的好一些因为它的vision的能力会相对更好它有点像机器人的能力解决架枯就是它有vision language model在里面然后它根据vision的结果然后它会再有反馈 你的Vision Model是指的你在比如说找航班的时候它能看到这个搜索页面的信息它不一定是要用后台数据API接口调用的方式指的是这个不同呢大多数的Browse Based Agent里面都有一些Vision的部分就是说我要去看那个页面到底长什么样因为很多时候你如果说靠像Browse Use这种 它就完全是靠后端想办法去拉它的页面里面的所有的HTML的components然后拿到components以后我再去看说每个component里是什么然后再去选择点哪个地方然后再去执行很多时候第一你有可能去访问页面的时候就会被卡死因为你是等于是在爬虫爬人家的页面第二作为一个browser-based agent的话你是希望说能够看到它整个visual structure是什么样子的 那它的Vision的能力就会有帮助那当然了像很多的Computer Use的Agent都带Vision能力所以也不是一个很大的创新了但是因为它的Vision能力相对强一些所以导致它真的take action的时候要比我现在看到市面上别的browser agent要好一些 他帮你订机票酒店然后做旅行规划整体花了多久我记得应该是二三十分钟吧他是最后完成支付环节了还是说只是把所有的航班给你选好了只是选好了就是到了支付环节都是要给我们takeover的 我觉得支付的环节是所有的agent业务范围内最麻烦的一个点因为正常的人类不会trust agent去做支付环节所以很多时候所有的agent一旦涉及到支付都会卡死在那里不是技术上卡死在那里而是产品上卡死在那里因为人和agent之间的信任其实没有达到那个标准所以 导致大多数的agent像我们也一样其实有很多跟支付相关的功能是已经继承完的但是我们一直都没有release他们因为我觉得不会有人那么轻易的信任Pokey就做这件事情OpenAI也有一样的问题就是说到了支付环节它还是需要人类去takeover然后去完成支付的任务 等于说他花了20多分钟但当中你还是得要jump in说我要去付钱总体来说我觉得使用性没有很大我宁可说自己花点时间十几分钟全部搞定了另外一个相对比较常用的用力就是他们在电商方面也花了很多力气比如说根据你的要求然后去找相对应的产品 我个人还挺不是很喜欢这个产品方式因为我感觉他整个帮你搜索产品找相对应的产品的形态比如说什么颜色什么样的款式的过程它其实是一个挺慢的一个过程而人去选的话也就是点几个键的事情 我一直认为说电商这个方向它的决策链路很短导致说agent真正能够给你带来的优势很小因为它真正需要人类决策的那个范畴也就是可能三到四步最多了它没有像别的那种比如说你要做个research你要写个slides你要去写一个spreadsheet像这种东西都是很花很花时间的 而shopping可能没有那么花时间我觉得shopping它最花时间的地方其实不是在你已经想好了你要什么到下单的这个过程而是一个你在选择的那个过程所以刚刚其实你有提到就是你用它去订航班跟酒店的时候 我就特别想问你最后自己订的那家酒店跟他做旅行规划然后帮你找到的那家酒店最后是一致的吗就是你对他找的结果满意吗不一致航班呢也不是因为他有很多信息他不知道我举个例子我一般出门都住Hiat飞航班的话我一般都会选尽可能在直飞里面找可能价格比较低的但是他在找的时候他其实没有这个反馈机制 就一开始问你说他只会high level问你三四个问题就是deep research的那种问题他一轮完成了以后他后面没有再跟你有反馈了他就一直在自己执行所以他定的就是一个相当于笼统的这么一个解决方案到最后我得要全部推翻重来因为他并没有用任何我喜欢的品牌 个性化的部分是我认为目前市面上agent产品特别是2C的agent产品而且跟productivity不相关的agent产品的一个最大通点OBI一直在强调他们memory的能力这是很重要的确实但是他们从哪里去一开始去收集这个memory就变成了一个co-start问题都没有办法解决的一个事 但是其实只要你告诉他一次你喜欢住哈亚他的酒店他可能以后就记住了跟一个人类的助理一样你越用才会越顺手而且假设让你的秘书去帮你订这个机票你可能也得跟他沟通说我要哈亚他的酒店我在飞机上骗好什么时间段什么价格什么仓位对对确实是这样的但是就是人类会不会愿意去做这么一两轮的沟通说完了以后他是不是能记住 其实我目前用XGPT用下来它对于你的一些行文的偏好是有些记忆的但是更复杂的偏好其实它的记忆没有那么完整XGPT刚出来的时候我其实有问过它跟旅行相关的问题但这次问它的时候它仍然没有记住当时给它的一些反馈所以它并不是能够很完整的把你所有的反馈都记下来 对我们知道其实OpenAI在推出这一轮的XGPT Agent以前就刚刚我们反复提到它有两个Agent一个是Operator它处理的是跟电商购物相关的Agent的调用另一个是Deep Research是做深度研究的然后我看它这一次整个的发布啊我自己的感受是它有一点点像这两个Agent之间的一个结合体 因为其实你也自己在开发agent相关的产品你觉得OpenAI在这个中间核心的技术壁垒是什么就是把这两个agent放在一起它的难度大吗其实没有很大这次的这个产品让我甚至于感觉是他们为了看到市面上有很多通用agent出现想要占领市场而做的一个move而不是说他们真的已经准备好了 像他们发布会上面甚至给到的一定的产品的demo其实也并不是很ready的一个状态说句实话他们做的很多的任务和市面上的通用agent相比其实可能效果更差一些速度又更慢他为什么结合Deep Research和Operator这两件东西放在一块变成一个agent核心原因是因为Deep Research是帮你retrieve information 就是说我从哪里可以得到更完整的面向于用户需求的这么一个信息operator说基于这个信息我怎么去执行这个任务过往的话基本上这两个方向是割裂开的如果说要去了解更完善的信息你就直接只能用Deep Research用完了以后他可能给了你一个巨大的report这个report也不足以让你去做什么事情你可能只能拿这个report复制粘贴到某一个文档里面然后operator也是一样的就是你必须要已经知道说你想要什么 然后基于你想要的东西你再去找operator说帮你去操作一些网页来完成这个任务这两个都是可能在自己的这个领域里面做的比较好的他希望说可以从信息获取information retrieval到execution这一个端到端的体验能够把它打通通过这两个这是个比较natural的决策吧 但我目前看起来它相当于是个工程解决方案就相当于是个判定如果这个用户需要非常复杂的information retrieval那你就去做deep research完成了deep research以后我拿着这个信息再去做执行如果不需要那就直接执行就好了 然后当中还有一个偏coding和sandbox一个解决方案就是它跟Manus很像的一个点是它确实有个sandbox它可以去执行比如说生成PPTX的文件用python的script写一些那种比如说bash那种script让你去sandbox去执行一些任务 所以它基本上就是一个从deep research到browser到sandbox的一个结合体对那你觉得它跟市面上的这种通用型的AI agent它的主要区别是什么或者说市面上所有这些通用型的AI agent我们把它放在一个池子里我们看各家他们的优劣势都分别是什么因为我相信他们可能在解决不同场景的问题还是会有一些些区分度的 对目前的通用agent我把browser和非browser全部列出来可能包括这么几家一个是Properluxity一个是OpenAIEnthloppy其实没有推出他们自己的通用agent但他们有coding的agent我们相当比较小一些吧就是我们比较晚期出来有Manus有GenSpark 可能在浏览器方面有Utory,Fellow,还有FlowEth但FlowEth可能更偏向Vertical一些首先在browser能力最强和operating的能力最强的应该是目前还是OpenAI特别在Deep Research加browserOperation放在一块以后他们绝对是最强的如果你去看一些Benchmark里面比如说像最新出来的Browseing Camp 他们能够在browsing camp上面达到50%多的benchmark score而别的最高现在目前也只有20多份就是在开源环境下然后在browser真的execution上面operator做的还是相对比较好的因为当年的operator是跟很多有API有sandbox的环境去对比的它就只有一个browser 所以现在加上sandbox的能力以后operator加open-end sandbox应该是会超越市面上别的一些工具的browser加sandbox的但是它唯一的一个比较麻烦的点就是在于open-end browser尝试do a little bit too much就是说它什么东西都想我把往browser里面塞导致它速度很慢那browser就包括了open-endfellow以及manus的一部分因为manus也用browser 在另外一个方向就是完全只有LM然后再加上一些execution可能是也能算sandbox但是它是一个limited sandbox就是说它并不是可以navigate整个系统里面的所有的package它有些预设package然后去做这件事情的 当然我们忘记说Perplexity了Perplexity在browser里面我觉得是做了一个相对比较另类的就是它的那个browser不是说我做一个能够navigate browser的agent而是说它在一个用户在使用browser的时候他给你一个sidebar然后让你说我现在在这个页面上做些什么 然后它去帮你执行对browser就是浏览器的意思sandbox就是虚拟机所以刚刚其实你提到了基于浏览器跟虚拟机的这两种搭建方式可不可以整体跟听众科普一下现在整个AI agent它的搭建在底层架构上有哪几种 现在的agent有这么四种大的方向一个是基于浏览器的那种agent然后第二种是浏览器加虚拟机的agent在这种agent里面就会有很多通过虚拟机里面的代码以及命令行来完成的操作然后第三种是只有虚拟机但是在虚拟机内部有非常大的限制的那种agent 主要通过LM的能力去生成代码然后只能运行某一种类型的代码然后最后一种就是一个可以横跨很多很多工具集成的这种agent我先讲一下browser非browser就是browser sandbox和就是像Pokey可能是个另类在所有的里面是个另类就是browser然后sandbox纯LM然后在Pokey的这种这四个方向都有互相可借鉴的地方而且也有互相overlap的地方 browser的意义是在于说我认为世界上所有的网页和所有的互联网服务都可以在某个网页上面呈现所以我只需要我的agent能够看到那个网页去操作那个网页我就可以完成我的任务那browser就用户可视化的可以看到这个browser-based agent在页面上点些哪些地方 它可以一页一页的去看说Brother是不是跟人一样在操作选网页那它的缺点是什么就是它很慢而且它的token consumption特别特别高原因在于你去看一个网页要花就等于把那个html的文件直接拉下来然后可能还包一些JavaScript的一些scripts然后你把它全部拉下来然后就从零开始全部读一遍就只为了操作一个网页但是它确实是万能的 那第二个就是SandboxSandbox的意义是我可以线下写一些PythonScript写一些比如BashScript甚至写一些JavaScript的一些Script就直接在那个虚拟机环境里面直接去跑那个Script来完成一些任务你像你要去做数据分析 你完全就可以说这是一个表格的一样的文件然后我直接告诉虚拟介义诊说我有这个文件它的抬头是比如说是个Sales文件的话那就是时间weekly sales品类各种各样的抬头然后你得到这个文件以后你就直接告诉你虚拟介义诊说你能不能照着这个帮我去做一个每周的week over week的Sales analysis然后他就带给你写个python script然后就帮你运行了得到那个结果 虚拟机环境的好处就在于它可以运行任何的线下的就是open source那种package但它的缺点就在于它很多情况下无法防御互联网特别是那种需要OAuth的那种产品比如说你要去登录你的Facebook这些东西它都是肯定做不到的第三种呢就是LM加Sandbox放一块的那种agent它可能是limit一个大环境JSBOX是一个这样的例子它并不给你完整的一个Sandbox它这个例子里面连browser都没有 Jamsbox作为一个例子是他有一个LM作为主体的一个reasoning的过程然后他写代码也是完全靠这个LM他有一个sandbox让他去运行一些代码去生成一些东西然后再把它render出来但那个sandbox甚至不能叫一个sandbox因为它是一个very limited的一个环境就是说它只有三四个package 它是fully controlled就是说这个环境内部它无法说我现在现有去下载一个开源的package比如说我现在需要临时去修改一张图片这个任务如果在它原始的那个package design里面没有它自己不会去说我去下载一个这个package然后去做这件事情 所以这种设计是Jansbug比如说像那种Slide AgentSheets Agent他们在设计的时候就把他的那个可用的包裹给限制住说我不再让用户去用更多的package就是一个相对来说比较封闭的一个环境的一个工作流在限制环境下用一个LM做主体写代码同时用一个小的那种环境去执行 然后最后一种就是可能和我们还有以前的ZapierNAN UiPath这种一个工作流式的但是工作流内部的每一个节点它是通过和第三方服务提供商直接集成来完成的这么一个做法 那这个优势就在于说我可以保证每一个服务的deliverable是非常solid的因为就是第三方服务比如Facebook他就是Facebook给我们的access他不会出错但与此同时他有他的限制就是他不能做doeverything就是他又很有可能会出现这个用户想要在personal的Facebook账户上面发图片那我们就做不到因为Facebook只让creator和商业用户去自动化的发这种帖子 所以这是我们的和比如说以前的UiPathZPRNAN的一条路径所以有这么四种类型第二种和第三种之间的边界是很模糊的唯一的区别就在于第二种的SandboxLM执行完了以后它所能够给你用使用的Sandbox是一个几乎开放的Sandbox 就是你自己可以选择说我要去下载新的package再去执行所以那个sandbox本身的能力是占整个能力做主体的而第三种可能是lm的能力在现有package底下能生成什么代码就已经是限制了整个agent能力的主体了 嗯嗯对对对很精彩那从用户的使用体验上说如果我们说Pokey跟James Park跟Manus跟OpenAI的ChatGPT Agent就你觉得比如说用户的体验它会有什么非常明显的不一样吗其实有蛮多地方都还蛮不一样的我们先讲Manus吧因为他们是第一家出来的 Manus的体验就是说它尽可能用一个Sandbox加上browser的环境来搭建一个几乎让人觉得万能的环境我有一个LM作为一个planning主题planning完了以后它进入到browser以后它是另外一个agent在完成browser navigation 他得到的信息再用这个信息总结下来再去进sandbox做执行如果有必要的话他确实可以做很多事情虽然他有很多时候会出现好伦子内讯因为他看整个上下门太长了但是他确实理论上可以涵盖市面上你所需要的所有的功能 但与此同时它也被browser的能力所限制比如说你要去真的发个帖它就做不到因为它对于这个页面的navigation说我要去选择那个小的button然后选择完了以后去上传一个图片生成一个视频各种各样的这就很难比如说你要去进一个google sheets说我要把google sheets里面的某一个cell把它改成某一个格式它也比较难因为这个attention的space太小了 那browser就是它的一个main limitation第二点就是它很慢这个是Manus跟XGBT agent的一个通病就因为你用了browser所以它的速度就会非常非常慢30多分钟做一个task30多分钟我觉得还是快的酷季因为我最开始使用的时候可能是一两个小时但那个时候非常早对 现在肯定比以前要快了因为他们的整个基建什么的都上来了但是它的瓶颈会在呢它的瓶颈升至最后变成network call 就你load的一个网页本身你可能就需要三四秒那你这个是跳不掉的XGPD的优势在于他们deep research做得好它能够做出一个很详细的report然后你如果通过这个report再去执行某些任务它会变得相对来说比较更comprehensive一些minus的话可能它的总体优势可能在于它的那个sandbox的环境达的可能要比XGPD要达的更好一些 但这个我还需要更详尽的去look into it因为XGPT里面的Sandbox能做到什么程度还不太清楚但我猜应该Manus在Sandbox可能已经花了很多精力去deploy了应该会有一个比较小优势Jansbox就是他一开始有个super agent几乎说我可以做任何事情但他后面就发现他能够处理的工具数量开始变得有限 所以他开始做templates就比如说slides是一个agent比如说AI call是一个agentsheets是一个agentbrowser也单独做了一个agent在同一个用力下面他们把用户体验作为核心目标然后做一些templates不管你问什么问题他总是用这样的template去生成slides总是用这些工序去搜索信息使得他变成一个相对比较标化的工作流就越来越不是一个general agent 它就变成一个偏人为选择的这么一个agent但它速度确实要比Manus跟XGPT要快一些原因就是因为它没有那么大的browser navigation同时它的sandbox本身是非常有限制的它就只有这么一点工具在某一个agent里面这样是不是也更节省tokens会相对节省一些tokens对 它把大任务都拆成了细分的垂直的小任务然后我猜它想做的是当它把应用场景一个一个完善它可能就类似于一个承载了很多小任务的一个大平台 对它就会变成一个类似于像微信小程序一样的一个所在Tookie可能最大不一样就是说它可能是目前所有的agent里面最快的我们现在还没有把我们的deep research agent开出来但是我们是有一个deep research agent正在开发当中的所以我们最后会有我们自己的deep research agent加上我们的execution agent放在一块总体体验会有大幅提升但是总体速度应该是市面上所有产品的4到10倍左右对 为什么可以做到的原因就是因为你如果不再需要用非常复杂的sandbox你也不再需要去用非常复杂的tool calling我们现在直接用第三方集成的SDK和工具通过我们自己的tool calling foundation model去靠这个function的话整个速度是会大幅度提升的就是没有了像mcp和现在市面上的这种在tool calling里面的巨场无比的context问题 所以它每次脱口的整个成本可能能够削减掉5-60%再加上我们自己的上下文端Engineering使得整个的cost在市面上至少跟OpenAI的JTBD agent跟Nemanda相比是个数量级的difference跟像Verticalize Jetpack这样的可能是几倍的一个差距在token使用上面我们确实是有劣势的特别是跟Browserbase相比我们并不是完全万能的 有一些任务像你要去Personal Accounting去post Facebook Postversus我们只能在Facebook Page上面去post然后Instagram也必须是Creator Account或者Business Account但是个人账户我们没有办法帮你post就是它只有企业用户才能去使用你们的Agent因为比如说你在接Instagram跟Facebook的接口的时候它给到你的就是一个企业用户才能操作的界面不是企业用户是Creator就是相当于说创作者或者企业账户 他们不希望说个人用户全都用这个去postpost完以后没人上Facebook和Instagram他们希望个人用户像consumer仍然可以每天去Facebook和Instagram上面自己去看那些帖子然后去发帖子这样有engagement然后企业用户和创作者用户希望能够让他们去创作更多所以在为什么把API开给他们 然后每个平台都有他们自己的limitation我觉得这个路径其实是相对比较符合商业逻辑的因为如果你想象所有的个人用户都通过一个agent想慢慢用browser去hackfacebook或者instagram账户或者是hack某一个平台说我通过一个agent去爬虫你的网页来完成一个任务 那对于这个平台来说是一个损失我就把这些browser全都卡掉所以如果你一开始就是跟着他们的商业逻辑走以前有人会通过非常manual写代码的方式去完成这个产品upload那现在就会有人直接写一段文字然后直接vibe working然后就直接把这个视频creative直接上传到这些说明平台上 别的平台也是一样的它所给你所开放的权限就是他们认为开发者和非个人用户或者非consumer用户真正最需要用得上的一些工具那如果你可以把这些都放进agent里面那些原来就会使用这些工具的人他就会转过来说我写一行prompt就行了不再需要写的代码 对所以我理解其实像MainosJames Park还有OpenAI的ChatGPT Agent他们的商业模式其实是2C的然后你的商业模式听起来现在应该是更偏2B的现在这个时代下B端跟C端的模糊性很高但是我们一定是在Professional Plus来使用我们的产品的 Professional BelowConsumer用户其实使用一个非常省时间的AI agent的概率不是很高这是为什么市面上很多AI agent的 retention是非常差的原因因为它没有重复性它很多的工作流是用一次就结束了而我们的很多的目前上来用户我们看到的是他每周都会在跑一模一样的过程 所以这是我们发现它有重复性在那这个是不是也很取决于平台会给你们开放一些什么样的SDK工具跟它的API接口假设我每天的微信太多了然后我想有一个agent去帮我管理所有的信息帮我去回复一些比较基础的信息那其实前提还是说微信他要给这样的一个agent开放一个他的接口那他们是不是愿意把这些接口开放给开发者呢 在美国的话像这种开发者的community是很多大公司特别是科技公司所崇尚的一个方向所以大多数公司都有非常完善的API接口SDKpackage甚至于说他们给到你的就是非常简单的一个curl的接口他也不给你python SDK之类的 国内公司可能会相对差一些它很多接口不开放但微信的话比如企业微信creator人那种级别的微信也把接口放给你你也可以自动回复什么都有国内的整个生态其实也在慢慢在开放特别是MCP这波出来以后有很多的公司都开始被迫开放他们的SDK跟API比如说高德地图就是一个例子 之前可能没有那么开放的高度地图后面在MCP出来以后他们是首先把地图这个生态给完全打开的这么一家公司所以其实有蛮多这样的例子的我们目前有一些公司给到我们的开放一些平台的一些API或者接口是独家的 但有一些不是总体来说这个商业模式一定是偏professional的一个商业模式因为有很多的consumer端的一些use case它就是非常browser oriented比如说你去浏览网页买东西其实travel request也有偏professional和非professional 像professional就比如说出差的这种那你每次都是标划的比如说你每两个礼拜要去飞一趟湾区那你每次都住同一个酒店那你就每两周帮你买一次这个机票但如果是一个consumer他去出去旅行的话那他就是我要去玩这个地方然后我住的酒店也要去export新的东西然后我的航班要比如说今天我刚发了奖金我要飞上物舱了他有很多的变数在里面 所以这种用力它本身就更适合比如说可能browser-based agent因为它就有一个laptop在它面前它可以开那个browser去做事情对在你跟大公司合作的过程中他们去开放这个API接口他们的动力是什么包括其实刚刚你也提到了像国内高德地图再去接入MCP协议就是他们的动力又是什么呢 首先第一点是整个agent的浪潮会从某种意义上来说取代正常的web traffic过往可能是一个人打开一个浏览器然后在Google search里面打入一段搜索得到搜索结果以后点一个网页再去做某件事情这是一个常规流程 但未来可能是你打开XGPT比如说你是做consumer转你比如说打开Pokey是你的professional转你可能就打一段字说今天早上我看到了Replit的CEO和YC的一个采访你能不能直接把YouTube上面的那个Script直接拉下来帮我写一段报告告诉我说那个growth strategy的key takeaway是什么然后他就直接做完了整个流程我从来没有打开过YouTube一个agent就从头到尾做完了这件事情 可能你以后shopping的use case也是一样你可能从头到尾就只是打开了XGPT说我明天要去一个晚宴需要一套症状他已经知道了说我的身材是什么样子的我多高然后他就自动帮我说找到了这是最符合你的然后把这个衣服摁在了你的身上你看一眼就好然后就说现在这边有个折扣然后就付款了就可能是这么一个流程那这个给我们的启示是什么就是说以前的那种所谓的工作流已经被改变了 他们不再是通过browser去initiate整个工作流的开端去下单或者去得到这个信息然后再去进入另外一个网页去进行操作无法避免的是我认为在接下来一到两年的时间内大多数的门户网站不管你是e-commerce还是搜索还是视频网站还是各种方面的门户网站他们的流量一定会非常快速的下降而它的入口变成了各个方向的agent 这是为什么当时Google要推出这个A2A的这个协议每一家公司都可能会有自己的agent可能是agent跟agent之间的交互那他如果能够占用这个协议的话在Gemini里面完成这个协议的首先部署那最后他就会是整个里面最大的赢家因为他成为了agent的入口 XGPT也是一样Cloud也是一样为什么他们要推出协议也是他们想要占领这个agent入口的核心目的那也是为什么Pokey要推出协议的原因就是我们也想占据professional这个场景下的agent入口你们为什么想自己推出协议而不是就接一个标准的MCP协议这样其实大家都是可以统一用的然后你也在一个更大更广的生态里面可以直接的接入很多已经接好了的APP 其实MCP现在的可用性是很差的现在市面上应该快要2万个MCP了其中可用的MCP大概不到200个而且大多数MCP都无人为乎导致的结果就是大多数的公司是不愿意花时间去做那个MCP协议的 我们的目标是说公司不再需要做MCP协议你也不需要自己去做一个MCP server你就直接把OpenAPI给到我们我们就take care of the rest所以公司在那些service provider公司的层面上来说就他们啥也不用干他们就可以得到一个额外的流量入口 对然后你刚刚在描述整个未来在接入了agent以后互联网它会发生一个什么样的形态的变化比如说门户网站它的流量会大幅的下降就像你听到Rapplet的CEO的一段演讲你就直接在ChatGPT或者自己Pokey上就完成所有对演讲的复述了其实我是在想这样一个问题因为我自己的身份是一个创作者就我俩身份是不一样的 那你觉得未来这个对创作者的影响是什么呢如果我现在做一档播客假设我们上一期内容那腾讯算法广告大赛它是有一个口播广告在里面的只有更多的人听这个播客大家才可以听到这个广告它才能支撑一个播客的商业模式运转下去就是大家才能持续地赚到钱然后能把这档节目持续地运营下去 那如果没有这样一个过程了还有人在下面说这期播客为什么没有开AI总结对就不去听这个播客了就直接去看这个AI总结那其实对广告其实是一种流量的折损我觉得广告这个行业会永远存在但是它的发生形式会发生改变 是为什么市面上有很多专注于广告的AI公司他们想要去看在LM时代或者Agent时代广告要如何被查入那我举个简单的例子在播客里面插播广告这件事情未来会变成一个什么样子现在的播客大多数除了平台方收你钱以外播客提供者本身是不收你钱的 比如说硅谷101入的一个播客但是大家都是免费听的如果你在YouTube上面只是用了YouTube的广告然后YouTube通过那个广告给你们分成那未来可能是说我们需要去access你的这个播客本身这个知识产权就是值价钱的 每一次通过调用也好通过网页访问也好去找到你们这个播客的那个时间或者是得到你这个信息的那一刻任何的Asian方就要向你付款你不再需要去担任那个广告流量的负责方那个广告是由Asian来完成就是Asian说我得到了这个信息以后我怎么去在整个工作流或者说在用户体验当中插入广告 那个agent就可以问说我们现在得到了这个对比你想要选哪一个agent去startplaying around with这个时候他就有一个ranking的机制在那因为这个地方并没有black and white的answer那他就有个ranking机制他这个时候推荐哪个agent去for the user to try他就可以向那个agent的公司去收钱了 所以广告在这个时候发生而知识每个API每一个第三方的插件的产品本身或者说知识产权本身是可以直接收费的所以对于创作者生态以及SaaS生态从某种意义上来说是变好了而不是变差了你不再需要去在Google上面投广告也不再需要去免费的把你的内容发给YouTube让他去帮你投放而是有一个agent直接向你付费 通过他自己的广告机制去cover他自己的cost我不觉得说你们会受到很大的冲击对整体上我觉得其实就是说流量分成这样的一个模式它会变得越来越弱然后呢如果agent调用了很多创作者的内容怎么给创作者付费其实是未来可能会讨论的一个问题 然后我觉得稍微有一点点疑问的就是基于流量的这套方式呢,因为比如说你有推荐算法,你一个页面可以显示10条播客的内容,或者是12条你想要点击的一个视频信息,但是比如说一个agent他在回答一个问题的时候,我觉得现在他还是比较聚焦于精准,他可能引用的范围就相对更小了。 其实上礼拜在ICML的时候有一个专门做推荐系统的人然后我们俩其实聊到了这件事情Panel之后有一个researcher上来问我说那你觉得推荐系统之后会是一个什么样的发展路径我当时告诉他我觉得推荐系统的大方向可能会受到巨大挤压在Asian的整个框架下面它还是一个推荐系统的一个端到端的multi-run decision making的一个过程 但是呢它每一次给你的交互其实只是给你一条信息的结构或者说几条最相关信息的结构这个时候它的整个决策线不再是按照排行第一排行第二排行第三这样的方式去决策了 而是时间是他的决策点因为一个人和一个agent之间的交互的总市场是基本固定的就是说这个agent好我就会交互时间久一点他的目标可能是说我在每一个时间点上我给你推荐的东西可以让你所consume的time和他能够得到的回报成正比 那这个时候它的整个原始的推荐系统的算法可能就不那么成立了因为原来的推荐系统算法是说我可能每一条点击的概率是跟它的排行所成正比的而现在成为说我每一次给你推荐或者给你回复的这个信息基本上都是你必定会去点的东西但是你会有第二轮跟我交互的过程 那我下一次你花这个时间跟我交互我所占用这个时间成本给你推荐的东西这一条就必须是最精确这样会使得你跟我有更多的交互所以它的目标就变成了说我不是有五条十条在一个页面给你呈现而是说我可能有五轮十轮的conversation然后每一轮我的目标是让你跟我做下一轮的交互 这个时候就跟传统推荐系统的算法就完全不一样所以当时我跟他说我觉得整个推荐系统特别是这种rank based推荐系统的长期的发展的潜力可能会被极度压缩因为它可能没有rank它更多的是一个sequential的然后experience basedexperation based这么一个交互机制你可能唯一的目标就是说每一条我都是给你最精确的 能够在不损失我未来的Opportunity Cost的情况下我在同等级别的Content里面选择一个我可以有更多收入的这么一个Content当然我也不是100%确定说这个一定是未来的方向但我个人从目前的这个Agent发展趋势来说感觉是这么一个方向 我觉得非常有意思,而且整个之后比如说创作者的生态会怎么演变,也是我们一直非常关注的一个话题。我注意到其实在整个这次OpenAI它的发布会里面,它其实也提到了它在用强化学习的底层架构,然后呢我知道强化学习的架构也是你的强项,就你可不可以跟听众简单介绍一下用强化学习的架构好在哪儿,它对应的是什么。 我觉得先要简单解释一下的就是强化学习的架构有很多种有完全以LM为核心的Token-based的这种强化学习的方向也有我们这种整个Action本身就是我要让Agent去决策的这个点可能不再是一个Language Token为决策Element的这么一个决策方式 这两种角色方式没有好坏之分但是他们的用力也不太一样但是总体来说为什么要用RL的framework去完成Agent训练的原因就是因为有目标在不管是deep research它可能只需要从tokenbytoken的generation方式去尽可能的搜索相关信息然后完成一整个report还有说Agent Access像Pokey一样说我的工具可能就是一个tokenalized的东西然后我可能通过很多个工具放在一块可以解决一个问题 它都是为了以目标为驱动跟过往的一个LM训练很大的一个不同在于说LM本身的训练是可以通过大量的supervised learning data来完成就是autoregressive的这种training方式而agentic system这些事情很难deep research仍然可以用一些但是到了tool calling这一部分单一的tool calling可以通过数据来完成但是当变成工具链的时候它就很难再完成一个autoregressive的training 原因是因为市面上不存在一个比如说我有这么一个任务然后这个任务所对应的是这50个tool call然后把这个数据复役的给一个蓝维士房子让他去训练没有人去撞见过这个数据也不可能通过互联网去得到这个数据因为互联网上也没有人产生过这种数据所以只能靠人为标注了如果说你非要用这样的数据的话 你觉得有哪些任务比如说他用监督学习微调的方式更加容易有哪些任务他是一定要通过这种强化学习的方式来做呢就是这两者之间我想他针对的任务可能也是不太一样的对目前的共识是针对于世界上已经有的很多的写作数据文本视频图片这一系列有大量以标注数据的这种任务 一般来说通过监督学习就已经可以得到一个很高的水平然后再通过ROHF的这种Post Training的方式使得这个能力再上一个台阶使得可以更符合人类大多数Preference的一个效果为什么要做这个原因呢是因为你大量的监督数据其实很多数据掺杂着好坏的 并不是每一个数据点都是人类所喜欢的那它训练完了以后是完全泛化到所有的互联网上的数据那下一步就是说我能不能以人类喜好为目标去fine tune一下我的模型使得它更偏向于人类喜好的模式那这是RHF的目的 在后面为什么现在甚至于要讲RL pre-training原因是在于很多的任务是只有目标驱动的有哪些公司在做RL pre-training现在只有研究的组在做RL pre-training但我们其实就已经开始做一些类似于RL pre-training的东西了 但它还有些prior knowledge那些没法靠pre-训练得到但是其实它已经基本上把中间的那些很多训练的过程给扔掉了但我就不细讲这个方面我先讲讲以RL为核心的训练机制为了解决什么问题就是说很多的任务是以目标举动的比如说写代码比如说数学物理就金融机构的一些东西然后再比如说城市规划你做operations researchsupply chain这些东西它都是有明确目标的世界机制也很完整 如果A发生了会出现B那在这种情况下pre-training就变得不是很有必要第一你这种专业型的目标为驱动的这些场景你可以想象大多数都是没有任何的数据的数学跟代码是唯一的两个可能有相对比较多的数据点的一些场景除此以外我刚刚说的剩下的那些点基本上都没什么数据 你很难在互联网上得到大量的数据去完成这个训练第二本质上它要解决的问题是非常泛滑的而数据上已经出现的数据大多数都是非常聚焦在一些经常会发生的coding问题和代码问题和数学问题而那些非常高深难测的那些数学问题它是从来没有出现过的 那他就必须要通过一个Counterfactual的形式就是我要生成一些这试验上从来没有出现过的代码数学物理规划等等等等的这种输出然后靠一个Ground Truth Evaluator来告诉我做的对不对然后去Self Train那这种训练方式是非常适合于这种有Ground Truth能够做出精确判断的这种用力然后去进行优化的 这个时候RL的最闪光的时候了其实很多research在网上都说过就是说其实现在最大的问题是verification我如果能够找到一个good verifier那我可以consider the problem solved因为可以通过RL去完全对于这个verifier的occupization就可以了 那接下来我也讲一个我个人认为可能有一定非共识的一件事情在Verifier之上我们可能下一步最需要完成的一件事情就是怎么去提升那个Verification方向那个模型或者Verification那个机制的算化性 以及说当这个agent本身输出在devate from what people have seen in the world的时候如何能够使那个verifier可以adapt到新的输出上面去然后使得那个verifier可以完成更好的verification 这个如果有谁能做出来我们就可能会真正踏入向Super Human Intelligence迈进的这么一条路因为它可能闪出的知识就是人类所不拥有的这个如果能做出来它是可以解决幻觉的问题吗我觉得幻觉问题是另外一个问题就这个东西很容易产生幻觉这个方向是就像我们当年看到Alpha Zero打败人类一样它所能够走出的一些路子是跟人类正常想象当中想象不到的一些路子 可以通过这个机制甚至可以发现新的物理定理可能可以真正去discoverhuman所不拥有的knowledge这个可能是下一步我觉得真正迈向super intelligence的一个关键点但是目前还没有什么很好的一个突破 对,你说到这个点让我想起了OpenAI对AGI的五个层次的划分,其实也是因为OpenAI在这一轮跟微软争夺控制权的问题上,把他们之前跟微软签的一份协议给曝光了,我觉得整个路径啊,就是在沿着你说的这个方向走。 它的AGI的第一个层级是就是聊天机器人我们可以理解成ChadGPT对话型AI很好理解第二个是推理型的AI这也是大家在去年其实看到的一个方向第三个方向就是AI Agent代理型AI或者AI智能体 这个AI不仅能思考还能替代人类去执行这种多步骤的自主操作完成一系列的任务比如说我们刚刚说的旅行这个定行班定酒店这一类的看起来今年也在朝着这个方向迈进了第四个等级的AI就是创新型AI它把它叫做Innovators 他说的是这个人工智能需要具备创造性思维他能够自主地发明新的工具或者方案比如说在药物发现中他可以去发现一个新的分子那这个时候其实AI他就已经可以提出人类没有想过的办法 然后自己去找到这种创新型的解决方案就是你刚刚说的如果有了这个方案AI是不是在创作性的问题上可以超越人的范畴去提出一些人没有想到的这个解决方式现在看起来我们今年就是在整个市面上大家看到的是大家对AI agent的一个非常热的市场在爆发但是就是你刚刚说的这一点让我想到了OpenAI它定义的第四个等级 他说的第五个等级就是组织型或者是超人级的AI就是说AI可以独立承担一个组织的全部职责远超常人有一点类似于我们说的超级AGI我不得不说的一个点就是说他们对于AI能力的定义其实是偏产品能力的 它不是偏技术能力的其实从某种意义上来说二跟三之间没有一个巨大的跨越性然后一看你怎么定义它因为聊天机器人可以是非常非常普通的聊天机器人也可能是像现在我们看到的这些聊天机器人然后四跟五之前我个人认为也没有很大的gap主要是三到四之间有个巨大的gap这个gap的核心原因就是我刚刚说的那verification能力的无法跨越 从人的角度来举例子吧因为人可能是他的学习方式其实就跟RL很像比如说你小时候学一个东西你可能可以判断的东西都是在你的知识范围之内的比如说你学会了加法那你只能判断一加一等于多少二加二等于多少你没办法直接去泛化到说三减二等于多少 这个reasoning的过程并不是一个靠内在知识就可以完成提升的一个问题像我们现在所说的verifiable的像比如说reinforcementfine tuning这些都是以一个内在verification体系就可以完成的知识迭代 就是说我有这么一个verification它是永久固定的你可以通过这个verification去不停的提升或者说我预制了给到你一定verification的knowledge根据这个knowledge就可以不停的提升但如果说一个agent可以做到20位数的加减法但他从来没有见过减法这个东西 它仍然没有办法verify说一个减法是对还是错那我觉得人也是啊对吧假设我学的是数学或者说我从来没有学过生物我的数学领域的知识我不知道生物的底层逻辑的话我也很难翻华对所以这个地方最难的一个点两个地方一如何通过一个人类给定的简单的描述可能说减法跟加法的关系是什么 直接能够从A推理到B的verification是什么如果可以做到这一点那agent的整个verification泛化性就直接上到下一个台阶第二点是它能不能通过自我探索基于现有知识的grounding去完成对于未来知识verification的一个延伸这个也很难 比如说你已经知道了大多数的碱氧酸之间会生成比如说二氧化碳那你能不能对二氧化碳的性质进行一个简单的自我了解并且对于未来可能会出现对二氧化碳的问题做出一个verification这个也是非常难的然后未来如果出现了类似的agent本身产生的结果我能够去verify说这个结果是对还是错 这个也非常非常难所以我理解就刚刚比如说我们在说到AGI的五个等级的时候就是从第三个代理型AI到创新型AI它可能是跨越从低于人类水平到一下子超过人类的平均水平甚至是超过最好的人类的那个水平的一个时间基点对所以三到四之间是远超过一二三跟四五之间的gap 我觉得5可能还有一个很微妙的东西agent跟agent之间会不会出现人之间politics因为如果agent和agent之间是decentralized的话那他们的objective可能互相之间是有misalignment的那在decentralized multiagent system里面它就有可能会出现politics 你指的是人与人之间的比如说办公室政治斗争就是类似于这样子的对但是在agent环境下会出现一个完全不一样的因为他们的objective会互相冲突一旦出现互相冲突以后会卡死在那甚至就有点像在计算机系统里面的那种racing condition直接lock在那回心针问题对就可能会出现类似的情况但是一二三跟四之间是一个红钩 这个是谁能解决的话这个是一个非常非常大的一个突破你有看见有大公司在沿着你说的方向用RL做pre-training这个路径去解决吗包括做这个verification的机制的泛化verification机制的泛化目前还没有谁在做任何非常大的突破吧目前大家能想到的就是说human knowledge distillation来做到verification的提升 Auto Pre-training确实有很多人在提了但是Auto Pre-training有一个致命弱点因为Auto是一个complete counterfactual learning的一个过程那它会给你无法避免带来的一个问题就在于它会不会出现一个能够解决问题但human看不懂的解决方案比如说我们写一个代码 verification能够 verify input 是什么offer 是什么 然后这个A写了一段代码它确实work了但是里面所有的operator全是你看不懂比如object的variable的definition都是一些乱码它的加减成熟都是用那些非常复杂的甚至用编译语言写出来的东西然后把它硬生生摁进了原来的那种代码里面人类就看不懂那东西发生了什么但它就是能work这个也是它的一个致命过点 所以它的那个reward definition会非常重要比如说human readability要怎么样但是human readability你没有办法因为如果来解决对吧所以你就变成没有办法unverifiable整个听下来世界也很危险我大概听到这里能理解为什么Jeffrey Hinton他会那么悔恨自己去创造了AI的底层吗 比如说当这个AI他已经可以用人类不知道的语言写出超越人类知识的时候就这个时候还是蛮危险的那应该Rich Sutton更合理因为Jeffrey Hinton所创造的Newon Network更多的是能够 represent human knowledge 而要做到 counterfactual的 knowledge discovery或者说 policy discovery还得靠RL所以如果要说悔恨的话那Rich Sutton可能会更悔恨我觉得最终的一个事情还是如果说要谈到 regulatory的这个 information我觉得 eventually对于 reward design可能是需要有一定的regulatory的 efforts的 训练的时候给agent是什么样的一个incentive他可能会决定说这个agent训练出来是什么样子对其实关于就是刚刚我们在比较强化学习跟SFT就是监督微调学习就我们在比较这两者的时候呢我也听到了这样一个说法就我在我有一期节目里面讲过比如说我们假设用强化学习的效果是比这个SFT的效果要好个两倍但是它消耗的token的数量可能在十倍之多 就是对于现在大家马上要商业化马上要应用来说它的这个性价比算不过来你怎么看对这个是很正常的因为reinforcement fine tuning的做法是说我只有一个reward function我没有任何的其他信息我要去完成那个目标而suffice fine tuning是说我已经有标准答案了我只是需要想办法去靠近那个标准答案就好了 这个无法避免的就是21 fine tuning的价格会更高但是长期以往有更复杂的任务它就没有办法做supervised fine tuning因为它没有标准答案所以它就不再是一个选择性问题现在为什么会有选择性问题是因为我们解决的问题还不够复杂到了未来问题会越来越复杂当它问题到了极度复杂的时候就没有选择 嗯对然后你刚刚提到强化学习跟监督学习微调的这些方式的不太一样的一个大点啊就我理解强化学习就是在你没有标注数据的时候你也可以用这种方法但是比如说传统的方法这个数据必须是标注的而且这个可能已经慢慢的成为业界的一个共识了那基于这个Meta为什么还要收购Skill AI 数据的重要性在现在的这个大时代下是有下降的但是有一个方向是无法避免就是数据的标注性在multi-modality特别是在视频和图片数据上是目前还完全无法跳开的一件事情因为它的verification能力会基于比如说我们要做基于视频跟image的reinforcement fine tuning它的作为image input的解析能力要达到很高的一个程度 而且没有办法靠Human rule来完成就是说它必须要靠模型的解析能力去把那个video和图片的content整个解析出来在这个content之上Human才能写 rule说我怎么去verify它那这个解析能力就变得非常的难因为我们现在都知道图片里面的很多细节视频里面的很多细节现在其实我们的模型是没有办法很好解析的特别是这种multimodel的模型它其实还是更多的偏向于text的能力 所以我的总理感觉是他们可能想在MultiModality上面发理而MultiModality上面以及Robotics上面标注目前是还跳不开的一个问题所以这个方向可能会是一个Meta接下来会发理的一个点所以第一步多么泰上还是得有先解析好了的或者标注好了的数据 相当于是把所有的数据先有一个基础的训练以后我们再看强化学习能怎么处理我现在看的整个路径都是这样XGBT最早是我有大量大量的数据我训练出了模型你这个基础模型在做一些superfights反映前点把它变成一个精炼的基础模型精炼的基础模型之上最早是说我们拿一些数据去训练一个reward model然后通过这个reward model再去训练我的language model用RL去训练language model让它变得泛化性更强或者说它能够在位置� 现在慢慢就变成reinforcement fine tuning就是说我不要那个rule world model我就用现在大家的共识或者说lm as judge去训练模型这个已经成为慢慢慢慢会变成一个共识在mortemodality上面现在还处于第一第二股就是说我现在有大量的数据我现在在训练一个基础模型基础模型训练完了以后我做了一些rl fine tuning我怎么能够去做一个标准化的judge verifier或者说一个rule based verifier 这个是目前不存在的一个东西而非常难做因为一个image本身它没有表情答案所以他可能会说我先通过数据来训练一个rover model然后使得我multipability的能力变得最大然后再说OK我multipability的能力已经很强了我能不能去通过这个输入输出的能力把它变成一个wifr然后通过这个wifr我再去做reformable function 我觉得整个lifesight都是这样在转到目前为止对你觉得scale.ai它在标注图片跟视频的这些数据上更像是一个技术含量很高的一个工作还是说它其实就是一个我找很多工人来给这个数据打标只要找的人多然后打的标多它就可以成为一个数据库很多的地方还是说它这个中间其实有很多要考验你技术的环节我觉得第一点最难的地方就是文字的人为打标还稍微简单一点 图片的人为打费就变得更难了比如说你要生成一个产品图这个产品图是好还是坏100个人估计有100个说法那他怎么能够标换那个产品图好坏这个非常非常难所以这里面其实有alignment的问题这个alignment的问题是个技术问题我觉得短时间内可能很难解决他们可能会先写一个非常复杂的rubrics然后去训练这些人说这些图哪些比较好哪些比较不好然后robotics就变得更难了就是说在这个情况下robot干了这么一件事情是好还是不好 人可能都看不懂说这个robot在干嘛但robot可能自己心里有plan说我可能要先做这个再做那个再做那个可以完成这个目标但是人可能完全不懂说这个robot为什么干了这件事情所以multi model以后再加上multi model加action这一层串下来其实需要很多很多数据的支持所以我觉得data是个中期问题 如果你说非常短期比如说resource啊人人菜啊中期可能会在data上面有瓶颈长期可能还是一个optimizationRL的问题所以它短中长期所需要的资源和能力都不太一样而Meta可能希望说它能够从模特意上解决它自己的中期的数据问题使得它自己mortemodality的能力会有比较大的提升吧 他挖的这批人算是在解决长期问题吗对短期是什么是算力对我们最早不是遇到了卡不够啊各种各样的问题吗那个问题已经解决了现在就到中期问题中期就是说我们可能已经解决了一些在文字上面的代码上面的offermentation问题但现在multimodality上面是不是也能够解决这些问题 在数据上还是有缺口的那之前的那些数据缺口在GPD4O之后的那一整批的Iteation里面其实已经基本上完成了对于代码和文字上面的这些Iteation那现在就到了Multipedality上面等于是一模一样的GangChart那它只是把这个东西横移过来了而已对 但是也会有新的问题产生就比如说刚刚我们提到的审美啊 图片的标注啊视频的标注啊对对对对但我觉得都是时间问题 对那你觉得你自己做这个Pokey AI你搭AI agent的一个你自己的底层的开发哲学跟逻辑是什么最核心的逻辑是说我们现在认为AI agent的使用不像当年XGPT刚出来的时候那么简单但我们希望说AI agent的使用就跟XGPT一样简单 不只是在用户层面一个consumer层面而是说对于任何的企业开发者professional来说他们调用一个agent就是对着一个简单的API一行prompt就完成了整个agent调用得到的就是你最后的结果 而你不用去担心说中间出现各种各样的browser的环境各种各样的问题都不再存在这是我们的开发逻辑这是为什么我们尽可能避免了非常非常复杂的infra架构而是通过很多的集成把更多的能力全都压在agent本身的模型里面 而不是说我通过一个language model然后通过不停的去掉用市面上更多的infrastructure去bypass这个工具的能力把工具的数量去压缩就某种意义上是说你用browser就是用一个工具代替了几千个工具但是同时也意味着你的模型所需要的能力会更小一些而我们的方式就是说我们希望模型的能力变得最强然后工具就直接把它铺开你就直接去想要用什么工具就用什么工具就好了 就相当于一个agent可以操作整个internet和一个agent只能看一个网页这样的一个区别模型的能力用到最强还是接其他的基座大模型吗还是你们自己也会开发自己的模型我们会开发自己的模型就是我们现在的很多的tool callingtool selection的这些能力都是我们自己的模型在做的未来的话可能连那个language model的部分会跟我们的模型会直接结合在一块变成一个单一模型 那个时候就从用户的input到予以理解到工具选择planning到最后的结果全都变成同一个agent来完成这个时候这个agent会变得非常好用因为它就不再像很多市面上的这种agent一样它需要有大量的来来后回的info之间的跳转而是说你只要把那个prompt输进一个API这个API就可以给你提到你最后的deliverable的结果 为什么要开发自己的模型这个是所有的通用型agent他必须具备的一个技能还是说他也可以直接大模型就如果你用browser你用那些sandbox就是说我用了sandbox然后让另外一个codingagent去完成coding的过程然后再给到个结果你可以不用自己开发大模型 原因是在于你把工具压缩了我去依赖于另外一个写代码的agent去跳过这些工具的使用或者说我选择一个browser的agent我去跳过你选择工具的使用这个就是通过压缩工具的数量选择更general的工具来完成你的目标 不是说直接选择工具为什么我们要去训练模型的原因呢第一成本很高你从一开始去解析用户理解planning到你选择sandboxsandbox本身价格很高browser还有vision的部分第二它速度很慢第三它的范化性很差它训练的时候见过很多很多网页当你进入到专业场景以后它就很难我举个例子有朋友问我们要的一个feature说我能不能从post hoc就是一个analyze web traffic的一个网站上面这是个很复杂的网页 去找到这个用户本身的behavior基于这个用户behavior的一些metrics然后去导入一个analysis的一个script然后在这个script里面得到presentation的几个figure这个figure再放进一个report里面生成一个pdf就这么一个agent flow你是不可能通过browser加sandbox来完成的 你必须要直接去access那个工具去得到最精确的数据然后再去做分析这个流程就变成了我们的优势类似于这种用户设例其实非常多在广告分析里面在用户分析里面其实有很多很多的工具是在互联网上面但是正常的browser是肯定搞不定的因为他们在训练当中从来没见过 所以我们能够通过我们的foundation model把成本降下来把泛化性提升把它的适用的workflow的类型有很大程度的拓展而不只是限定于说那几个最简单的购物写slides做些research这种 其实有很多很多专业型的workflow是他们解决不了的所以我理解其实你们搭的是一个垂直的选agent的模型对不对选工具的模型我们不选agent它不只是选单一工具它是选一个sequence of工具就是一个推理加工具选择的一个模型 对 因为我看见大家在谈到AI的时候大家其实一般有两种派别一种是说我把越来越多的问题交给AI然后端到端的训练它主打的就是一个人更少的干预让AI去犯错误 让AI去学习那另外一种呢就是说我们在真实的应用中还是产品跟用户体验优先那这种情况下我们就要减少幻觉减少幻觉的方式就是说我们还是要去拆分一些细节 让他的工作流稍微能确认的地方能够更加确认让产品跟应用能够先用起来跟落地就你觉得你自己的产品哲学上你更偏向于哪种就是我做一个CEO现在一半的我是一个产品人一半的我是一个researcher做一个researcher我同意第一个关键因为越是general的环境能训练出越强的模型 作为一个产品人我会选择第二种因为用户的体验跟模型的能力是不成正比的我们的模型能力肯定很强但是最后的用户体验可以是非常糟糕的举个简单的例子我们之前自己遇到的就是我们模型其实选择的工具从头到尾都是对的我们其实我们的工具是可以发帖到所有的平台的就以社会运营作为例子好了之前我们其实有一段时间那个社会运营本身就发布完了以后那个link没有给到你有很多用户就非常get confused 我这个发文发到哪去了呢他也不知道说自己应该跑到那个账户里面自己去看是不是有新的视频出现了或者有新的图片出现了然后就导致说能力其实都端到端打通了但是就是这个用户不知道说你的产品在干什么然后还有一个另外的例子就是我们比如说甚至Google Slides我们之前是就给你个Google Slides link你自己去看 但现在我们会直接把那个grove size就imbed在我们的网页里面你就直接可以原地在pocket里面就直接可以修改grove size大家就会觉得说这个东西是完全in my control的一个东西而不是说我还要跑到另外一个网页里面去再改完改完回来再看你生成点什么东西所以它有很多这种用户细节在里面跟你模型能力毫不相关 那在这种情况下作为产品或者作为一家创业公司你就必须要去打磨产品的细节而模型能力是决定你的产品下限的而产品的上限是由你的产品细节决定的对 我们刚刚好多次提到了Race Thurton教授他是强化学习的奠基人之一也是2025年的图灵奖得主因为我知道你在斯坦福读博自己学的也是强化学习嘛所以你跟Race Thurton他的渊源是什么 Rich Sutton跟我的导师是铁哥们在他们提出RL这个概念当时提出Temporal Difference Learning的时候就认识了然后我的导师当年是证明Q Learning最基础的Temporal Difference of Policy Learning的那个理论能够被Function Approximation完成的那篇paper是我导师写的然后我在Stanford读国的时候其实见过好几次Rich Sutton 甚至有一次在我导师家里然后Riserton来开party然后大家就一起吃烧烤啥的有很多点为什么我提到Riserton第一是他的这个经历跟很多人不太一样他当年其实是罹患癌症的他那个时候其实有好几年都没有任何工作 一度非常非常艰难但是他从而没有放弃RL这个research方向后来他去了University Alberta然后Alberta其实给了他挺大的支持但他其实整个人身体的状态其实一直都不是很好即便很多人都说RL是一个玄学那时候也没有放弃过了 第二个就是他这个人我跟他交流过几次他非常principle他的PhD学生是我们公司的visual scientist所以还有更多的原言在里面我们其实有聊很多的这种我们的startup想法然后聊模型的想法他其实有非常多的前瞻性的想法就是他不会拘泥于现在比如说LM的能力或者是foundation model是会取代2L就是因为他的坚持所以现在有了2L整个行业的基础 与此同时有现在那么大的发展虽然现在市面上很多汇款很多人其实并不是特别懂RL然后但所有人都在说我们要do RL whatever但真正能够把RL optimize好的其实整个行业也就这么几十号人吧然后你可以看到都昌森坠在这些人发的推分和做的产品里面 我觉得未来还是很大的潜力的而且要感谢他能够对这个行业和他自己的领域有那么强的坚持否则也没有我们现在那么大的发展然后你提到你跟Rich Salton在聊天的时候他提到了很多非常前瞻性的想法觉得有哪些想法是非常打动你的或者让你印象深刻我觉得他跟我提了很多次叫model plasticity这个问题模型本身你的训练是不可以无限制对他训练的就是你训练到某一个程度他就会fall apart 其实在210领域之前很经常看到叫catastrophe forgetting就是说你训练很久很久以后他开始忘记所有过往的学习到知识然后整个模型像疯了一样他所有的原来的policy都消失了这个出现过吗出现过很多文章里面都提到过这种事情 这是为什么你一开始模型要变得足够大其实就像海绵一样然后你往里面不停的注水然后你注水注到一定程度它满了那你再往里面注水会发生什么就是它会流出来一些但流出来的不一定是注入的水可能是原来已经有的水那如果原来已经有的一部分水是很重要的水就像你大脑里面不停的灌输知识然后到最后你过载了然后把加减乘除忘了那是不是剩下的所有的知识体系就直接fall apart 这个问题本身叫model plasticity就是说它的可塑性到了某种程度就直接崩溃了然后你要怎么去解决这个问题叫continual learning现在可能你有一天会人类生成一个terabyte of data那10天是10个terabyte那未来可能生成数据还会越来越多 那你怎么能够用一个模型无限地去训练它让它仍然能够对未来的知识进行获取这是不可能的你觉得现在整个模型的训练比如说到GPT-4甚至是GPT-5它的数据量已经到极限了吗还没有模型的size是一个linear在增长的一个过程但是我们的数据量是一个指数在往上涨的过程到了某一个阶段一定会碰壁的没有办法这样skill下去其实我们在Poge训练的时候就已经遇到过这个问题了 那么我们训练的模型比较小然后我们的工具量也很大我们的数据量也挺大的然后我们其实用小模型训练训练到某一个点它就突然间整个performance就会掉得非常厉害然后我们必须要把模型认为更大一号然后再去训练才能够不出现这个contextual forgetting的情况它取决于你的use case有些use case你可能小模型有一定的数据量它已经发生了然后另外一个它一直提的就是如果design的问题 在未来的世界如果RL作为核心的模型的优化机制了那去设计这个RORMODEL的这个人他有什么样的标准这个RORM本身是怎么去设计能够保证他的MORAL STANDARD这是一个非常麻烦的事情因为你应该知道RL是一个SEQUENTIAL DECISION MAKING的问题也就是他的RORM是相加的 你可能定义一个单步的如果是make sense的当它被加起来以后变成很多步以后它就变得并不是一个你可预测的东西因为它的那个总体如果是跟the policy就是那个agent policy或者它的决策机制所改变的所以它的设计可能跟你原来的想法可能已经背道而驰了 然后还有一个问题比如说你有多个reward怎么办那你要同时优化四五个不同的目标那在这种情况下你怎么能够做到balance这些目标然后能够在这些目标当中找到一个每个项目都做的相对比较好的状态这也是个问题然后他也提出过这个想法叫generalized value function 怎么能够去学到一个同时优化多个objective的一个vile functionvile function就是在211里面去决策说我去到下一步去到哪个状态能够达到更优解的这么一件事情然后它可以在一个状态下得到多个目标所对应的值 这样的话可以去判断说我要怎么去平衡这些对应的这些objectives挺有意思的你觉得你从他身上学到了什么我觉得就是如果你自己觉得first principle是对的就不要放弃坚持自己的路很多东西中期短期长期所看到的结果都很不一样然后有些东西你可能短期内你可以看到很多的结果但你会卡死在那 但有些你可能take a step back真正去专注于你认为first principle是对的东西你可能长期会得到更好的结果你说到现在对RL研究的特别深的人是以哪些高校或者以哪些中心为原点的就是以OBI早期的这批人Peter Beale的学生可能现在派里面的这批人Sergei Levine的学生Rich Sutton的学生基本上都在学界 除此以外也有很多现在已经分支出来的好的教授学界偏多一些但是学界一个问题就是大家做RL都做的太理论然后写很多reparound的写些新的theory之类的Industry的话可能就是deepmind的那批人DevServor唯一有核心的这一批deepmind的人还有我导师也在deepmind 可能对RL的领域是最了解然后做最好的然后Microsoft也有比如说像LenfordLenford的话其实是做RL的理论方向很早期很先驱的人之一但是这个核心人群并不大基本上不管他们怎么换地方都看到是这几个 核心人底下的学生啊或者跟他们work together这些人衍生出来的嗯对你觉得伦敦会是一个RL的大本营吗因为我其实是想到当年AlphaGo AlphaZero那一段历史的时候其实那个时候是强化学习非常火的一段时间了 他可能也是一个最早的一批人在研究强化学习的方向的也算是一个小热潮吧你觉得那个时候研究这个强化学习跟现在大家去研究强化学习它方向上会有很大的不同吗就15到18年是AlphaGo,AlphaZero,MuZero到后面有些比如说StarCraft游戏里面的2L发展的一个巅峰到了那个之后就开始沉寂了 然后所有人都说LM可以stop everything然后到现在突然之间RL又变火了我自己看下来是觉得伦敦的David Silver他们这批人做的RL是有一个他自己的一个style的他有一个formal verification的一个方式一定能够知道true or not基于这个verification的方式去训练一个非常dedicated agent这个agent只能解决一个问题的那种 他没有真的说我通过一个非常通用的decision making的action space去训练一个可以解决很多问题的verifiable的一个agent但是现在伦敦其实做Oro的人也不止David Silver有很多人在做Oro我觉得大本营上感觉还是会是弯曲因为对OpenEye跟DeepMind的人都在那大概率还是以那边为核心 OpenAI是不是也是15到17年左右是花了很多时间去研究强化学习的,因为我记得他们早期的研究就是有各种游戏里面的推方块啊,对,我觉得那些好像都是强化学习去解决问题的。 对最早的时候是Gem Environment他们希望能够通过一些比较简单的游戏证明说RL的go-oriented的解决问题的能力但是因为这些游戏就直于游戏18年为什么慢慢RL开始沉寂的一个核心原因就是因为大家都认为RL就是一个游戏环境的产物它没有一个真正能够解决实际问题的能力 但是直到现在我不得不承认的一点就是到目前为止RL还是作为一个LM之上的optimizer它并不是从零开始训练出了一个极致可以解决通用问题的所以现在大家说RL pre-training这个也是一个值得去深究的一件事情就是说这个事如果能做成的话意味着可以从零开始训练一个完全通用的RL解决方案这个会是一个非常大的成果 对 刚刚在我们整个的聊天过程中就是我自己的感受啊是你的整个思维方式包括你的眼界还是非常非常超前的但是呢当你真正去做产品或者去跟投资人卖一个想法的时候他们可能有的时候就是越超前是越没有共识的你会有遇到类似的困难吗 有其实上礼拜在ICML我们聊panel的时候其中有一个问题就是怎么跟投资人聊特别technical的startup项目我个人认为是不要尝试去sell your idea除非你的idea是共识但是一旦你的idea是超共识的话那也没有任何的意义去投你的项目 我的一般观点是如果要去跟投资人聊的话利用市场的共识但是在这共识之上加一个logic leap比如说市场共识是Are your agent is the hot thing大家都觉得这个东西有future你的唯一的那个hop是说你怎么能够实现它同时你实现它的时候你有什么优势 就是你要告诉他说我训练这个RO agent的方式跟所有人都不一样其实是没有任何意义的所有人都不会理解说你为什么跟别人不一样但你要出了的时候你要解决的这个问题在你的技术知识之上是很有意义的同时你为什么有这个unfair advantage就可以了 刚刚其实我们在谈到你做这个AI agent底层哲学的时候我也把两种不同的这种思维方式有丢给你然后同时我们刚刚在评价几家不同的AI agent公司的时候比如说James Park,Manners,OpenAI的ChatGBT还有Fellow所有的公司大家用的方法都不太一样啊就是你觉得未来agent大家能在这个中间脱颖而出的核心的点是什么 是技术路线产品还是什么样的决策我觉得这些公司最后都会走向一个不一样的focus area有点像当年早期的像Mistro像HopinEye像Anthrobic大家后面都走不一样的路 最后会有一个区分化diversified的一个过程然后大家会发现这个agent都越发展越不一样原因就是因为founder也不一样其实人在这里面就会自然的发展出很多的不一样的diversified的一些decision第二我觉得技术方向确实它会是一个决定一家公司能够存活下去的核心 原因在于Agentic System的成本很高虽然你融了很多钱但是很多AI公司的一个核心痛点就是你融了钱你的growth越快你死得越快因为你都是入不敷出的在做growth然后你下一轮融资的时候给所有的投资人你看你的growth profit全是负的50%什么的 第一反应就是这些东西就算我投了你下一轮你有什么办法可以把它转正吗你说你没有那投资人也不会买账总体来说就变成了一个无限消耗的过程那技术的提升会使得你可以把这个growth profit转正所以投资人来说那行你知道能增长那就值得投所以技术路径是你能够活下来的核心 但是最后的产品发展形态以及最后的市场的格局会是Founder以及这个团队的decision所导致的而且会区分度很大对 讲得特别好确实是如果你技术路径选错了那可能整个AI的成本就太高了短时间还可以靠融资维持但是这不是一个长时间它能一直维持的事情 对对对当然很多团的固执很高都快上一个billion可能Equahard的可能性不太大但是小一点团队的现在相对quality比较高的那种团队被Equahard的盖利群都挺大的所以现在这个市场可能接下来一到两年都会是一个非常疯狂的大鱼吃小鱼的过程所以我们可以拭目以待我觉得接下来一到两年的商业市场会是一个非常有意思的一个故事好的好的太精彩了谢谢感谢 好的 这就是我们今天的节目如果大家有什么样的想法可以给我们写评论 写留言另外呢 如果大家对整个硅谷每天在发生什么感兴趣我们也有一档关于硅谷热点的清解读节目叫做101 Weekly大家可以在小宇宙还有Spotify上来搜索到我们的节目 同时也可以在各大的视频网站看硅谷101的视频最后如果大家喜欢我们的播客也可以在你所收听的音频渠道来订阅我们我是红军感谢大家的收听谢谢ご視聴ありがとうございました
